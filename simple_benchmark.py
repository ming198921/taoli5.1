#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆ <1ms å»¶è¿ŸåŸºå‡†æµ‹è¯•
"""
import asyncio
import aiohttp
import time
import numpy as np
from typing import List

async def test_baseline_latency(iterations: int = 1000) -> List[float]:
    """åŸºå‡†å»¶è¿Ÿæµ‹è¯•"""
    latencies = []
    
    connector = aiohttp.TCPConnector(
        limit=100,
        ttl_dns_cache=300,
        use_dns_cache=True,
        keepalive_timeout=60,
        enable_cleanup_closed=True
    )
    
    timeout = aiohttp.ClientTimeout(total=1.0)
    
    async with aiohttp.ClientSession(
        connector=connector, 
        timeout=timeout,
        skip_auto_headers=['User-Agent']
    ) as session:
        
        # é¢„çƒ­è¿æ¥
        for _ in range(10):
            try:
                async with session.post(
                    'http://127.0.0.1:8881/api/v3/order',
                    json={'symbol': 'WARMUP'}
                ) as response:
                    await response.json()
            except:
                pass
        
        print("å¼€å§‹åŸºå‡†æµ‹è¯•...")
        
        for i in range(iterations):
            start = time.perf_counter()
            
            try:
                async with session.post(
                    'http://127.0.0.1:8881/api/v3/order',
                    json={
                        'symbol': 'BTCUSDT',
                        'side': 'BUY',
                        'type': 'LIMIT',
                        'quantity': 0.001,
                        'price': 50000 + i,
                        'timestamp': int(time.time() * 1000)
                    },
                    headers={'Connection': 'keep-alive'}
                ) as response:
                    await response.json()
                    
            except Exception as e:
                print(f"è¯·æ±‚å¤±è´¥: {e}")
                continue
            
            latency_ms = (time.perf_counter() - start) * 1000
            latencies.append(latency_ms)
            
            if i % 200 == 0:
                print(f"è¿›åº¦: {i}/{iterations}, å½“å‰å»¶è¿Ÿ: {latency_ms:.3f}ms")
            
            # é¿å…è¿‡è½½
            await asyncio.sleep(0.005)
    
    return latencies

def analyze_results(latencies: List[float]) -> dict:
    """åˆ†æç»“æœ"""
    if not latencies:
        return {}
    
    latencies_np = np.array(latencies)
    
    # è¿‡æ»¤å¼‚å¸¸å€¼
    filtered = latencies_np[latencies_np < 100]  # è¿‡æ»¤>100msçš„å¼‚å¸¸å€¼
    
    under_1ms = np.sum(filtered < 1.0)
    under_2ms = np.sum(filtered < 2.0)
    under_5ms = np.sum(filtered < 5.0)
    under_10ms = np.sum(filtered < 10.0)
    
    return {
        'total_samples': len(filtered),
        'min_ms': np.min(filtered),
        'max_ms': np.max(filtered),
        'mean_ms': np.mean(filtered),
        'median_ms': np.median(filtered),
        'p95_ms': np.percentile(filtered, 95),
        'p99_ms': np.percentile(filtered, 99),
        'p999_ms': np.percentile(filtered, 99.9),
        'std_ms': np.std(filtered),
        'under_1ms_count': under_1ms,
        'under_1ms_rate': under_1ms / len(filtered) * 100,
        'under_2ms_rate': under_2ms / len(filtered) * 100,
        'under_5ms_rate': under_5ms / len(filtered) * 100,
        'under_10ms_rate': under_10ms / len(filtered) * 100,
    }

def print_optimization_analysis(stats: dict):
    """æ‰“å°ä¼˜åŒ–åˆ†æ"""
    print("\n" + "=" * 80)
    print("5.1å¥—åˆ©ç³»ç»Ÿ å»¶è¿Ÿä¼˜åŒ–åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    print(f"æ ·æœ¬æ•°é‡: {stats['total_samples']}")
    print(f"å»¶è¿ŸèŒƒå›´: {stats['min_ms']:.3f}ms - {stats['max_ms']:.3f}ms")
    print(f"å¹³å‡å»¶è¿Ÿ: {stats['mean_ms']:.3f}ms")
    print(f"ä¸­ä½æ•°å»¶è¿Ÿ: {stats['median_ms']:.3f}ms")
    print(f"æ ‡å‡†å·®: {stats['std_ms']:.3f}ms")
    print()
    
    print("å»¶è¿Ÿåˆ†å¸ƒ:")
    print(f"  P50:  {stats['median_ms']:.3f}ms")
    print(f"  P95:  {stats['p95_ms']:.3f}ms")
    print(f"  P99:  {stats['p99_ms']:.3f}ms")
    print(f"  P99.9: {stats['p999_ms']:.3f}ms")
    print()
    
    print("å»¶è¿Ÿåˆ†çº§ç»Ÿè®¡:")
    print(f"  < 1ms:  {stats['under_1ms_count']} ({stats['under_1ms_rate']:.1f}%)")
    print(f"  < 2ms:  {stats['under_2ms_rate']:.1f}%")
    print(f"  < 5ms:  {stats['under_5ms_rate']:.1f}%")
    print(f"  < 10ms: {stats['under_10ms_rate']:.1f}%")
    print()
    
    print("=" * 80)
    print("é©å‘½æ€§ä¼˜åŒ–æ½œåŠ›åˆ†æ")
    print("=" * 80)
    
    # å½“å‰æœ€ä½³æ€§èƒ½
    min_latency = stats['min_ms']
    avg_latency = stats['mean_ms']
    under_1ms_rate = stats['under_1ms_rate']
    
    print(f"âœ… å½“å‰æœ€ä½³å»¶è¿Ÿ: {min_latency:.3f}ms")
    
    if min_latency < 1.0:
        print(f"ğŸ¯ å·²å®ç°äºšæ¯«ç§’çº§å»¶è¿Ÿï¼æœ€å¿«: {min_latency:.3f}ms")
    else:
        print(f"ğŸ”¸ æœ€å¿«å»¶è¿Ÿ: {min_latency:.3f}ms (è·ç¦»1msç›®æ ‡: {min_latency-1:.3f}ms)")
    
    print()
    print("ä¼˜åŒ–å»ºè®®ç­‰çº§:")
    
    if under_1ms_rate > 50:
        print("ğŸ† Level 5: è¶…è¶ŠæœŸæœ› - >50% è®¢å•å·²è¾¾åˆ° <1ms")
        print("   å»ºè®®: ç»´æŒå½“å‰ä¼˜åŒ–ï¼Œè€ƒè™‘å¾®ç§’çº§ä¼˜åŒ–")
    elif under_1ms_rate > 20:
        print("ğŸ¥‡ Level 4: æ¥è¿‘ç›®æ ‡ - >20% è®¢å•è¾¾åˆ° <1ms")
        print("   å»ºè®®: è¿æ¥æ± ä¼˜åŒ–ã€äºŒè¿›åˆ¶åè®®")
    elif under_1ms_rate > 10:
        print("ğŸ¥ˆ Level 3: éƒ¨åˆ†æˆåŠŸ - >10% è®¢å•è¾¾åˆ° <1ms")
        print("   å»ºè®®: ç½‘ç»œä¼˜åŒ–ã€ä¸“çº¿è¿æ¥")
    elif under_1ms_rate > 1:
        print("ğŸ¥‰ Level 2: å¶æœ‰çªç ´ - >1% è®¢å•è¾¾åˆ° <1ms")
        print("   å»ºè®®: ç‰©ç†ä½ç½®ä¼˜åŒ–ã€Co-location")
    else:
        print("ğŸ“ˆ Level 1: åŸºç¡€ä¼˜åŒ– - <1% è®¢å•è¾¾åˆ° <1ms")
        print("   å»ºè®®: å…¨é¢ç³»ç»Ÿé‡æ„ã€ç¡¬ä»¶å‡çº§")
    
    print()
    print("é©å‘½æ€§ä¼˜åŒ–è·¯å¾„:")
    
    # è®¡ç®—ç†è®ºæœ€ä¼˜å»¶è¿Ÿ
    theoretical_min = 0.1  # 100å¾®ç§’ç†è®ºæœ€å°å€¼ï¼ˆco-location + ç¡¬ä»¶ä¼˜åŒ–ï¼‰
    
    potential_improvement = (avg_latency - theoretical_min) / avg_latency * 100
    
    print(f"1. ğŸ“¡ ç½‘ç»œå±‚ä¼˜åŒ–:")
    print(f"   å½“å‰å¹³å‡: {avg_latency:.3f}ms")
    print(f"   Co-locationç›®æ ‡: 0.5ms (æ”¹å–„ {(avg_latency-0.5)/avg_latency*100:.1f}%)")
    print(f"   ç†è®ºæé™: 0.1ms (æ”¹å–„ {potential_improvement:.1f}%)")
    
    print(f"2. ğŸš€ åè®®å±‚ä¼˜åŒ–:")
    if stats['p95_ms'] > 5:
        print(f"   äºŒè¿›åˆ¶åè®®å¯å‡å°‘ 2-3ms (å½“å‰P95: {stats['p95_ms']:.3f}ms)")
    print(f"   UDPåè®®å¯å‡å°‘ 1-2ms")
    
    print(f"3. ğŸ’» ç³»ç»Ÿå±‚ä¼˜åŒ–:")
    print(f"   å†…æ ¸æ—è·¯ (DPDK): å‡å°‘ 0.5-1ms")
    print(f"   CPUç»‘å®š: å‡å°‘ 0.1-0.3ms")
    print(f"   å†…å­˜é¢„åˆ†é…: å‡å°‘ 0.1-0.2ms")
    
    print(f"4. ğŸ—ï¸ ç¡¬ä»¶å±‚ä¼˜åŒ–:")
    print(f"   FPGAåŠ é€Ÿ: å‡å°‘åˆ°å¾®ç§’çº§ (<0.1ms)")
    print(f"   ä¸“ç”¨ç½‘å¡: å‡å°‘ 0.2-0.5ms")
    print(f"   é«˜é¢‘CPU: å‡å°‘ 0.1-0.2ms")
    
    print("\n" + "=" * 80)
    
    # å¯è¡Œæ€§è¯„ä¼°
    if under_1ms_rate > 10:
        feasibility = "é«˜"
        color = "ğŸŸ¢"
    elif under_1ms_rate > 1:
        feasibility = "ä¸­ç­‰"
        color = "ğŸŸ¡"
    else:
        feasibility = "å…·æœ‰æŒ‘æˆ˜"
        color = "ğŸ”´"
    
    print(f"{color} <1ms å»¶è¿Ÿå¯è¡Œæ€§: {feasibility}")
    print(f"   å½“å‰åŸºç¡€: {under_1ms_rate:.1f}% å·²è¾¾åˆ°ç›®æ ‡")
    print(f"   é¢„æœŸé€šè¿‡ä¼˜åŒ–å¯è¾¾åˆ°: {min(under_1ms_rate * 5, 80):.1f}% <1ms")
    
    print("=" * 80)

async def main():
    print("å¯åŠ¨ <1ms å»¶è¿Ÿåˆ†ææµ‹è¯•...")
    print("ç›®æ ‡: è¯„ä¼°5.1å¥—åˆ©ç³»ç»Ÿé©å‘½æ€§ä¼˜åŒ–æ½œåŠ›")
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    latencies = await test_baseline_latency(1000)
    
    if not latencies:
        print("âŒ æµ‹è¯•å¤±è´¥: æ— æ³•è¿æ¥åˆ°äº¤æ˜“æ‰€æ¨¡æ‹Ÿå™¨")
        print("è¯·ç¡®ä¿è¿è¡Œ: python3 exchange_simulator.py")
        return
    
    # åˆ†æç»“æœ
    stats = analyze_results(latencies)
    
    # æ‰“å°è¯¦ç»†åˆ†æ
    print_optimization_analysis(stats)

if __name__ == "__main__":
    asyncio.run(main())