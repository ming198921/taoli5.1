#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
QingXi V5.1 æ•°æ®æŸ¥çœ‹å™¨
ğŸ§¹ V3+O1 æ¸…æ´—åæ•°æ®æŸ¥çœ‹å·¥å…·

åŠŸèƒ½:
- æŸ¥çœ‹L2æ¸…æ´—åæ•°æ® (cache/l2_cleaned_data/)
- æŸ¥çœ‹L3æœ€ç»ˆå¤„ç†æ•°æ® (cache/l3_processed_data/)
- æ•°æ®ç»Ÿè®¡åˆ†æ
- å®æ—¶æ•°æ®ç›‘æ§
"""

import os
import json
import pickle
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import argparse

class QingXiDataViewer:
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.l2_cache_dir = self.base_path / "cache" / "l2_cleaned_data"
        self.l3_cache_dir = self.base_path / "cache" / "l3_processed_data"
        self.log_dir = self.base_path / "logs" / "cache"
        
    def print_status(self, message: str, status: str = "INFO"):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        status_emoji = {
            "INFO": "â„¹ï¸",
            "SUCCESS": "âœ…", 
            "ERROR": "âŒ",
            "WARNING": "âš ï¸",
            "DATA": "ğŸ“Š"
        }
        print(f"[{timestamp}] {status_emoji.get(status, 'â„¹ï¸')} {message}")

    def scan_cache_directories(self):
        """æ‰«æç¼“å­˜ç›®å½•"""
        print("\n" + "="*80)
        print("ğŸ§¹ QingXi V5.1 æ•°æ®å­˜å‚¨ä½ç½®æŠ¥å‘Š")
        print("="*80)
        
        # L2 æ¸…æ´—åæ•°æ®ç›®å½•
        if self.l2_cache_dir.exists():
            l2_files = list(self.l2_cache_dir.glob("*.cache"))
            self.print_status(f"L2æ¸…æ´—åæ•°æ®ç›®å½•: {self.l2_cache_dir}", "SUCCESS")
            self.print_status(f"L2ç¼“å­˜æ–‡ä»¶æ•°é‡: {len(l2_files)}", "DATA")
            
            if l2_files:
                # æ˜¾ç¤ºæœ€æ–°çš„å‡ ä¸ªæ–‡ä»¶
                l2_files_sorted = sorted(l2_files, key=lambda x: x.stat().st_mtime, reverse=True)
                self.print_status("æœ€æ–°çš„L2æ¸…æ´—æ•°æ®æ–‡ä»¶:", "DATA")
                for i, file in enumerate(l2_files_sorted[:5]):
                    mtime = datetime.fromtimestamp(file.stat().st_mtime)
                    size = file.stat().st_size
                    print(f"   {i+1}. {file.name} ({size} bytes, {mtime})")
        else:
            self.print_status(f"L2æ¸…æ´—åæ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.l2_cache_dir}", "WARNING")
            
        # L3 æœ€ç»ˆå¤„ç†æ•°æ®ç›®å½•
        if self.l3_cache_dir.exists():
            l3_files = list(self.l3_cache_dir.glob("*.cache"))
            self.print_status(f"L3æœ€ç»ˆå¤„ç†æ•°æ®ç›®å½•: {self.l3_cache_dir}", "SUCCESS")
            self.print_status(f"L3ç¼“å­˜æ–‡ä»¶æ•°é‡: {len(l3_files)}", "DATA")
            
            if l3_files:
                # æ˜¾ç¤ºæœ€æ–°çš„å‡ ä¸ªæ–‡ä»¶
                l3_files_sorted = sorted(l3_files, key=lambda x: x.stat().st_mtime, reverse=True)
                self.print_status("æœ€æ–°çš„L3å¤„ç†æ•°æ®æ–‡ä»¶:", "DATA")
                for i, file in enumerate(l3_files_sorted[:5]):
                    mtime = datetime.fromtimestamp(file.stat().st_mtime)
                    size = file.stat().st_size
                    print(f"   {i+1}. {file.name} ({size} bytes, {mtime})")
        else:
            self.print_status(f"L3æœ€ç»ˆå¤„ç†æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.l3_cache_dir}", "WARNING")
            
        # æ—¥å¿—ç›®å½•
        if self.log_dir.exists():
            log_files = list(self.log_dir.glob("*.log"))
            self.print_status(f"ç¼“å­˜æ—¥å¿—ç›®å½•: {self.log_dir}", "SUCCESS")
            self.print_status(f"æ—¥å¿—æ–‡ä»¶æ•°é‡: {len(log_files)}", "DATA")
        else:
            self.print_status(f"ç¼“å­˜æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {self.log_dir}", "WARNING")
            
        print("="*80)

    def analyze_cache_file(self, file_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ä¸ªç¼“å­˜æ–‡ä»¶"""
        try:
            with open(file_path, 'rb') as f:
                data = f.read()
                
            # å°è¯•ä¸åŒçš„ååºåˆ—åŒ–æ–¹æ³•
            try:
                # å…ˆå°è¯• bincode æ ¼å¼ (Ruståºåˆ—åŒ–)
                # è¿™é‡Œæˆ‘ä»¬åªèƒ½åˆ†ææ–‡ä»¶å¤§å°å’ŒåŸºæœ¬ä¿¡æ¯
                analysis = {
                    "file_name": file_path.name,
                    "file_size": len(data),
                    "creation_time": datetime.fromtimestamp(file_path.stat().st_ctime),
                    "modification_time": datetime.fromtimestamp(file_path.stat().st_mtime),
                    "data_format": "bincode (Rust)",
                    "raw_data_preview": data[:100].hex() if len(data) > 0 else "empty"
                }
                
                # å°è¯•æ£€æµ‹æ•°æ®ä¸­çš„äº¤æ˜“æ‰€å’Œäº¤æ˜“å¯¹ä¿¡æ¯
                data_str = data.decode('utf-8', errors='ignore')
                exchanges = []
                symbols = []
                
                # æ£€æµ‹å¸¸è§çš„äº¤æ˜“æ‰€åç§°
                for exchange in ['binance', 'okx', 'bybit', 'gateio']:
                    if exchange.lower() in data_str.lower():
                        exchanges.append(exchange)
                
                # æ£€æµ‹å¸¸è§çš„äº¤æ˜“å¯¹
                for symbol in ['BTC', 'ETH', 'USDT', 'ADA', 'XRP', 'SOL']:
                    if symbol in data_str:
                        symbols.append(symbol)
                
                analysis["detected_exchanges"] = exchanges
                analysis["detected_symbols"] = symbols
                
                return analysis
                
            except Exception as e:
                return {
                    "file_name": file_path.name,
                    "file_size": len(data),
                    "error": f"Failed to analyze: {str(e)}",
                    "data_format": "unknown"
                }
                
        except Exception as e:
            return {
                "file_name": file_path.name,
                "error": f"Failed to read file: {str(e)}"
            }

    def view_cache_data(self, cache_type: str = "l2"):
        """æŸ¥çœ‹ç¼“å­˜æ•°æ®è¯¦æƒ…"""
        cache_dir = self.l2_cache_dir if cache_type == "l2" else self.l3_cache_dir
        
        if not cache_dir.exists():
            self.print_status(f"{cache_type.upper()}ç¼“å­˜ç›®å½•ä¸å­˜åœ¨", "ERROR")
            return
            
        cache_files = list(cache_dir.glob("*.cache"))
        if not cache_files:
            self.print_status(f"{cache_type.upper()}ç¼“å­˜ç›®å½•ä¸ºç©º", "WARNING")
            return
            
        print(f"\nğŸ” {cache_type.upper()}ç¼“å­˜æ•°æ®è¯¦ç»†åˆ†æ")
        print("="*60)
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        cache_files_sorted = sorted(cache_files, key=lambda x: x.stat().st_mtime, reverse=True)
        
        total_size = 0
        exchange_stats = {}
        symbol_stats = {}
        
        for i, file_path in enumerate(cache_files_sorted[:10]):  # åªåˆ†ææœ€æ–°çš„10ä¸ªæ–‡ä»¶
            analysis = self.analyze_cache_file(file_path)
            total_size += analysis.get("file_size", 0)
            
            print(f"\nğŸ“„ æ–‡ä»¶ {i+1}: {analysis['file_name']}")
            print(f"   å¤§å°: {analysis.get('file_size', 0)} bytes")
            print(f"   ä¿®æ”¹æ—¶é—´: {analysis.get('modification_time', 'Unknown')}")
            print(f"   æ•°æ®æ ¼å¼: {analysis.get('data_format', 'Unknown')}")
            
            if 'detected_exchanges' in analysis:
                exchanges = analysis['detected_exchanges']
                symbols = analysis['detected_symbols']
                
                if exchanges:
                    print(f"   æ£€æµ‹åˆ°çš„äº¤æ˜“æ‰€: {', '.join(exchanges)}")
                    for exchange in exchanges:
                        exchange_stats[exchange] = exchange_stats.get(exchange, 0) + 1
                        
                if symbols:
                    print(f"   æ£€æµ‹åˆ°çš„äº¤æ˜“å¯¹: {', '.join(symbols)}")
                    for symbol in symbols:
                        symbol_stats[symbol] = symbol_stats.get(symbol, 0) + 1
            
            if 'error' in analysis:
                print(f"   âŒ é”™è¯¯: {analysis['error']}")
        
        # ç»Ÿè®¡æ‘˜è¦
        print(f"\nğŸ“Š {cache_type.upper()}ç¼“å­˜ç»Ÿè®¡æ‘˜è¦:")
        print(f"   æ€»æ–‡ä»¶æ•°: {len(cache_files)}")
        print(f"   æ€»å¤§å°: {total_size / 1024:.2f} KB")
        
        if exchange_stats:
            print(f"   äº¤æ˜“æ‰€åˆ†å¸ƒ: {dict(exchange_stats)}")
        if symbol_stats:
            print(f"   äº¤æ˜“å¯¹åˆ†å¸ƒ: {dict(symbol_stats)}")

    def monitor_data_flow(self, interval: int = 10):
        """ç›‘æ§æ•°æ®æµ"""
        self.print_status(f"å¼€å§‹ç›‘æ§æ•°æ®æµï¼Œæ£€æŸ¥é—´éš”: {interval}ç§’", "INFO")
        
        prev_l2_count = 0
        prev_l3_count = 0
        prev_l2_size = 0
        prev_l3_size = 0
        
        try:
            while True:
                # ç»Ÿè®¡L2æ•°æ®
                l2_files = list(self.l2_cache_dir.glob("*.cache")) if self.l2_cache_dir.exists() else []
                l2_count = len(l2_files)
                l2_size = sum(f.stat().st_size for f in l2_files)
                
                # ç»Ÿè®¡L3æ•°æ®
                l3_files = list(self.l3_cache_dir.glob("*.cache")) if self.l3_cache_dir.exists() else []
                l3_count = len(l3_files)
                l3_size = sum(f.stat().st_size for f in l3_files)
                
                # è®¡ç®—å˜åŒ–
                l2_count_delta = l2_count - prev_l2_count
                l3_count_delta = l3_count - prev_l3_count
                l2_size_delta = l2_size - prev_l2_size
                l3_size_delta = l3_size - prev_l3_size
                
                # æ˜¾ç¤ºçŠ¶æ€
                print(f"\nâ° {datetime.now().strftime('%H:%M:%S')} æ•°æ®æµç›‘æ§:")
                print(f"   L2æ¸…æ´—æ•°æ®: {l2_count}ä¸ªæ–‡ä»¶ ({l2_size/1024:.1f}KB) [+{l2_count_delta}æ–‡ä»¶, +{l2_size_delta/1024:.1f}KB]")
                print(f"   L3å¤„ç†æ•°æ®: {l3_count}ä¸ªæ–‡ä»¶ ({l3_size/1024:.1f}KB) [+{l3_count_delta}æ–‡ä»¶, +{l3_size_delta/1024:.1f}KB]")
                
                # æ›´æ–°å‰å€¼
                prev_l2_count = l2_count
                prev_l3_count = l3_count
                prev_l2_size = l2_size
                prev_l3_size = l3_size
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            self.print_status("æ•°æ®æµç›‘æ§å·²åœæ­¢", "INFO")

def main():
    parser = argparse.ArgumentParser(description="QingXi V5.1 æ•°æ®æŸ¥çœ‹å™¨")
    parser.add_argument("--path", default=".", help="QingXié¡¹ç›®æ ¹ç›®å½•è·¯å¾„")
    parser.add_argument("--action", choices=[
        "scan", "view-l2", "view-l3", "monitor"
    ], required=True, help="è¦æ‰§è¡Œçš„æ“ä½œ")
    parser.add_argument("--interval", type=int, default=10, help="ç›‘æ§æ¨¡å¼æ£€æŸ¥é—´éš”(ç§’)")
    
    args = parser.parse_args()
    
    viewer = QingXiDataViewer(args.path)
    
    if args.action == "scan":
        viewer.scan_cache_directories()
        
    elif args.action == "view-l2":
        viewer.view_cache_data("l2")
        
    elif args.action == "view-l3":
        viewer.view_cache_data("l3")
        
    elif args.action == "monitor":
        viewer.monitor_data_flow(args.interval)

if __name__ == "__main__":
    main() 