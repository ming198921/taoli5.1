#!/usr/bin/env python3
"""
é›¶åˆ†é…å¤±è´¥é—®é¢˜ä¸“é¡¹åˆ†æ
åˆ†æV3.0é›¶åˆ†é…éªŒè¯å¤±è´¥çš„æ¨¡å¼å’Œå½±å“
"""

import json
from datetime import datetime
from collections import defaultdict
import statistics

def parse_timestamp(timestamp_str):
    return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))

def main():
    print("ğŸ” V3.0é›¶åˆ†é…å¤±è´¥ä¸“é¡¹åˆ†æ")
    print("=" * 60)
    
    # æ”¶é›†ç›¸å…³äº‹ä»¶
    zero_alloc_failures = []
    cleaning_events = []
    performance_issues = []
    
    with open('qingxi_system_20250726_050553.log', 'r') as f:
        for line_num, line in enumerate(f, 1):
            try:
                data = json.loads(line.strip())
                timestamp = parse_timestamp(data['timestamp'])
                message = data['fields']['message']
                
                # é›¶åˆ†é…å¤±è´¥
                if "é›¶åˆ†é…éªŒè¯å¤±è´¥" in message:
                    zero_alloc_failures.append({
                        'timestamp': timestamp,
                        'line': line_num,
                        'thread': data.get('threadName', 'unknown')
                    })
                
                # æ¸…æ´—äº‹ä»¶
                elif "Data cleaning successful" in message:
                    cleaning_events.append({
                        'timestamp': timestamp,
                        'line': line_num
                    })
                
                # æ€§èƒ½ç›¸å…³è­¦å‘Š
                elif any(keyword in message for keyword in ["å›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•", "è¶…æ—¶", "å»¶è¿Ÿ", "æ€§èƒ½"]):
                    performance_issues.append({
                        'timestamp': timestamp,
                        'message': message,
                        'line': line_num
                    })
                    
            except (json.JSONDecodeError, KeyError):
                continue
    
    print(f"ğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"  é›¶åˆ†é…å¤±è´¥æ¬¡æ•°: {len(zero_alloc_failures)}")
    print(f"  æ¸…æ´—æˆåŠŸæ¬¡æ•°: {len(cleaning_events)}")
    print(f"  æ€§èƒ½é—®é¢˜æ¬¡æ•°: {len(performance_issues)}")
    
    # è®¡ç®—å¤±è´¥ç‡
    if cleaning_events:
        failure_rate = len(zero_alloc_failures) / len(cleaning_events) * 100
        print(f"  é›¶åˆ†é…å¤±è´¥ç‡: {failure_rate:.2f}%")
    
    # åˆ†æå¤±è´¥çš„æ—¶é—´æ¨¡å¼
    print(f"\nâ° é›¶åˆ†é…å¤±è´¥æ—¶é—´åˆ†æ:")
    print("-" * 40)
    
    if len(zero_alloc_failures) > 1:
        # è®¡ç®—å¤±è´¥é—´éš”
        intervals = []
        for i in range(1, len(zero_alloc_failures)):
            interval = (zero_alloc_failures[i]['timestamp'] - zero_alloc_failures[i-1]['timestamp']).total_seconds()
            intervals.append(interval)
        
        avg_interval = statistics.mean(intervals)
        min_interval = min(intervals)
        max_interval = max(intervals)
        
        print(f"  å¹³å‡å¤±è´¥é—´éš”: {avg_interval:.3f}ç§’")
        print(f"  æœ€å°å¤±è´¥é—´éš”: {min_interval:.3f}ç§’")
        print(f"  æœ€å¤§å¤±è´¥é—´éš”: {max_interval:.3f}ç§’")
        
        # åˆ†ææ˜¯å¦æœ‰é›†ä¸­çˆ†å‘
        burst_threshold = avg_interval / 10  # å¦‚æœé—´éš”å°äºå¹³å‡å€¼1/10ï¼Œè®¤ä¸ºæ˜¯çˆ†å‘
        bursts = [i for i in intervals if i < burst_threshold]
        print(f"  çˆ†å‘æ€§å¤±è´¥æ¬¡æ•°: {len(bursts)} ({len(bursts)/len(intervals)*100:.1f}%)")
    
    # åˆ†ææœ€åˆçš„å¤±è´¥æ¨¡å¼
    print(f"\nğŸš¨ æœ€åˆå¤±è´¥æ¨¡å¼åˆ†æ:")
    print("-" * 40)
    
    if zero_alloc_failures:
        first_10_failures = zero_alloc_failures[:10]
        print("å‰10æ¬¡å¤±è´¥æ—¶é—´:")
        start_time = zero_alloc_failures[0]['timestamp']
        
        for i, failure in enumerate(first_10_failures):
            relative_time = (failure['timestamp'] - start_time).total_seconds()
            print(f"  {i+1:2d}. +{relative_time:8.3f}s (è¡Œ {failure['line']})")
    
    # åˆ†æå¤±è´¥å¯¹æ¸…æ´—æ€§èƒ½çš„å½±å“
    print(f"\nğŸ“ˆ é›¶åˆ†é…å¤±è´¥å¯¹æ€§èƒ½çš„å½±å“åˆ†æ:")
    print("-" * 50)
    
    # åŒ¹é…å¤±è´¥äº‹ä»¶å’Œæ¸…æ´—æˆåŠŸäº‹ä»¶
    failure_impact_times = []
    
    for failure in zero_alloc_failures:
        # æ‰¾åˆ°è¿™æ¬¡å¤±è´¥åæœ€è¿‘çš„æ¸…æ´—æˆåŠŸäº‹ä»¶
        for cleaning in cleaning_events:
            if (cleaning['timestamp'] > failure['timestamp'] and 
                (cleaning['timestamp'] - failure['timestamp']).total_seconds() < 0.1):  # 100mså†…
                
                impact_time = (cleaning['timestamp'] - failure['timestamp']).total_seconds() * 1000  # ms
                failure_impact_times.append(impact_time)
                break
    
    if failure_impact_times:
        avg_impact = statistics.mean(failure_impact_times)
        max_impact = max(failure_impact_times)
        min_impact = min(failure_impact_times)
        
        print(f"  å¤±è´¥åæ¢å¤æ—¶é—´ç»Ÿè®¡ ({len(failure_impact_times)}ä¸ªæ ·æœ¬):")
        print(f"    å¹³å‡æ¢å¤æ—¶é—´: {avg_impact:.3f}ms")
        print(f"    æœ€é•¿æ¢å¤æ—¶é—´: {max_impact:.3f}ms")
        print(f"    æœ€çŸ­æ¢å¤æ—¶é—´: {min_impact:.3f}ms")
    
    # åˆ†ææŒ‰å°æ—¶çš„å¤±è´¥åˆ†å¸ƒ
    print(f"\nğŸ“… å¤±è´¥æ—¶é—´åˆ†å¸ƒåˆ†æ:")
    print("-" * 30)
    
    hourly_failures = defaultdict(int)
    for failure in zero_alloc_failures:
        hour_minute = failure['timestamp'].strftime('%H:%M')
        minute_key = hour_minute[:-1] + '0'  # æŒ‰10åˆ†é’Ÿåˆ†ç»„
        hourly_failures[minute_key] += 1
    
    print("æ¯10åˆ†é’Ÿå¤±è´¥æ¬¡æ•°:")
    for time_slot in sorted(hourly_failures.keys()):
        count = hourly_failures[time_slot]
        bar = "â–ˆ" * (count // 5) + "â–Œ" * (1 if count % 5 >= 3 else 0)
        print(f"  {time_slot}: {count:3d} {bar}")
    
    # é—®é¢˜æ ¹æœ¬åŸå› åˆ†æ
    print(f"\nğŸ”§ é—®é¢˜æ ¹æœ¬åŸå› åˆ†æ:")
    print("-" * 30)
    print("åŸºäºæ—¥å¿—åˆ†æï¼Œé›¶åˆ†é…å¤±è´¥çš„å¯èƒ½åŸå› :")
    print("1. å†…å­˜æ± ä¸è¶³ - é«˜å¹¶å‘æ—¶65536ç¼“å†²åŒºå¯èƒ½ä¸å¤Ÿ")
    print("2. çº¿ç¨‹ç«äº‰ - å¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®é›¶åˆ†é…å™¨")
    print("3. å†…å­˜ç¢ç‰‡ - é•¿æ—¶é—´è¿è¡Œåå†…å­˜ç¢ç‰‡å½±å“åˆ†é…")
    print("4. GCå‹åŠ› - Rustçš„Dropå®ç°å¯èƒ½å½±å“é›¶åˆ†é…")
    print("5. CPUç¼“å­˜å¤±æ•ˆ - é«˜é¢‘æ“ä½œå¯¼è‡´ç¼“å­˜æœªå‘½ä¸­")
    
    print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    print("-" * 15)
    print("1. å¢åŠ é›¶åˆ†é…ç¼“å†²åŒºå¤§å° (65536 -> 131072)")
    print("2. å®ç°per-threadçš„é›¶åˆ†é…æ± ")
    print("3. æ·»åŠ å†…å­˜é¢„çƒ­æœºåˆ¶")
    print("4. ä¼˜åŒ–å†…å­˜å¯¹é½å’Œç¼“å­˜å‹å¥½æ€§")
    print("5. å®ç°å¤±è´¥å›é€€çš„ä¼˜é›…é™çº§")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³çš„ç¯å¢ƒå˜é‡æœªè®¾ç½®
    print(f"\nğŸ” ç¯å¢ƒé…ç½®æ£€æŸ¥:")
    print("-" * 20)
    print("ç¡®ä¿ä»¥ä¸‹ç¯å¢ƒå˜é‡å·²æ­£ç¡®è®¾ç½®:")
    print("- QINGXI_ZERO_ALLOCATION=true")
    print("- QINGXI_ENABLE_V3_OPTIMIZATIONS=true")
    print("- QINGXI_INTEL_OPTIMIZATIONS=true")
    print("- å†…å­˜æ± å¤§å°é…ç½®")

if __name__ == "__main__":
    main()
