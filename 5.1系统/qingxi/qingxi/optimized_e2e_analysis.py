#!/usr/bin/env python3
import json
import re
from collections import defaultdict
from datetime import datetime

def parse_timestamp(timestamp_str):
    # Parse timestamp: 2025-07-26T05:06:03.835445Z
    return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))

def extract_symbol_exchange(message):
    # Extract symbol and exchange from message
    if "Received OrderBook" in message and " from " in message:
        # Extract symbol and exchange from received message
        match = re.search(r'for ([A-Z]+/[A-Z]+) from (\w+)', message)
        if match:
            return match.group(1), match.group(2)  # symbol, exchange
    
    if "Data cleaning successful for" in message:
        # Extract exchange from cleaning message
        match = re.search(r'successful for (\w+)', message)
        if match:
            return None, match.group(1)  # None for symbol, exchange
    
    return None, None

def main():
    print("ğŸ” å¼€å§‹ç«¯åˆ°ç«¯å¤„ç†æ—¶é—´åˆ†æ...")
    
    # Group events by exchange for faster matching
    reception_by_exchange = defaultdict(list)
    cleaning_by_exchange = defaultdict(list)
    
    print("ğŸ“– è¯»å–æ—¥å¿—æ–‡ä»¶...")
    with open('qingxi_system_20250726_050553.log', 'r') as f:
        for line_num, line in enumerate(f, 1):
            if line_num % 100000 == 0:
                print(f"  å¤„ç†äº† {line_num} è¡Œ...")
            
            try:
                data = json.loads(line.strip())
                timestamp = parse_timestamp(data['timestamp'])
                message = data['fields']['message']
                
                # Collect reception events
                if "ğŸ“Š Received OrderBook" in message and " from " in message:
                    symbol, exchange = extract_symbol_exchange(message)
                    if symbol and exchange:
                        reception_by_exchange[exchange].append({
                            'timestamp': timestamp,
                            'symbol': symbol,
                            'line_num': line_num
                        })
                
                # Collect cleaning events
                elif "âœ… Data cleaning successful for" in message:
                    symbol, exchange = extract_symbol_exchange(message)
                    if exchange:
                        cleaning_by_exchange[exchange].append({
                            'timestamp': timestamp,
                            'line_num': line_num
                        })
                
            except (json.JSONDecodeError, KeyError) as e:
                continue
    
    total_receptions = sum(len(events) for events in reception_by_exchange.values())
    total_cleanings = sum(len(events) for events in cleaning_by_exchange.values())
    
    print(f"ğŸ“¥ æ‰¾åˆ° {total_receptions} ä¸ªæ•°æ®æ¥æ”¶äº‹ä»¶")
    print(f"ğŸ§¹ æ‰¾åˆ° {total_cleanings} ä¸ªæ¸…æ´—å®Œæˆäº‹ä»¶")
    
    # Match reception with cleaning events efficiently
    e2e_times = []
    
    for exchange in reception_by_exchange:
        if exchange not in cleaning_by_exchange:
            continue
            
        receptions = reception_by_exchange[exchange]
        cleanings = cleaning_by_exchange[exchange]
        
        print(f"ğŸ”„ å¤„ç†äº¤æ˜“æ‰€ {exchange}: {len(receptions)} æ¥æ”¶, {len(cleanings)} æ¸…æ´—")
        
        # Sort both lists by timestamp for efficient matching
        receptions.sort(key=lambda x: x['timestamp'])
        cleanings.sort(key=lambda x: x['timestamp'])
        
        cleaning_idx = 0
        
        for reception in receptions:
            # Find the first cleaning event after this reception
            while (cleaning_idx < len(cleanings) and 
                   cleanings[cleaning_idx]['timestamp'] < reception['timestamp']):
                cleaning_idx += 1
            
            if cleaning_idx < len(cleanings):
                cleaning = cleanings[cleaning_idx]
                time_diff = (cleaning['timestamp'] - reception['timestamp']).total_seconds()
                
                if time_diff <= 1.0:  # Within 1 second
                    e2e_times.append({
                        'symbol': reception['symbol'],
                        'exchange': exchange,
                        'reception_time': reception['timestamp'],
                        'cleaning_time': cleaning['timestamp'],
                        'processing_time_ms': time_diff * 1000,
                        'reception_line': reception['line_num'],
                        'cleaning_line': cleaning['line_num']
                    })
    
    print(f"\nâœ… æˆåŠŸåŒ¹é… {len(e2e_times)} ä¸ªç«¯åˆ°ç«¯å¤„ç†è®°å½•")
    
    if not e2e_times:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ç«¯åˆ°ç«¯è®°å½•")
        return
    
    # Group by symbol and exchange
    symbol_exchange_stats = defaultdict(list)
    for record in e2e_times:
        key = f"{record['symbol']}@{record['exchange']}"
        symbol_exchange_stats[key].append(record['processing_time_ms'])
    
    print("\nğŸ“Š æ¯ä¸ªå¸ç§æ¯ä¸€æ¡æ•°æ®ä»äº¤æ˜“æ‰€è·å–åˆ°æ¸…æ´—æˆåŠŸçš„æ—¶é—´ç»Ÿè®¡è¡¨:")
    print("=" * 90)
    print(f"{'å¸ç§@äº¤æ˜“æ‰€':<20} {'è®°å½•æ•°':<8} {'å¹³å‡æ—¶é—´(ms)':<12} {'æœ€å°å€¼(ms)':<12} {'æœ€å¤§å€¼(ms)':<12} {'æ ‡å‡†å·®(ms)':<12}")
    print("-" * 90)
    
    for key in sorted(symbol_exchange_stats.keys()):
        times = symbol_exchange_stats[key]
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        # Calculate standard deviation
        variance = sum((t - avg_time) ** 2 for t in times) / len(times)
        std_dev = variance ** 0.5
        
        print(f"{key:<20} {len(times):<8} {avg_time:<12.3f} {min_time:<12.3f} {max_time:<12.3f} {std_dev:<12.3f}")
    
    # Show some sample records
    print(f"\nğŸ“ æ ·æœ¬ç«¯åˆ°ç«¯å¤„ç†è®°å½• (å‰15æ¡):")
    print("=" * 100)
    print(f"{'å¸ç§@äº¤æ˜“æ‰€':<20} {'æ¥æ”¶æ—¶é—´':<26} {'æ¸…æ´—æ—¶é—´':<26} {'å¤„ç†æ—¶é—´(ms)':<12}")
    print("-" * 100)
    
    for i, record in enumerate(e2e_times[:15]):
        key = f"{record['symbol']}@{record['exchange']}"
        reception_str = record['reception_time'].strftime('%H:%M:%S.%f')[:-3]
        cleaning_str = record['cleaning_time'].strftime('%H:%M:%S.%f')[:-3]
        
        print(f"{key:<20} {reception_str:<26} {cleaning_str:<26} {record['processing_time_ms']:<12.3f}")
    
    # Analysis by exchange
    exchange_stats = defaultdict(list)
    for record in e2e_times:
        exchange_stats[record['exchange']].append(record['processing_time_ms'])
    
    print(f"\nğŸ“ˆ å„äº¤æ˜“æ‰€ç«¯åˆ°ç«¯å¤„ç†æ€§èƒ½å¯¹æ¯”:")
    print("=" * 70)
    print(f"{'äº¤æ˜“æ‰€':<10} {'è®°å½•æ•°':<8} {'å¹³å‡æ—¶é—´(ms)':<12} {'æœ€å°å€¼(ms)':<12} {'æœ€å¤§å€¼(ms)':<12}")
    print("-" * 70)
    
    for exchange in sorted(exchange_stats.keys()):
        times = exchange_stats[exchange]
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        print(f"{exchange:<10} {len(times):<8} {avg_time:<12.3f} {min_time:<12.3f} {max_time:<12.3f}")
    
    # Analysis of high processing times
    high_processing = [r for r in e2e_times if r['processing_time_ms'] > 5]
    if high_processing:
        print(f"\nâš ï¸  å¤„ç†æ—¶é—´è¶…è¿‡5msçš„è®°å½• ({len(high_processing)}æ¡):")
        print("-" * 80)
        for record in high_processing[:15]:  # Show first 15
            key = f"{record['symbol']}@{record['exchange']}"
            print(f"  {key}: {record['processing_time_ms']:.3f}ms")
    
    print(f"\nğŸ“ˆ æ€»è®¡åˆ†æäº† {len(e2e_times)} ä¸ªç«¯åˆ°ç«¯å¤„ç†è®°å½•")
    print(f"ğŸ“Š è¦†ç›–äº† {len(symbol_exchange_stats)} ä¸ªå¸ç§-äº¤æ˜“æ‰€ç»„åˆ")

if __name__ == "__main__":
    main()
