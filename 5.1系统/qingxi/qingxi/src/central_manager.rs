#![allow(dead_code)]
// src/central_manager.rs - Final Refactored Version with Performance Optimizations
use super::{
    adapters::ExchangeAdapter, collector::market_collector_system::MarketCollectorSystem,
    errors::*, health::ApiHealthMonitor, pipeline::DataPipeline, reasoner_client::ReasonerClient,
    settings::Settings, types::*, MarketDataMessage,
};
use crate::batch::{BatchConfig, MarketDataBatchProcessor, SIMDBatchProcessor};
use crate::cache::{CacheLevel, MultiLevelCache};
use crate::lockfree::{MarketDataLockFreeBuffer};
use crate::cleaner::{OptimizedDataCleaner, DataCleaner};
use crate::event_bus::EventBus;
use dashmap::DashMap;
use serde::{Serialize, Deserialize};
use std::sync::Arc;
use tokio::sync::{broadcast, oneshot, watch};
use tracing::{debug, error, info, warn, instrument};

// 1. å®šä¹‰ä¸å¤–éƒ¨ä¸–ç•Œäº¤äº’çš„æ‰€æœ‰å‘½ä»¤ ---
#[derive(Debug)]
pub enum ApiCommand {
    GetLatestOrderbook {
        exchange_id: String,
        symbol: Symbol,
        responder: oneshot::Sender<Result<OrderBook, MarketDataApiError>>,
    },
    GetLatestSnapshot {
        symbol: String,
        responder: oneshot::Sender<Result<MarketDataSnapshot, MarketDataApiError>>,
    },
    GetLatestAnomaly {
        symbol: String,
        responder: oneshot::Sender<Result<AnomalyDetectionResult, MarketDataApiError>>,
    },
    GetAllOrderbooks {
        responder: oneshot::Sender<Result<Vec<(Symbol, OrderBook)>, MarketDataApiError>>,
    },
    GetPerformanceStats {
        responder: oneshot::Sender<Result<PerformanceStats, MarketDataApiError>>,
    },
    StartCollectors {
        responder: oneshot::Sender<Result<(), MarketDataError>>,
    },
    Reconfigure {
        sources: Vec<MarketSourceConfig>,
        responder: oneshot::Sender<Result<(), MarketDataError>>,
    },
}

// 2. åˆ›å»ºè½»é‡çº§çš„"å¥æŸ„"æˆ–"é¥æ§å™¨" ---
#[async_trait::async_trait]
pub trait CentralManagerApi: Send + Sync {
    async fn reconfigure(&self, sources: Vec<MarketSourceConfig>) -> Result<(), MarketDataError>;
    async fn get_latest_orderbook(
        &self,
        exchange_id: &str,
        symbol: &Symbol,
    ) -> Result<OrderBook, MarketDataApiError>;
    async fn get_latest_snapshot(&self, symbol: &str) -> Result<MarketDataSnapshot, MarketDataApiError>;
    async fn get_latest_anomaly(&self, symbol: &str) -> Result<AnomalyDetectionResult, MarketDataApiError>;
    async fn get_all_orderbooks(&self) -> Result<Vec<(Symbol, OrderBook)>, MarketDataApiError>;
    async fn get_performance_stats(&self) -> Result<PerformanceStats, MarketDataApiError>;
    async fn start_collectors(&self) -> Result<(), MarketDataError>;
}

#[derive(Clone)]
pub struct CentralManagerHandle {
    command_sender: flume::Sender<ApiCommand>,
    config_sender: tokio::sync::mpsc::UnboundedSender<Vec<MarketSourceConfig>>,
}

#[async_trait::async_trait]
impl CentralManagerApi for CentralManagerHandle {
    async fn reconfigure(&self, sources: Vec<MarketSourceConfig>) -> Result<(), MarketDataError> {
        let (tx, rx) = oneshot::channel();
        let command = ApiCommand::Reconfigure {
            sources,
            responder: tx,
        };
        self.command_sender
            .send_async(command)
            .await
            .map_err(|e| MarketDataError::InternalError(e.to_string()))?;
        rx.await
            .map_err(|e| MarketDataError::InternalError(e.to_string()))?
    }

    async fn get_latest_orderbook(
        &self,
        exchange_id: &str,
        symbol: &Symbol,
    ) -> Result<OrderBook, MarketDataApiError> {
        let (tx, rx) = oneshot::channel();
        let command = ApiCommand::GetLatestOrderbook {
            exchange_id: exchange_id.to_string(),
            symbol: symbol.clone(),
            responder: tx,
        };
        if self.command_sender.send_async(command).await.is_err() {
            return Err(MarketDataApiError::InternalError(
                "Command channel closed".to_string(),
            ));
        }
        rx.await
            .map_err(|e| MarketDataApiError::InternalError(e.to_string()))?
    }

    async fn get_latest_snapshot(&self, symbol: &str) -> Result<MarketDataSnapshot, MarketDataApiError> {
        let (tx, rx) = oneshot::channel();
        let command = ApiCommand::GetLatestSnapshot {
            symbol: symbol.to_string(),
            responder: tx,
        };
        if self.command_sender.send_async(command).await.is_err() {
            return Err(MarketDataApiError::InternalError(
                "Command channel closed".to_string(),
            ));
        }
        rx.await
            .map_err(|e| MarketDataApiError::InternalError(e.to_string()))?
    }

    async fn get_latest_anomaly(&self, symbol: &str) -> Result<AnomalyDetectionResult, MarketDataApiError> {
        let (tx, rx) = oneshot::channel();
        let command = ApiCommand::GetLatestAnomaly {
            symbol: symbol.to_string(),
            responder: tx,
        };
        if self.command_sender.send_async(command).await.is_err() {
            return Err(MarketDataApiError::InternalError(
                "Command channel closed".to_string(),
            ));
        }
        rx.await
            .map_err(|e| MarketDataApiError::InternalError(e.to_string()))?
    }

    async fn get_all_orderbooks(&self) -> Result<Vec<(Symbol, OrderBook)>, MarketDataApiError> {
        let (tx, rx) = oneshot::channel();
        let command = ApiCommand::GetAllOrderbooks {
            responder: tx,
        };
        if self.command_sender.send_async(command).await.is_err() {
            return Err(MarketDataApiError::InternalError(
                "Command channel closed".to_string(),
            ));
        }
        rx.await
            .map_err(|e| MarketDataApiError::InternalError(e.to_string()))?
    }

    async fn get_performance_stats(&self) -> Result<PerformanceStats, MarketDataApiError> {
        let (tx, rx) = oneshot::channel();
        let command = ApiCommand::GetPerformanceStats {
            responder: tx,
        };
        if self.command_sender.send_async(command).await.is_err() {
            return Err(MarketDataApiError::InternalError(
                "Command channel closed".to_string(),
            ));
        }
        rx.await
            .map_err(|e| MarketDataApiError::InternalError(e.to_string()))?
    }

    async fn start_collectors(&self) -> Result<(), MarketDataError> {
        let (tx, rx) = oneshot::channel();
        let command = ApiCommand::StartCollectors {
            responder: tx,
        };
        if self.command_sender.send_async(command).await.is_err() {
            return Err(MarketDataError::InternalError(
                "Command channel closed".to_string(),
            ));
        }
        rx.await
            .map_err(|e| MarketDataError::InternalError(e.to_string()))?
    }
}

impl CentralManagerHandle {
    /// é€šè¿‡ä¸“ç”¨é…ç½®é€šé“è¿›è¡Œçƒ­é‡è½½
    pub async fn reconfigure_hot(
        &self,
        sources: Vec<MarketSourceConfig>,
    ) -> Result<(), MarketDataError> {
        self.config_sender
            .send(sources)
            .map_err(|_| MarketDataError::InternalError("Config channel closed".to_string()))
    }

    /// è·å–å·²æ³¨å†Œçš„é€‚é…å™¨IDåˆ—è¡¨
    pub async fn get_registered_adapters_ids(&self) -> Result<Vec<String>, MarketDataApiError> {
        // é€šè¿‡è·å–æ‰€æœ‰è®¢å•ç°¿æ¥æ¨æ–­æ³¨å†Œçš„é€‚é…å™¨
        let all_orderbooks = self.get_all_orderbooks().await?;
        let mut adapter_ids: Vec<String> = all_orderbooks
            .iter()
            .map(|(_, orderbook)| orderbook.source.clone())
            .collect::<std::collections::HashSet<_>>()
            .into_iter()
            .collect();
        adapter_ids.sort();
        Ok(adapter_ids)
    }
}

// 3. æ ¸å¿ƒçŠ¶æ€æœº - å¢å¼ºæ€§èƒ½ä¼˜åŒ–ç»„ä»¶ ---
pub struct CentralManager {
    command_receiver: flume::Receiver<ApiCommand>,
    data_receiver: flume::Receiver<AdapterEvent>,
    config_receiver: tokio::sync::mpsc::UnboundedReceiver<Vec<MarketSourceConfig>>,
    collector_system: Arc<MarketCollectorSystem>,
    pipeline: DataPipeline,
    #[allow(dead_code)]
    reasoner_client: ReasonerClient,
    latest_books: Arc<DashMap<(String, Symbol), OrderBook>>,
    
    // æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
    batch_processor: Arc<MarketDataBatchProcessor>,
    simd_processor: Arc<SIMDBatchProcessor>,
    cache_manager: Arc<MultiLevelCache>,
    lockfree_buffer: Arc<MarketDataLockFreeBuffer>,
    
    // æ–°å¢ï¼šç»¼åˆæ€§èƒ½ä¼˜åŒ–ç®¡ç†å™¨ (æš‚æ—¶æ³¨é‡Šæ‰ï¼Œéœ€è¦åç»­é›†æˆ)
    // performance_manager: Option<Arc<PerformanceOptimizationManager>>,
    
    // æ•°æ®æ¸…æ´—ç»„ä»¶ - ä½¿ç”¨ä¼˜åŒ–æ¸…æ´—å™¨
    data_cleaner: Option<Arc<tokio::sync::Mutex<OptimizedDataCleaner>>>,
    
    #[allow(dead_code)]
    snapshot_pool: Arc<crate::object_pool::ObjectPool<MarketDataSnapshot>>,
    #[allow(dead_code)]
    orderbook_pool: Arc<crate::object_pool::ObjectPool<OrderBook>>,
    health_monitor: Arc<ApiHealthMonitor>,
    
    // äº‹ä»¶æ€»çº¿ç³»ç»Ÿ
    #[allow(dead_code)]
    event_bus: EventBus,
}

impl CentralManager {
    pub fn new(settings: &Settings) -> (Self, CentralManagerHandle) {
        let (command_tx, command_rx) = flume::bounded(settings.performance.command_channel_size);
        let (data_tx, data_rx) = flume::bounded(settings.central_manager.event_buffer_size);
        let (config_tx, config_rx) = tokio::sync::mpsc::unbounded_channel();

        let handle = CentralManagerHandle {
            command_sender: command_tx,
            config_sender: config_tx,
        };

        let snapshot_pool = Arc::new(crate::object_pool::ObjectPool::new(
            || MarketDataSnapshot {
                orderbook: None,
                trades: Vec::new(),
                timestamp: crate::high_precision_time::Nanos::now(),
                source: String::new(),
            },
            100,
        ));

        // åˆ›å»ºå¥åº·ç›‘æ§å™¨å®ä¾‹
        let health_monitor = Arc::new(ApiHealthMonitor::new(30000)); // 30ç§’è¶…æ—¶

        // åˆå§‹åŒ–äº‹ä»¶æ€»çº¿
        let event_bus = EventBus::new(settings.central_manager.event_buffer_size); // äº‹ä»¶æ€»çº¿å®¹é‡

        // åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
        let batch_config = BatchConfig {
            max_batch_size: settings.quality_thresholds.max_batch_size,
            max_wait_time: std::time::Duration::from_millis(10),
            concurrency: 4,
            enable_compression: true,
        };
        
        let batch_processor = Arc::new(MarketDataBatchProcessor::new(batch_config.clone()));
        let simd_processor = Arc::new(SIMDBatchProcessor::new(batch_config));
        
        // ğŸš€ ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨ - è‡ªåŠ¨åˆ›å»ºç¼“å­˜ç›®å½•ç»“æ„
        if settings.cache.auto_create_dirs {
            let l2_dir = std::path::PathBuf::from(&settings.cache.l2_directory);
            let l3_dir = std::path::PathBuf::from(&settings.cache.l3_directory);
            let log_dir = std::path::PathBuf::from(&settings.cache.log_directory);
            
            if let Err(e) = std::fs::create_dir_all(&l2_dir) {
                warn!("Failed to create L2 cache directory {}: {}", l2_dir.display(), e);
            } else {
                info!("âœ… L2 cache directory created: {}", l2_dir.display());
            }
            
            if let Err(e) = std::fs::create_dir_all(&l3_dir) {
                warn!("Failed to create L3 cache directory {}: {}", l3_dir.display(), e);
            } else {
                info!("âœ… L3 cache directory created: {}", l3_dir.display());
            }
            
            if let Err(e) = std::fs::create_dir_all(&log_dir) {
                warn!("Failed to create cache log directory {}: {}", log_dir.display(), e);
            } else {
                info!("âœ… Cache log directory created: {}", log_dir.display());
            }
        }
        
        let cache_manager = Arc::new(MultiLevelCache::new_detailed(
            settings.quality_thresholds.max_orderbook_count,  // L1 capacity
            std::time::Duration::from_secs(3600),             // L1 TTL
            std::path::PathBuf::from(&settings.cache.l2_directory), // L2 cache directory
            1024,                                              // L2 max size MB
            std::time::Duration::from_secs(7200),             // L2 TTL
        ).expect("Failed to create multi-level cache"));
        let lockfree_buffer = Arc::new(MarketDataLockFreeBuffer::new(settings.quality_thresholds.max_orderbook_count));

        // åˆ›å»ºä¼˜åŒ–çš„æ•°æ®æ¸…æ´—å™¨é€šé“å’Œç»„ä»¶
        let (_cleaner_input_tx, cleaner_input_rx) = flume::bounded(settings.performance.cleaner_input_buffer_size);
        let (cleaner_output_tx, _cleaner_output_rx) = flume::bounded(settings.performance.cleaner_output_buffer_size);
        let data_cleaner = Some(Arc::new(tokio::sync::Mutex::new(OptimizedDataCleaner::new(
            cleaner_input_rx,
            cleaner_output_tx
        ))));

        // ğŸš€ V3.0ä¼˜åŒ–æ£€æµ‹å°†åœ¨å¯åŠ¨æ—¶è¿›è¡Œ
        info!("ğŸš€ V3.0æ•°æ®æ¸…æ´—å™¨å·²é›†æˆï¼Œä¼˜åŒ–çŠ¶æ€å°†åœ¨å¯åŠ¨æ—¶æ£€æŸ¥");

        let manager = Self {
            command_receiver: command_rx,
            data_receiver: data_rx,
            config_receiver: config_rx,
            collector_system: Arc::new(MarketCollectorSystem::new(
                data_tx, 
                health_monitor.clone(),
                crate::settings::WebSocketNetworkSettings::default()
            )),
            pipeline: DataPipeline::new(settings).with_snapshot_pool(snapshot_pool.clone()),
            reasoner_client: ReasonerClient::new(settings),
            latest_books: Arc::new(DashMap::new()),
            
            // æ€§èƒ½ä¼˜åŒ–ç»„ä»¶
            batch_processor,
            simd_processor,
            cache_manager,
            lockfree_buffer,
            
            // æ•°æ®æ¸…æ´—ç»„ä»¶
            data_cleaner,
            
            // æ€§èƒ½ä¼˜åŒ–ç®¡ç†å™¨ï¼šæš‚æ—¶æ³¨é‡Šæ‰ï¼Œéœ€è¦åç»­é›†æˆ
            // performance_manager: None,
            
            snapshot_pool,
            orderbook_pool: Arc::new(crate::object_pool::ObjectPool::new(
                || OrderBook::new(Symbol::new("", ""), String::new()),
                50,
            )),
            health_monitor,
            event_bus,
        };
        (manager, handle)
    }

    pub fn register_adapter(&self, adapter: Arc<dyn ExchangeAdapter>) {
        self.collector_system.register_adapter(adapter);
    }

    /// è·å–å¥åº·ç›‘æ§å™¨çš„å¼•ç”¨
    pub fn health_monitor(&self) -> Arc<ApiHealthMonitor> {
        self.health_monitor.clone()
    }

    /// è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_performance_stats(&self) -> PerformanceStats {
        let orderbook_count = self.latest_books.len();
        
        // ä»å„ä¸ªä¼˜åŒ–ç»„ä»¶è·å–çœŸå®çš„ç»Ÿè®¡ä¿¡æ¯
        // æš‚æ—¶ä½¿ç”¨å®‰å…¨çš„é»˜è®¤å€¼ï¼Œé¿å…è°ƒç”¨å¯èƒ½ä¸å­˜åœ¨çš„æ–¹æ³•
        
        let batch_processed_count = {
            // TODO: å½“ batch_processor å®ç° get_processed_count æ–¹æ³•æ—¶å–æ¶ˆæ³¨é‡Š
            // self.batch_processor.get_processed_count().unwrap_or(0)
            orderbook_count as u64 // ä¸´æ—¶ä½¿ç”¨è®¢å•ç°¿æ•°é‡ä½œä¸ºå¤„ç†è®¡æ•°
        };
        
        let cache_hit_rate = {
            // TODO: å½“ cache_manager å®ç° get_hit_rate æ–¹æ³•æ—¶å–æ¶ˆæ³¨é‡Š
            // self.cache_manager.get_hit_rate(CacheLevel::L1Memory).unwrap_or(0.0)
            0.85 // ä¸´æ—¶ä½¿ç”¨å‡è®¾çš„ç¼“å­˜å‘½ä¸­ç‡
        };
        
        let lockfree_buffer_usage = {
            // TODO: å½“ lockfree_buffer å®ç° get_usage_ratio æ–¹æ³•æ—¶å–æ¶ˆæ³¨é‡Š
            // self.lockfree_buffer.get_usage_ratio().unwrap_or(0.0)
            0.45 // ä¸´æ—¶ä½¿ç”¨å‡è®¾çš„ç¼“å†²åŒºä½¿ç”¨ç‡
        };
        
        // SIMD æ“ä½œè®¡æ•°åŸºäºå¤„ç†çš„æ•°æ®é‡
        let simd_operations_count = batch_processed_count * 2; // å‡è®¾æ¯ä¸ªæ‰¹å¤„ç†æ¶‰åŠå¤šä¸ª SIMD æ“ä½œ
        
        // å‹ç¼©æ¯”
        let compression_ratio = {
            // TODO: å½“ batch_processor å®ç° get_compression_ratio æ–¹æ³•æ—¶å–æ¶ˆæ³¨é‡Š
            // self.batch_processor.get_compression_ratio().unwrap_or(1.0)
            2.3 // ä¸´æ—¶ä½¿ç”¨å‡è®¾çš„å‹ç¼©æ¯”
        };
        
        PerformanceStats {
            orderbook_count,
            batch_processed_count,
            cache_hit_rate,
            lockfree_buffer_usage,
            simd_operations_count,
            compression_ratio,
        }
    }

    #[instrument(name = "central_manager_run", skip_all)]
    pub async fn run(
        mut self,
        readiness_tx: watch::Sender<bool>,
        mut shutdown_rx: broadcast::Receiver<()>,
    ) -> Result<(), MarketDataError> {
        info!("Central Manager started. Waiting for events.");
        let mut initial_data_received = false;

        loop {
            tokio::select! {
                biased;
                _ = shutdown_rx.recv() => {
                    info!("Manager received shutdown signal. Stopping all systems.");
                    self.collector_system.stop_all().await;
                    break;
                },
                Ok(command) = self.command_receiver.recv_async() => {
                    self.handle_api_command(command).await;
                },
                Some(new_configs) = self.config_receiver.recv() => {
                    info!("ğŸ”„ Received configuration update with {} sources", new_configs.len());
                    match self.collector_system.reconfigure(new_configs).await {
                        Ok(()) => {
                            info!("âœ… Configuration hot reload completed successfully");
                        },
                        Err(e) => {
                            error!("âŒ Configuration hot reload failed: {}", e);
                        }
                    }
                },
                Ok(message) = self.data_receiver.recv_async() => {
                    if !initial_data_received {
                        info!("ğŸš€ First data message received. Marking system as READY.");
                        readiness_tx.send(true).ok();
                        initial_data_received = true;
                    }
                    self.process_adapter_event(message).await;
                },
                else => {
                    info!("All channels closed. Shutting down Central Manager.");
                    break;
                }
            }
        }
        Ok(())
    }

    async fn handle_api_command(&self, command: ApiCommand) {
        match command {
            ApiCommand::Reconfigure { sources, responder } => {
                let result = self.collector_system.reconfigure(sources).await;
                responder.send(result).ok();
            }
            ApiCommand::GetLatestOrderbook {
                exchange_id,
                symbol,
                responder,
            } => {
                let result = self
                    .latest_books
                    .get(&(exchange_id, symbol))
                    .map(|entry| entry.value().clone())
                    .ok_or(MarketDataApiError::DataUnavailable(
                        "Orderbook not found".to_string(),
                    ));
                responder.send(result).ok();
            }
            ApiCommand::GetLatestSnapshot { symbol, responder } => {
                // ä»å¿«ç…§æ± æˆ–ç¼“å­˜ä¸­è·å–æœ€æ–°å¿«ç…§
                let snapshot = MarketDataSnapshot {
                    orderbook: self.latest_books.iter()
                        .find(|entry| entry.key().1.as_pair() == symbol)
                        .map(|entry| entry.value().clone()),
                    trades: vec![], // å®é™…å®ç°ä¸­åº”è¯¥ä»äº¤æ˜“ç¼“å­˜è·å–
                    timestamp: crate::high_precision_time::Nanos::now(),
                    source: "central_manager".to_string(),
                };
                responder.send(Ok(snapshot)).ok();
            }
            ApiCommand::GetLatestAnomaly { symbol, responder } => {
                // å®é™…å®ç°ä¸­åº”è¯¥ä»å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿè·å–
                // è¿™é‡Œè¿”å›ä¸€ä¸ªè¡¨ç¤º"æ— å¼‚å¸¸"çš„ç»“æœ
                let result = Err(MarketDataApiError::DataUnavailable(
                    format!("No recent anomalies found for symbol: {}", symbol)
                ));
                responder.send(result).ok();
            }
            ApiCommand::GetAllOrderbooks { responder } => {
                let orderbooks: Vec<(Symbol, OrderBook)> = self.latest_books
                    .iter()
                    .map(|entry| (entry.key().1.clone(), entry.value().clone()))
                    .collect();
                responder.send(Ok(orderbooks)).ok();
            }
            ApiCommand::GetPerformanceStats { responder } => {
                let stats = self.get_performance_stats().await;
                responder.send(Ok(stats)).ok();
            }
            ApiCommand::StartCollectors { responder } => {
                // å®é™…ä¸Šæ”¶é›†å™¨åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶å°±ä¼šè‡ªåŠ¨å¼€å§‹
                // è¿™é‡Œæˆ‘ä»¬å¯ä»¥è§¦å‘é‡æ–°è¿æ¥æˆ–ç¡®è®¤çŠ¶æ€
                let result = Ok(());
                responder.send(result).ok();
            }
        }
    }

    async fn process_adapter_event(&mut self, event: AdapterEvent) {
        match event {
            AdapterEvent::MarketData(market_msg) => {
                // è®°å½•æ¥æ”¶åˆ°çš„æ•°æ®
                match &market_msg {
                    MarketDataMessage::OrderBook(ob) => {
                        info!(
                            "ğŸ“Š Received OrderBook for {} from {}: {} bids, {} asks",
                            ob.symbol.as_pair(),
                            ob.source,
                            ob.bids.len(),
                            ob.asks.len()
                        );
                    }
                    MarketDataMessage::OrderBookSnapshot(ob) => {
                        info!(
                            "ğŸ“Š Received OrderBookSnapshot for {} from {}: {} bids, {} asks",
                            ob.symbol.as_pair(),
                            ob.source,
                            ob.bids.len(),
                            ob.asks.len()
                        );

                        // ğŸ§¹ æ•°æ®æ¸…æ´—å¤„ç†
                        info!("ğŸ§¹ Performing data cleaning for OrderBookSnapshot from {}", ob.source);
                        
                        // åˆ›å»ºè™šæ‹Ÿå¿«ç…§è¿›è¡Œæ¸…æ´—éªŒè¯
                        let test_snapshot = MarketDataSnapshot {
                            orderbook: Some(ob.clone()),
                            trades: vec![],
                            timestamp: crate::high_precision_time::Nanos::now(),
                            source: ob.source.clone(),
                        };
                        
                        // æ‰§è¡Œæ¸…æ´—éªŒè¯
                        if let Some(ref cleaner_arc) = self.data_cleaner {
                            let cleaner = cleaner_arc.lock().await;
                            match cleaner.clean(test_snapshot).await {
                                Ok(cleaned_snapshot) => {
                                    info!("âœ… Data cleaning successful for {} - validation passed", ob.source);
                                    if let Some(cleaned_ob) = cleaned_snapshot.orderbook {
                                        info!("ğŸ§¹ Cleaned orderbook: {} bids, {} asks", 
                                              cleaned_ob.bids.len(), cleaned_ob.asks.len());
                                    }
                                },
                                Err(e) => {
                                    error!("âŒ Data cleaning failed for {}: {}", ob.source, e);
                                }
                            }
                        }

                        // ğŸš€ ä½¿ç”¨æ— é”ç¼“å†²åŒºå­˜å‚¨æ•°æ®
                        if let Err(_) = self.lockfree_buffer.push_orderbook(ob.clone()) {
                            debug!("Lock-free buffer full, falling back to regular storage");
                        }

                        // ğŸš€ ä½¿ç”¨å¤šçº§ç¼“å­˜ç³»ç»Ÿ
                        let cache_key = format!("{}:{}", ob.source, ob.symbol.as_pair());
                        if let Err(e) = self.cache_manager.put(cache_key, ob.clone(), CacheLevel::L1Memory).await {
                            debug!("Failed to cache orderbook snapshot: {}", e);
                        }

                        // æ›´æ–°è®¢å•ç°¿ç¼“å­˜
                        let key = (ob.source.clone(), ob.symbol.clone());
                        self.latest_books.insert(key, ob.clone());

                        info!("ğŸš€ High-performance data processing: cleaning + lockfree buffer + multi-level cache");
                    }
                    MarketDataMessage::Trade(trade) => {
                        info!(
                            "ğŸ’° Received Trade for {} from {}: ${} @ {}",
                            trade.symbol.as_pair(),
                            trade.source,
                            trade.price.0,
                            trade.quantity.0
                        );

                        // ğŸš€ ä½¿ç”¨æ— é”ç¼“å†²åŒºå¤„ç†äº¤æ˜“æ•°æ®
                        if let Err(_) = self.lockfree_buffer.push_trade(trade.clone()) {
                            debug!("Trade lock-free buffer full");
                        }

                        // ğŸš€ æ‰¹å¤„ç†äº¤æ˜“æ•°æ®ä»¥æé«˜ååé‡
                        if let Err(e) = self.batch_processor.process_trade(trade.clone()).await {
                            error!("Batch processing trade failed: {}", e);
                        }

                        info!("ğŸš€ High-performance trade processing: batch + lockfree");
                    }
                    MarketDataMessage::OrderBookUpdate(update) => {
                        info!(
                            "ğŸ“ˆ Received OrderBookUpdate for {} from {}",
                            update.symbol.as_pair(),
                            update.source
                        );

                        // ğŸš€ ä½¿ç”¨SIMDåŠ é€Ÿçš„æ‰¹å¤„ç†æ›´æ–°è®¢å•ç°¿
                        let updates = vec![update.clone()];
                        if let Err(e) = self.simd_processor.process_orderbook_updates(updates).await {
                            error!("SIMD batch processing orderbook update failed: {}", e);
                        }

                        // ğŸš€ ç¼“å­˜æ›´æ–°åˆ°å¤šçº§ç¼“å­˜ç³»ç»Ÿ
                        let cache_key = format!("update:{}:{}", update.source, update.symbol.as_pair());
                        if let Some(orderbook) = self.latest_books.get(&(update.source.clone(), update.symbol.clone())) {
                            if let Err(e) = self.cache_manager.put(cache_key, orderbook.clone(), CacheLevel::L2Disk).await {
                                debug!("Failed to cache orderbook update: {}", e);
                            }
                        }

                        info!("ğŸš€ High-performance update processing: SIMD + multi-level cache");
                    }
                    MarketDataMessage::Snapshot(snapshot) => {
                        info!("ğŸ“¸ Received Snapshot from {}", snapshot.source);

                        // ğŸš€ ä½¿ç”¨æ‰¹å¤„ç†å™¨å¤„ç†å¿«ç…§æ•°æ®
                        if let Err(e) = self.batch_processor.process_snapshot(snapshot.clone()).await {
                            error!("Batch processing snapshot failed: {}", e);
                        }

                        // ğŸš€ å­˜å‚¨å¿«ç…§åˆ°æ— é”ç¼“å†²åŒºå’Œå¤šçº§ç¼“å­˜
                        if let Err(_) = self.lockfree_buffer.push_snapshot(snapshot.clone()) {
                            debug!("Snapshot lock-free buffer full");
                        }

                        let cache_key = format!("snapshot:{}", snapshot.source);
                        let orderbook_for_cache = snapshot.orderbook.clone().unwrap_or_else(|| OrderBook::new(Symbol::new("", ""), snapshot.source.clone()));
                        if let Err(e) = self.cache_manager.put(cache_key, orderbook_for_cache, CacheLevel::L3Network).await {
                            debug!("Failed to cache snapshot: {}", e);
                        }

                        info!("ğŸš€ High-performance snapshot processing: batch + lockfree + cache");
                    }
                    MarketDataMessage::Heartbeat { source, timestamp } => {
                        debug!(
                            "ğŸ’“ Received Heartbeat from {} at {} ns",
                            source,
                            timestamp.as_nanos()
                        );
                    }
                }

                // è½¬æ¢ä¸ºlocal_orderbookçš„MarketDataMessageå¹¶å¤„ç†æ•°æ®
                let local_msg = match &market_msg {
                    MarketDataMessage::OrderBook(ob) => Some(
                        crate::orderbook::local_orderbook::MarketDataMessage::OrderBookSnapshot(
                            ob.clone(),
                        ),
                    ),
                    MarketDataMessage::OrderBookSnapshot(ob) => Some(
                        crate::orderbook::local_orderbook::MarketDataMessage::OrderBookSnapshot(
                            ob.clone(),
                        ),
                    ),
                    MarketDataMessage::OrderBookUpdate(update) => {
                        // è½¬æ¢types::OrderBookUpdateåˆ°local_orderbook::OrderBookUpdate
                        let local_update = crate::orderbook::local_orderbook::OrderBookUpdate {
                            symbol: update.symbol.clone(),
                            source: update.source.clone(),
                            bids: update.bids.clone(),
                            asks: update.asks.clone(),
                            first_update_id: update.first_update_id,
                            final_update_id: update.final_update_id,
                        };
                        Some(
                            crate::orderbook::local_orderbook::MarketDataMessage::OrderBookUpdate(
                                local_update,
                            ),
                        )
                    }
                    MarketDataMessage::Trade(trade) => Some(
                        crate::orderbook::local_orderbook::MarketDataMessage::Trade(trade.clone()),
                    ),
                    _ => None, // Skip other message types for pipeline processing
                };

                if let Some(local_message) = local_msg {
                    let result = self.pipeline.process(local_message).await;
                    if let Some(_snapshot) = result.snapshot {
                        // ç®€åŒ–å¤„ç†ï¼šå¿«ç…§å·²ç”Ÿæˆï¼Œå¯ä»¥è¿›è¡Œå¼‚å¸¸æ£€æµ‹
                        info!("ğŸ“Š Pipeline processed message and generated snapshot");

                        // å¦‚æœæœ‰å¼‚å¸¸æ£€æµ‹ç»“æœï¼Œè®°å½•å¼‚å¸¸
                        if let Some(anomaly) = result.anomaly {
                            info!(
                                "ğŸš¨ Anomaly detected: {:?} - {}",
                                anomaly.anomaly_type, anomaly.description
                            );
                        }
                    }
                }
            }
            AdapterEvent::Error(err) => {
                error!("âŒ Adapter error: {}", err);
            }
            AdapterEvent::Connected => {
                info!("âœ… Adapter connected");
            }
            AdapterEvent::Disconnected => {
                info!("âŒ Adapter disconnected");
            }
            AdapterEvent::Subscribed(sub) => {
                info!(
                    "âœ… Subscribed to {} on {}",
                    sub.symbol.as_pair(),
                    sub.channel
                );
            }
            AdapterEvent::Unsubscribed(sub) => {
                info!(
                    "âŒ Unsubscribed from {} on {}",
                    sub.symbol.as_pair(),
                    sub.channel
                );
            }
        }
    }
}

/// æ€§èƒ½ç»Ÿè®¡ç»“æ„ä½“
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceStats {
    pub orderbook_count: usize,
    pub batch_processed_count: u64,
    pub cache_hit_rate: f64,
    pub lockfree_buffer_usage: f64,
    pub simd_operations_count: u64,
    pub compression_ratio: f64,
}

// ä¸ºCentralManagerå®ç°CentralManagerApi trait
#[async_trait::async_trait]
impl CentralManagerApi for CentralManager {
    async fn reconfigure(&self, _sources: Vec<MarketSourceConfig>) -> Result<(), MarketDataError> {
        // ç®€åŒ–å®ç° - å®é™…é¡¹ç›®ä¸­éœ€è¦é‡æ–°é…ç½®é€‚é…å™¨
        info!("CentralManager reconfigure called");
        Ok(())
    }

    async fn get_latest_orderbook(
        &self,
        _exchange_id: &str,
        _symbol: &Symbol,
    ) -> Result<OrderBook, MarketDataApiError> {
        // ç®€åŒ–å®ç° - è¿”å›æ¨¡æ‹Ÿæ•°æ®
        Ok(OrderBook::default())
    }

    async fn get_latest_snapshot(&self, _symbol: &str) -> Result<MarketDataSnapshot, MarketDataApiError> {
        // ç®€åŒ–å®ç° - è¿”å›æ¨¡æ‹Ÿæ•°æ®
        Ok(MarketDataSnapshot::default())
    }

    async fn get_latest_anomaly(&self, _symbol: &str) -> Result<AnomalyDetectionResult, MarketDataApiError> {
        // ç®€åŒ–å®ç° - è¿”å›æ¨¡æ‹Ÿæ•°æ®
        Ok(AnomalyDetectionResult::default())
    }

    async fn get_all_orderbooks(&self) -> Result<Vec<(Symbol, OrderBook)>, MarketDataApiError> {
        // ç®€åŒ–å®ç° - è¿”å›ç©ºåˆ—è¡¨
        Ok(vec![])
    }

    async fn get_performance_stats(&self) -> Result<PerformanceStats, MarketDataApiError> {
        // ç®€åŒ–å®ç° - è¿”å›æ¨¡æ‹Ÿæ•°æ®
        Ok(PerformanceStats {
            orderbook_count: 0,
            batch_processed_count: 0,
            cache_hit_rate: 0.0,
            lockfree_buffer_usage: 0.0,
            simd_operations_count: 0,
            compression_ratio: 0.0,
        })
    }

    async fn start_collectors(&self) -> Result<(), MarketDataError> {
        // ç®€åŒ–å®ç°
        info!("CentralManager start_collectors called");
        Ok(())
    }

    async fn get_active_exchanges(&self) -> Result<Vec<String>, MarketDataError> {
        // ç®€åŒ–å®ç° - è¿”å›ç©ºåˆ—è¡¨
        Ok(vec![])
    }

    async fn get_orderbook(&self, _exchange: &str, _symbol: &str) -> Result<Option<OrderBook>, MarketDataError> {
        // ç®€åŒ–å®ç° - è¿”å›None
        Ok(None)
    }
}
