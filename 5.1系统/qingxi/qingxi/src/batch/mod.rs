#![allow(dead_code)]
//! # æ‰¹å¤„ç†ä¼˜åŒ–æ¨¡å—
//!
//! æä¾›é«˜æ•ˆçš„æ‰¹é‡æ•°æ®å¤„ç†ï¼Œå‡å°‘ç³»ç»Ÿè°ƒç”¨å¼€é”€ï¼Œæé«˜ååé‡

use std::sync::Arc;
use std::time::{Duration, Instant};
use std::collections::VecDeque;
use tokio::sync::{Mutex, Notify};
use tokio::time::interval;
use tracing::{info, error, debug, instrument};

use crate::types::*;
use crate::OrderBookUpdate;
use crate::errors::MarketDataError;

/// æ‰¹å¤„ç†é…ç½®
#[derive(Debug, Clone)]
pub struct BatchConfig {
    /// æœ€å¤§æ‰¹æ¬¡å¤§å°
    pub max_batch_size: usize,
    /// æœ€å¤§ç­‰å¾…æ—¶é—´
    pub max_wait_time: Duration,
    /// å¹¶å‘å¤„ç†æ•°
    pub concurrency: usize,
    /// æ˜¯å¦å¯ç”¨å‹ç¼©
    pub enable_compression: bool,
}

impl Default for BatchConfig {
    fn default() -> Self {
        let (max_batch_size, max_wait_time_ms, concurrency, enable_compression) = 
            if let Ok(settings) = crate::settings::Settings::load() {
                (
                    settings.batch.max_batch_size,
                    settings.batch.max_wait_time_ms,
                    settings.batch.concurrency,
                    settings.batch.enable_compression
                )
            } else {
                (1000, 10, 4, false)
            };
            
        Self {
            max_batch_size,
            max_wait_time: Duration::from_millis(max_wait_time_ms),
            concurrency,
            enable_compression,
        }
    }
}

/// æ‰¹å¤„ç†é¡¹
#[derive(Debug, Clone)]
pub struct BatchItem<T> {
    pub data: T,
    pub timestamp: Instant,
    pub priority: u8,
}

impl<T> BatchItem<T> {
    pub fn new(data: T) -> Self {
        Self {
            data,
            timestamp: Instant::now(),
            priority: 0,
        }
    }

    pub fn with_priority(mut self, priority: u8) -> Self {
        self.priority = priority;
        self
    }
}

/// æ‰¹å¤„ç†å™¨ç‰¹æ€§
#[async_trait::async_trait]
pub trait BatchProcessor<T, R>: Send + Sync {
    /// å¤„ç†æ‰¹æ¬¡æ•°æ®
    async fn process_batch(&self, batch: Vec<BatchItem<T>>) -> Result<Vec<R>, MarketDataError>;
    
    /// è·å–æ‰¹æ¬¡å¤„ç†ç»Ÿè®¡
    fn stats(&self) -> BatchProcessorStats;
}

/// é€šç”¨æ‰¹å¤„ç†å™¨
pub struct GenericBatchProcessor<T, R, F> 
where
    T: Send + Sync + 'static,
    R: Send + Sync + 'static,
    F: Fn(Vec<BatchItem<T>>) -> Result<Vec<R>, MarketDataError> + Send + Sync + 'static,
{
    processor_fn: Arc<F>,
    config: BatchConfig,
    input_queue: Arc<Mutex<VecDeque<BatchItem<T>>>>,
    notify: Arc<Notify>,
    stats: Arc<Mutex<BatchProcessorStats>>,
    _phantom: std::marker::PhantomData<R>,
}

impl<T, R, F> GenericBatchProcessor<T, R, F>
where
    T: Send + Sync + 'static,
    R: Send + Sync + 'static,
    F: Fn(Vec<BatchItem<T>>) -> Result<Vec<R>, MarketDataError> + Send + Sync + 'static,
{
    pub fn new(processor_fn: F, config: BatchConfig) -> Self {
        Self {
            processor_fn: Arc::new(processor_fn),
            config,
            input_queue: Arc::new(Mutex::new(VecDeque::new())),
            notify: Arc::new(Notify::new()),
            stats: Arc::new(Mutex::new(BatchProcessorStats::default())),
            _phantom: std::marker::PhantomData,
        }
    }

    /// æ·»åŠ æ•°æ®åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—
    #[instrument(skip(self, item))]
    pub async fn enqueue(&self, item: BatchItem<T>) -> Result<(), MarketDataError> {
        {
            let mut queue = self.input_queue.lock().await;
            queue.push_back(item);
            
            // æ›´æ–°ç»Ÿè®¡
            let mut stats = self.stats.lock().await;
            stats.items_queued += 1;
        }
        
        // é€šçŸ¥å¤„ç†å™¨
        self.notify.notify_one();
        Ok(())
    }

    /// å¯åŠ¨æ‰¹å¤„ç†å·¥ä½œçº¿ç¨‹
    pub fn start_processing(&self) -> Vec<tokio::task::JoinHandle<()>> {
        let mut handles = Vec::new();

        for worker_id in 0..self.config.concurrency {
            let queue = self.input_queue.clone();
            let notify = self.notify.clone();
            let processor_fn = self.processor_fn.clone();
            let config = self.config.clone();
            let stats = self.stats.clone();

            let handle = tokio::spawn(async move {
                info!("Batch processor worker {} started", worker_id);
                
                let mut interval = interval(config.max_wait_time);
                
                loop {
                    tokio::select! {
                        _ = notify.notified() => {
                            Self::process_available_batches(
                                &queue, 
                                &processor_fn, 
                                &config, 
                                &stats
                            ).await;
                        }
                        _ = interval.tick() => {
                            // å®šæœŸå¤„ç†ï¼Œå³ä½¿æ²¡æœ‰è¾¾åˆ°æ‰¹æ¬¡å¤§å°
                            Self::process_available_batches(
                                &queue, 
                                &processor_fn, 
                                &config, 
                                &stats
                            ).await;
                        }
                    }
                }
            });
            
            handles.push(handle);
        }

        handles
    }

    async fn process_available_batches(
        queue: &Arc<Mutex<VecDeque<BatchItem<T>>>>,
        processor_fn: &Arc<F>,
        config: &BatchConfig,
        stats: &Arc<Mutex<BatchProcessorStats>>,
    ) {
        loop {
            let batch = {
                let mut q = queue.lock().await;
                if q.is_empty() {
                    break;
                }

                let batch_size = std::cmp::min(config.max_batch_size, q.len());
                let mut batch = Vec::with_capacity(batch_size);
                
                for _ in 0..batch_size {
                    if let Some(item) = q.pop_front() {
                        batch.push(item);
                    }
                }
                
                batch
            };

            if batch.is_empty() {
                break;
            }

            let batch_start = Instant::now();
            let batch_size = batch.len();
            
            match processor_fn(batch) {
                Ok(_results) => {
                    let mut s = stats.lock().await;
                    s.batches_processed += 1;
                    s.items_processed += batch_size as u64;
                    s.total_processing_time += batch_start.elapsed();
                    
                    debug!("Processed batch of {} items in {:?}", batch_size, batch_start.elapsed());
                }
                Err(e) => {
                    let mut s = stats.lock().await;
                    s.processing_errors += 1;
                    error!("Batch processing failed: {}", e);
                }
            }
        }
    }
}

#[async_trait::async_trait]
impl<T, R, F> BatchProcessor<T, R> for GenericBatchProcessor<T, R, F>
where
    T: Send + Sync + 'static,
    R: Send + Sync + 'static,
    F: Fn(Vec<BatchItem<T>>) -> Result<Vec<R>, MarketDataError> + Send + Sync + 'static,
{
    async fn process_batch(&self, batch: Vec<BatchItem<T>>) -> Result<Vec<R>, MarketDataError> {
        (self.processor_fn)(batch)
    }

    fn stats(&self) -> BatchProcessorStats {
        // è¿™é‡Œéœ€è¦åŒæ­¥è®¿é—®ï¼Œä½†ä¸ºäº†ç®€åŒ–è¿”å›é»˜è®¤å€¼
        BatchProcessorStats::default()
    }
}

/// å¸‚åœºæ•°æ®æ‰¹å¤„ç†å™¨
pub struct MarketDataBatchProcessor {
    orderbook_processor: GenericBatchProcessor<OrderBook, (), Box<dyn Fn(Vec<BatchItem<OrderBook>>) -> Result<Vec<()>, MarketDataError> + Send + Sync>>,
    trade_processor: GenericBatchProcessor<TradeUpdate, (), Box<dyn Fn(Vec<BatchItem<TradeUpdate>>) -> Result<Vec<()>, MarketDataError> + Send + Sync>>,
    snapshot_processor: GenericBatchProcessor<MarketDataSnapshot, (), Box<dyn Fn(Vec<BatchItem<MarketDataSnapshot>>) -> Result<Vec<()>, MarketDataError> + Send + Sync>>,
}

impl MarketDataBatchProcessor {
    pub fn new(config: BatchConfig) -> Self {
        let orderbook_fn = Box::new(|batch: Vec<BatchItem<OrderBook>>| {
            // æ‰¹é‡å¤„ç†è®¢å•ç°¿æ•°æ®
            for item in batch {
                // è¿™é‡Œå¯ä»¥æ·»åŠ å…·ä½“çš„å¤„ç†é€»è¾‘
                debug!("Processing orderbook for {}", item.data.symbol.as_pair());
            }
            Ok(vec![(); 0])
        });

        let trade_fn = Box::new(|batch: Vec<BatchItem<TradeUpdate>>| {
            // æ‰¹é‡å¤„ç†äº¤æ˜“æ•°æ®
            for item in batch {
                debug!("Processing trade for {}", item.data.symbol.as_pair());
            }
            Ok(vec![(); 0])
        });

        let snapshot_fn = Box::new(|batch: Vec<BatchItem<MarketDataSnapshot>>| {
            // æ‰¹é‡å¤„ç†å¿«ç…§æ•°æ®
            for item in batch {
                debug!("Processing snapshot from {}", item.data.source);
            }
            Ok(vec![(); 0])
        });

        Self {
            orderbook_processor: GenericBatchProcessor::new(orderbook_fn, config.clone()),
            trade_processor: GenericBatchProcessor::new(trade_fn, config.clone()),
            snapshot_processor: GenericBatchProcessor::new(snapshot_fn, config),
        }
    }

    pub async fn process_orderbook(&self, orderbook: OrderBook, priority: u8) -> Result<(), MarketDataError> {
        let item = BatchItem::new(orderbook).with_priority(priority);
        self.orderbook_processor.enqueue(item).await
    }

    pub async fn process_trade(&self, trade: TradeUpdate) -> Result<(), MarketDataError> {
        self.process_trade_with_priority(trade, 0).await
    }

    pub async fn process_trade_with_priority(&self, trade: TradeUpdate, priority: u8) -> Result<(), MarketDataError> {
        let item = BatchItem::new(trade).with_priority(priority);
        self.trade_processor.enqueue(item).await
    }

    pub async fn process_snapshot(&self, snapshot: MarketDataSnapshot) -> Result<(), MarketDataError> {
        self.process_snapshot_with_priority(snapshot, 0).await
    }

    pub async fn process_snapshot_with_priority(&self, snapshot: MarketDataSnapshot, priority: u8) -> Result<(), MarketDataError> {
        let item = BatchItem::new(snapshot).with_priority(priority);
        self.snapshot_processor.enqueue(item).await
    }

    /// è·å–æ‰¹å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_stats(&self) -> MarketDataBatchStatsExtended {
        let stats = self.stats().await;
        MarketDataBatchStatsExtended {
            processed_count: stats.trade_stats.items_processed + stats.orderbook_stats.items_processed + stats.snapshot_stats.items_processed,
            simd_operations: stats.trade_stats.items_processed, // ç®€åŒ–ç»Ÿè®¡
            compression_ratio: 1.2, // æ¨¡æ‹Ÿå‹ç¼©æ¯”
            stats,
        }
    }

    /// å¯åŠ¨æ‰€æœ‰æ‰¹å¤„ç†å·¥ä½œçº¿ç¨‹
    pub fn start_all(&self) -> Vec<tokio::task::JoinHandle<()>> {
        let mut handles = Vec::new();
        
        handles.extend(self.orderbook_processor.start_processing());
        handles.extend(self.trade_processor.start_processing());
        handles.extend(self.snapshot_processor.start_processing());
        
        handles
    }

    pub async fn stats(&self) -> MarketDataBatchStats {
        MarketDataBatchStats {
            orderbook_stats: self.orderbook_processor.stats(),
            trade_stats: self.trade_processor.stats(),
            snapshot_stats: self.snapshot_processor.stats(),
        }
    }
}

/// SIMDä¼˜åŒ–çš„æ‰¹å¤„ç†å™¨
pub struct SIMDBatchProcessor {
    config: BatchConfig,
    price_buffer: Arc<Mutex<Vec<f64>>>,
    quantity_buffer: Arc<Mutex<Vec<f64>>>,
}

impl SIMDBatchProcessor {
    pub fn new(config: BatchConfig) -> Self {
        let max_batch_size = config.max_batch_size;
        let buffer_multiplier = if let Ok(settings) = crate::settings::Settings::load() {
            settings.batch.buffer_multiplier
        } else {
            10
        };
        
        Self {
            config,
            price_buffer: Arc::new(Mutex::new(Vec::with_capacity(max_batch_size))),
            quantity_buffer: Arc::new(Mutex::new(Vec::with_capacity(max_batch_size * buffer_multiplier))),
        }
    }

    #[instrument(skip(self, trades))]
    pub async fn process_trades_simd(&self, trades: Vec<TradeUpdate>) -> Result<TradeProcessingResult, MarketDataError> {
        if trades.is_empty() {
            return Ok(TradeProcessingResult::default());
        }

        let mut price_buffer = self.price_buffer.lock().await;
        let mut quantity_buffer = self.quantity_buffer.lock().await;
        
        price_buffer.clear();
        quantity_buffer.clear();
        
        // æå–ä»·æ ¼å’Œæ•°é‡æ•°æ®
        for trade in &trades {
            price_buffer.push(trade.price.0);
            quantity_buffer.push(trade.quantity.0);
        }

        // ä½¿ç”¨SIMDè¿›è¡Œæ‰¹é‡è®¡ç®—
        let result = self.compute_trade_statistics(&price_buffer, &quantity_buffer).await;
        
        debug!("Processed {} trades with SIMD optimization", trades.len());
        
        Ok(result)
    }

    async fn compute_trade_statistics(&self, prices: &[f64], quantities: &[f64]) -> TradeProcessingResult {
        // è¿™é‡Œå¯ä»¥ä½¿ç”¨SIMDæŒ‡ä»¤è¿›è¡Œä¼˜åŒ–è®¡ç®—
        // ä¸ºäº†ç®€åŒ–ï¼Œä½¿ç”¨æ ‡å‡†çš„ç»Ÿè®¡è®¡ç®—
        
        let total_volume: f64 = quantities.iter().sum();
        let max_price = prices.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
        let min_price = prices.iter().fold(f64::INFINITY, |a, &b| a.min(b));
        let avg_price = if !prices.is_empty() {
            prices.iter().sum::<f64>() / prices.len() as f64
        } else {
            0.0
        };

        // VWAP (Volume Weighted Average Price)
        let mut vwap = 0.0;
        if total_volume > 0.0 {
            let weighted_sum: f64 = prices.iter()
                .zip(quantities.iter())
                .map(|(p, q)| p * q)
                .sum();
            vwap = weighted_sum / total_volume;
        }

        TradeProcessingResult {
            total_volume,
            max_price,
            min_price,
            avg_price,
            vwap,
            trade_count: prices.len(),
        }
    }

    /// æ‰¹é‡å¤„ç†è®¢å•ç°¿æ•°æ®
    #[instrument(skip(self, orderbooks))]
    pub async fn process_orderbooks_batch(&self, orderbooks: Vec<OrderBook>) -> Result<OrderBookBatchResult, MarketDataError> {
        if orderbooks.is_empty() {
            return Ok(OrderBookBatchResult::default());
        }

        let mut total_bid_volume = 0.0;
        let mut total_ask_volume = 0.0;
        let mut spreads = Vec::new();

        let volume_top_count = if let Ok(settings) = crate::settings::Settings::load() {
            settings.cleaner.volume_top_count
        } else {
            10
        };

        for ob in &orderbooks {
            // è®¡ç®—ä¹°å–é‡ï¼Œä½¿ç”¨é…ç½®åŒ–çš„é¡¶éƒ¨è®¢å•æ•°é‡
            let bid_volume: f64 = ob.bids.iter().take(volume_top_count).map(|entry| entry.quantity.0).sum();
            let ask_volume: f64 = ob.asks.iter().take(volume_top_count).map(|entry| entry.quantity.0).sum();
            
            total_bid_volume += bid_volume;
            total_ask_volume += ask_volume;

            // è®¡ç®—ä»·å·®
            if let (Some(best_bid), Some(best_ask)) = (ob.best_bid(), ob.best_ask()) {
                let spread = (best_ask.price.0 - best_bid.price.0) / best_bid.price.0;
                spreads.push(spread);
            }
        }

        let avg_spread = if !spreads.is_empty() {
            spreads.iter().sum::<f64>() / spreads.len() as f64
        } else {
            0.0
        };

        Ok(OrderBookBatchResult {
            total_bid_volume,
            total_ask_volume,
            avg_spread,
            orderbook_count: orderbooks.len(),
        })
    }

    /// è·å–æ‰¹å¤„ç†é…ç½®
    pub fn get_config(&self) -> &BatchConfig {
        &self.config
    }

    /// æ£€æŸ¥ç¼“å†²åŒºæ˜¯å¦éœ€è¦å¤„ç† (è¿‘ä¼¼æ£€æŸ¥)
    pub fn should_process_batch(&self) -> bool {
        // ç”±äºè¿™æ˜¯ä¸ªåŒæ­¥æ–¹æ³•ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®å¼‚æ­¥Mutex
        // è¿™é‡Œè¿”å›ä¸€ä¸ªå¯å‘å¼ç»“æœï¼Œå®é™…æ£€æŸ¥éœ€è¦åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œ
        true // æ€»æ˜¯å»ºè®®æ£€æŸ¥ï¼Œå…·ä½“åˆ¤æ–­äº¤ç”±è°ƒç”¨è€…
    }

    /// å¤„ç†è®¢å•ç°¿æ›´æ–°çš„SIMDæ‰¹å¤„ç†
    #[instrument(skip(self, updates))]
    pub async fn process_orderbook_updates(&self, updates: Vec<OrderBookUpdate>) -> Result<(), MarketDataError> {
        if updates.is_empty() {
            return Ok(());
        }

        // æ‰¹é‡å¤„ç†è®¢å•ç°¿æ›´æ–°
        for update in &updates {
            debug!("SIMD processing orderbook update for {}", update.symbol.as_pair());
        }

        info!("ğŸ§® SIMD processed {} orderbook updates", updates.len());
        Ok(())
    }
}

#[derive(Debug, Clone, Default)]
pub struct BatchProcessorStats {
    pub items_queued: u64,
    pub items_processed: u64,
    pub batches_processed: u64,
    pub processing_errors: u64,
    pub total_processing_time: Duration,
}

impl BatchProcessorStats {
    pub fn avg_processing_time(&self) -> Duration {
        if self.batches_processed > 0 {
            self.total_processing_time / self.batches_processed as u32
        } else {
            Duration::ZERO
        }
    }

    pub fn throughput_per_second(&self) -> f64 {
        if self.total_processing_time.as_secs_f64() > 0.0 {
            self.items_processed as f64 / self.total_processing_time.as_secs_f64()
        } else {
            0.0
        }
    }
}

#[derive(Debug, Clone)]
pub struct MarketDataBatchStats {
    pub orderbook_stats: BatchProcessorStats,
    pub trade_stats: BatchProcessorStats,
    pub snapshot_stats: BatchProcessorStats,
}

/// æ‰©å±•çš„æ‰¹å¤„ç†ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct MarketDataBatchStatsExtended {
    pub processed_count: u64,
    pub simd_operations: u64,
    pub compression_ratio: f64,
    pub stats: MarketDataBatchStats,
}

#[derive(Debug, Clone, Default)]
pub struct TradeProcessingResult {
    pub total_volume: f64,
    pub max_price: f64,
    pub min_price: f64,
    pub avg_price: f64,
    pub vwap: f64,
    pub trade_count: usize,
}

#[derive(Debug, Clone, Default)]
pub struct OrderBookBatchResult {
    pub total_bid_volume: f64,
    pub total_ask_volume: f64,
    pub avg_spread: f64,
    pub orderbook_count: usize,
}
