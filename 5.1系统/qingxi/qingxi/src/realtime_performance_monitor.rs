#![allow(dead_code)]
//! # å®æ—¶æ€§èƒ½ç›‘æ§å’Œè‡ªè°ƒä¼˜æ¨¡å—
//! 
//! æä¾›å¾®ç§’çº§æ€§èƒ½ç›‘æ§å’ŒåŸºäºå®æ—¶æ•°æ®çš„è‡ªåŠ¨å‚æ•°è°ƒä¼˜
//! ä½¿ç”¨ RDTSC æŒ‡ä»¤è¿›è¡Œé«˜ç²¾åº¦è®¡æ—¶å’Œæ€§èƒ½åˆ†æ

use std::sync::atomic::{AtomicU64, AtomicUsize, AtomicU32, Ordering};
use std::sync::{Arc, Mutex, RwLock};
use std::collections::{HashMap, VecDeque};
use std::time::{Instant, Duration};
use crate::types::{Symbol, Price, Quantity, Timestamp};

/// é«˜ç²¾åº¦æ€§èƒ½è®¡æ•°å™¨ï¼Œä½¿ç”¨ CPU å‘¨æœŸæ•°
#[derive(Debug, Clone)]
pub struct PerformanceMetrics {
    /// æ€»å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰
    pub latency_us: f64,
    /// CPU å‘¨æœŸæ•°
    pub cpu_cycles: u64,
    /// å¤„ç†çš„æ¡ç›®æ•°é‡
    pub entries_processed: usize,
    /// å†…å­˜åˆ†é…æ¬¡æ•°
    pub allocations: u32,
    /// ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
    pub cache_misses: u32,
    /// åˆ†æ”¯é¢„æµ‹å¤±è´¥æ¬¡æ•°
    pub branch_mispredictions: u32,
    /// æ—¶é—´æˆ³
    pub timestamp: Instant,
}

impl Default for PerformanceMetrics {
    fn default() -> Self {
        Self {
            latency_us: 0.0,
            cpu_cycles: 0,
            entries_processed: 0,
            allocations: 0,
            cache_misses: 0,
            branch_mispredictions: 0,
            timestamp: Instant::now(),
        }
    }
}

/// å¾ªç¯ç¼“å†²åŒºï¼Œç”¨äºå­˜å‚¨æ€§èƒ½å†å²æ•°æ®
pub struct CircularBuffer<T> {
    buffer: Vec<T>,
    head: AtomicUsize,
    size: usize,
    initialized: AtomicUsize,
}

impl<T: Clone + Default> CircularBuffer<T> {
    /// åˆ›å»ºæŒ‡å®šå¤§å°çš„å¾ªç¯ç¼“å†²åŒº
    pub fn new(size: usize) -> Self {
        Self {
            buffer: vec![T::default(); size],
            head: AtomicUsize::new(0),
            size,
            initialized: AtomicUsize::new(0),
        }
    }

    /// æ·»åŠ æ–°çš„æ•°æ®ç‚¹
    pub fn push(&self, item: T) {
        let index = self.head.fetch_add(1, Ordering::Relaxed) % self.size;
        
        // ä½¿ç”¨ unsafe æ“ä½œæé«˜æ€§èƒ½ï¼Œå› ä¸ºæˆ‘ä»¬ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
        unsafe {
            let ptr = self.buffer.as_ptr().add(index) as *mut T;
            std::ptr::write(ptr, item);
        }
        
        // æ›´æ–°å·²åˆå§‹åŒ–çš„å…ƒç´ æ•°é‡
        let current_init = self.initialized.load(Ordering::Relaxed);
        if current_init < self.size {
            self.initialized.store((current_init + 1).min(self.size), Ordering::Relaxed);
        }
    }

    /// è·å–æœ€è¿‘çš„ N ä¸ªæ•°æ®ç‚¹çš„å¹³å‡å€¼
    pub fn recent_average(&self, count: usize) -> T 
    where T: std::ops::Add<Output = T> + std::ops::Div<f64, Output = T> + Copy {
        let initialized = self.initialized.load(Ordering::Relaxed);
        if initialized == 0 {
            return T::default();
        }

        let actual_count = count.min(initialized);
        let head = self.head.load(Ordering::Relaxed);
        
        let mut sum = T::default();
        for i in 0..actual_count {
            let index = (head + self.size - 1 - i) % self.size;
            unsafe {
                let item = std::ptr::read(self.buffer.as_ptr().add(index));
                sum = sum + item;
            }
        }
        
        sum / (actual_count as f64)
    }

    /// è·å–æœ€è¿‘çš„æ•°æ®ç‚¹
    pub fn get_recent(&self, count: usize) -> Vec<T> 
    where T: Clone {
        let initialized = self.initialized.load(Ordering::Relaxed);
        if initialized == 0 {
            return Vec::new();
        }

        let actual_count = count.min(initialized);
        let head = self.head.load(Ordering::Relaxed);
        let mut result = Vec::with_capacity(actual_count);
        
        for i in 0..actual_count {
            let index = (head + self.size - 1 - i) % self.size;
            unsafe {
                let item = std::ptr::read(self.buffer.as_ptr().add(index));
                result.push(item);
            }
        }
        
        result
    }
}

/// å®ç° PerformanceMetrics çš„æ•°å­¦è¿ç®—
impl std::ops::Add for PerformanceMetrics {
    type Output = Self;
    
    fn add(self, other: Self) -> Self {
        Self {
            latency_us: self.latency_us + other.latency_us,
            cpu_cycles: self.cpu_cycles + other.cpu_cycles,
            entries_processed: self.entries_processed + other.entries_processed,
            allocations: self.allocations + other.allocations,
            cache_misses: self.cache_misses + other.cache_misses,
            branch_mispredictions: self.branch_mispredictions + other.branch_mispredictions,
            timestamp: self.timestamp.max(other.timestamp),
        }
    }
}

impl std::ops::Div<f64> for PerformanceMetrics {
    type Output = Self;
    
    fn div(self, divisor: f64) -> Self {
        Self {
            latency_us: self.latency_us / divisor,
            cpu_cycles: (self.cpu_cycles as f64 / divisor) as u64,
            entries_processed: (self.entries_processed as f64 / divisor) as usize,
            allocations: (self.allocations as f64 / divisor) as u32,
            cache_misses: (self.cache_misses as f64 / divisor) as u32,
            branch_mispredictions: (self.branch_mispredictions as f64 / divisor) as u32,
            timestamp: self.timestamp,
        }
    }
}

impl Copy for PerformanceMetrics {}

/// è¶…é«˜ç²¾åº¦æ€§èƒ½ç›‘æ§å™¨
pub struct UltraPerformanceMonitor {
    /// æ€§èƒ½å†å²æ•°æ®ï¼ˆæœ€è¿‘ 1000 æ¬¡æµ‹é‡ï¼‰
    performance_history: CircularBuffer<PerformanceMetrics>,
    /// CPU é¢‘ç‡ï¼Œç”¨äºå‘¨æœŸæ•°åˆ°æ—¶é—´çš„è½¬æ¢
    cpu_frequency_hz: AtomicU64,
    /// åŸºå‡†å‘¨æœŸæ•°
    baseline_cycles: AtomicU64,
    /// ç›‘æ§ç»Ÿè®¡
    total_measurements: AtomicU64,
    /// å¼‚å¸¸æ£€æµ‹é˜ˆå€¼
    anomaly_threshold_multiplier: f64,
}

impl UltraPerformanceMonitor {
    /// åˆ›å»ºæ–°çš„æ€§èƒ½ç›‘æ§å™¨
    pub fn new() -> Result<Self, Box<dyn std::error::Error + Send + Sync>> {
        let monitor = Self {
            performance_history: CircularBuffer::new(1000),
            cpu_frequency_hz: AtomicU64::new(0),
            baseline_cycles: AtomicU64::new(0),
            total_measurements: AtomicU64::new(0),
            anomaly_threshold_multiplier: 3.0, // 3 å€æ ‡å‡†å·®ä½œä¸ºå¼‚å¸¸é˜ˆå€¼
        };

        // åˆå§‹åŒ– CPU é¢‘ç‡æ£€æµ‹
        monitor.detect_cpu_frequency()?;
        monitor.calibrate_baseline()?;

        Ok(monitor)
    }

    /// æ£€æµ‹ CPU é¢‘ç‡
    fn detect_cpu_frequency(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        #[cfg(target_arch = "x86_64")]
        {
            // å°è¯•ä» /proc/cpuinfo è¯»å– CPU é¢‘ç‡
            if let Ok(frequency) = Self::read_cpu_frequency_from_proc() {
                self.cpu_frequency_hz.store(frequency, Ordering::Relaxed);
                log::info!("Detected CPU frequency: {} MHz", frequency / 1_000_000);
                return Ok(());
            }

            // å¦‚æœæ— æ³•è¯»å–ï¼Œä½¿ç”¨ç»éªŒæµ‹é‡
            log::info!("Could not read CPU frequency from /proc/cpuinfo, using empirical measurement");
            let measured_freq = Self::measure_cpu_frequency()?;
            self.cpu_frequency_hz.store(measured_freq, Ordering::Relaxed);
            log::info!("Measured CPU frequency: {} MHz", measured_freq / 1_000_000);
        }

        #[cfg(not(target_arch = "x86_64"))]
        {
            // é x86_64 æ¶æ„çš„é»˜è®¤å€¼
            self.cpu_frequency_hz.store(2_400_000_000, Ordering::Relaxed); // å‡è®¾ 2.4GHz
            log::warn!("Using default CPU frequency assumption: 2.4 GHz");
        }

        Ok(())
    }

    /// ä» /proc/cpuinfo è¯»å– CPU é¢‘ç‡
    fn read_cpu_frequency_from_proc() -> Result<u64, Box<dyn std::error::Error + Send + Sync>> {
        let cpuinfo = std::fs::read_to_string("/proc/cpuinfo")?;
        
        for line in cpuinfo.lines() {
            if line.starts_with("cpu MHz") {
                if let Some(freq_str) = line.split(':').nth(1) {
                    let freq_mhz: f64 = freq_str.trim().parse()?;
                    return Ok((freq_mhz * 1_000_000.0) as u64);
                }
            }
        }
        
        Err("CPU frequency not found in /proc/cpuinfo".into())
    }

    /// ç»éªŒæµ‹é‡ CPU é¢‘ç‡
    fn measure_cpu_frequency() -> Result<u64, Box<dyn std::error::Error + Send + Sync>> {
        let start_time = Instant::now();
        let start_cycles = Self::get_cpu_cycles();
        
        // ç­‰å¾…ä¸€å®šæ—¶é—´è¿›è¡Œæµ‹é‡
        std::thread::sleep(Duration::from_millis(100));
        
        let end_cycles = Self::get_cpu_cycles();
        let end_time = Instant::now();
        
        let elapsed_seconds = end_time.duration_since(start_time).as_secs_f64();
        let cycles_diff = end_cycles.wrapping_sub(start_cycles);
        
        let frequency = (cycles_diff as f64) / elapsed_seconds;
        Ok(frequency as u64)
    }

    /// è·å– CPU å‘¨æœŸæ•°
    #[inline(always)]
    fn get_cpu_cycles() -> u64 {
        #[cfg(target_arch = "x86_64")]
        {
            unsafe { std::arch::x86_64::_rdtsc() }
        }
        
        #[cfg(not(target_arch = "x86_64"))]
        {
            // é x86_64 æ¶æ„çš„ fallback
            std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_nanos() as u64
        }
    }

    /// æ ¡å‡†åŸºå‡†æ€§èƒ½
    fn calibrate_baseline(&self) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
        log::info!("Calibrating performance baseline...");
        
        const CALIBRATION_ITERATIONS: usize = 1000;
        let mut total_cycles = 0u64;
        
        for _ in 0..CALIBRATION_ITERATIONS {
            let start = Self::get_cpu_cycles();
            
            // æ‰§è¡Œä¸€ä¸ªç®€å•çš„åŸºå‡†æ“ä½œ
            Self::benchmark_operation();
            
            let end = Self::get_cpu_cycles();
            total_cycles += end.wrapping_sub(start);
        }
        
        let baseline = total_cycles / (CALIBRATION_ITERATIONS as u64);
        self.baseline_cycles.store(baseline, Ordering::Relaxed);
        
        log::info!("Performance baseline calibrated: {} cycles", baseline);
        Ok(())
    }

    /// åŸºå‡†æ“ä½œï¼Œç”¨äºæ ¡å‡†
    #[inline(never)]
    fn benchmark_operation() {
        let mut sum = 0u64;
        for i in 0..100 {
            sum = sum.wrapping_add(i);
        }
        // é˜²æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–æ‰è®¡ç®—
        std::hint::black_box(sum);
    }

    /// è·Ÿè¸ªæ“ä½œæ€§èƒ½
    pub fn track_operation<F, T>(&self, operation: F) -> (T, PerformanceMetrics) 
    where F: FnOnce() -> T {
        let start_cycles = Self::get_cpu_cycles();
        let start_time = Instant::now();
        
        // æ‰§è¡Œæ“ä½œ
        let result = operation();
        
        let end_cycles = Self::get_cpu_cycles();
        let end_time = Instant::now();
        
        // è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        let elapsed_cycles = end_cycles.wrapping_sub(start_cycles);
        let elapsed_us = end_time.duration_since(start_time).as_micros() as f64;
        
        let metrics = PerformanceMetrics {
            latency_us: elapsed_us,
            cpu_cycles: elapsed_cycles,
            entries_processed: 1, // é»˜è®¤å€¼ï¼Œè°ƒç”¨è€…å¯ä»¥è¦†ç›–
            allocations: 0,       // éœ€è¦å¤–éƒ¨è®¡æ•°å™¨
            cache_misses: 0,      // éœ€è¦ç¡¬ä»¶è®¡æ•°å™¨
            branch_mispredictions: 0, // éœ€è¦ç¡¬ä»¶è®¡æ•°å™¨
            timestamp: end_time,
        };
        
        // è®°å½•åˆ°å†å²æ•°æ®
        self.performance_history.push(metrics);
        self.total_measurements.fetch_add(1, Ordering::Relaxed);
        
        (result, metrics)
    }

    /// è·å–æœ€è¿‘çš„å¹³å‡æ€§èƒ½
    pub fn get_recent_average(&self, sample_count: usize) -> PerformanceMetrics {
        self.performance_history.recent_average(sample_count)
    }

    /// è·å–æ€§èƒ½è¶‹åŠ¿åˆ†æ
    pub fn analyze_performance_trend(&self, window_size: usize) -> PerformanceTrend {
        let recent_metrics = self.performance_history.get_recent(window_size);
        
        if recent_metrics.len() < 2 {
            return PerformanceTrend::Stable;
        }
        
        // è®¡ç®—å»¶è¿Ÿè¶‹åŠ¿
        let first_half = &recent_metrics[recent_metrics.len()/2..];
        let second_half = &recent_metrics[..recent_metrics.len()/2];
        
        let first_avg = Self::calculate_average_latency(first_half);
        let second_avg = Self::calculate_average_latency(second_half);
        
        let change_ratio = (second_avg - first_avg) / first_avg;
        
        if change_ratio > 0.1 {
            PerformanceTrend::Degrading
        } else if change_ratio < -0.1 {
            PerformanceTrend::Improving
        } else {
            PerformanceTrend::Stable
        }
    }

    /// è®¡ç®—å¹³å‡å»¶è¿Ÿ
    fn calculate_average_latency(metrics: &[PerformanceMetrics]) -> f64 {
        if metrics.is_empty() {
            return 0.0;
        }
        
        let sum: f64 = metrics.iter().map(|m| m.latency_us).sum();
        sum / (metrics.len() as f64)
    }

    /// æ£€æµ‹æ€§èƒ½å¼‚å¸¸
    pub fn detect_anomalies(&self, window_size: usize) -> Vec<PerformanceAnomaly> {
        let recent_metrics = self.performance_history.get_recent(window_size);
        
        if recent_metrics.len() < 10 {
            return Vec::new(); // éœ€è¦è‡³å°‘ 10 ä¸ªæ ·æœ¬
        }
        
        let mut anomalies = Vec::new();
        
        // è®¡ç®—å»¶è¿Ÿçš„å¹³å‡å€¼å’Œæ ‡å‡†å·®
        let latencies: Vec<f64> = recent_metrics.iter().map(|m| m.latency_us).collect();
        let mean = latencies.iter().sum::<f64>() / (latencies.len() as f64);
        let variance = latencies.iter()
            .map(|&x| (x - mean).powi(2))
            .sum::<f64>() / (latencies.len() as f64);
        let std_dev = variance.sqrt();
        
        let threshold = mean + std_dev * self.anomaly_threshold_multiplier;
        
        // æ£€æŸ¥æ¯ä¸ªæ•°æ®ç‚¹
        for (i, &latency) in latencies.iter().enumerate() {
            if latency > threshold {
                anomalies.push(PerformanceAnomaly {
                    anomaly_type: AnomalyType::HighLatency,
                    severity: if latency > threshold * 2.0 { AnomalySeverity::Critical } else { AnomalySeverity::Warning },
                    value: latency,
                    threshold,
                    timestamp: recent_metrics[i].timestamp,
                    description: format!("Latency {:.2}Âµs exceeds threshold {:.2}Âµs", latency, threshold),
                });
            }
        }
        
        anomalies
    }

    /// å°† CPU å‘¨æœŸè½¬æ¢ä¸ºå¾®ç§’
    pub fn cycles_to_microseconds(&self, cycles: u64) -> f64 {
        let frequency = self.cpu_frequency_hz.load(Ordering::Relaxed);
        if frequency == 0 {
            return 0.0;
        }
        
        (cycles as f64) / (frequency as f64) * 1_000_000.0
    }

    /// è·å–ç›‘æ§ç»Ÿè®¡ä¿¡æ¯
    pub fn get_monitor_stats(&self) -> MonitorStats {
        let total = self.total_measurements.load(Ordering::Relaxed);
        let recent_avg = self.get_recent_average(100);
        let cpu_freq = self.cpu_frequency_hz.load(Ordering::Relaxed);
        let baseline = self.baseline_cycles.load(Ordering::Relaxed);
        
        MonitorStats {
            total_measurements: total,
            cpu_frequency_hz: cpu_freq,
            baseline_cycles: baseline,
            recent_average_latency_us: recent_avg.latency_us,
            recent_average_cycles: recent_avg.cpu_cycles,
        }
    }
}

/// æ€§èƒ½è¶‹åŠ¿æšä¸¾
#[derive(Debug, Clone, PartialEq)]
pub enum PerformanceTrend {
    Improving,
    Stable,
    Degrading,
}

/// æ€§èƒ½å¼‚å¸¸ç±»å‹
#[derive(Debug, Clone)]
pub enum AnomalyType {
    HighLatency,
    HighCycles,
    MemoryLeak,
    CacheThrashing,
}

/// å¼‚å¸¸ä¸¥é‡ç¨‹åº¦
#[derive(Debug, Clone)]
pub enum AnomalySeverity {
    Info,
    Warning,
    Critical,
}

/// æ€§èƒ½å¼‚å¸¸æè¿°
#[derive(Debug, Clone)]
pub struct PerformanceAnomaly {
    pub anomaly_type: AnomalyType,
    pub severity: AnomalySeverity,
    pub value: f64,
    pub threshold: f64,
    pub timestamp: Instant,
    pub description: String,
}

/// ç›‘æ§ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone)]
pub struct MonitorStats {
    pub total_measurements: u64,
    pub cpu_frequency_hz: u64,
    pub baseline_cycles: u64,
    pub recent_average_latency_us: f64,
    pub recent_average_cycles: u64,
}

/// å®æ—¶è‡ªè°ƒä¼˜å™¨
pub struct RealTimeAutoTuner {
    /// æ€§èƒ½ç›‘æ§å™¨å¼•ç”¨
    monitor: Arc<UltraPerformanceMonitor>,
    /// ä¼˜åŒ–å‚æ•°
    optimization_parameters: Arc<RwLock<OptimizationParameters>>,
    /// è°ƒä¼˜å†å²
    tuning_history: Arc<Mutex<VecDeque<TuningAction>>>,
    /// è°ƒä¼˜é—´éš”
    tuning_interval: Duration,
    /// æœ€åè°ƒä¼˜æ—¶é—´
    last_tuning: Arc<Mutex<Instant>>,
}

/// ä¼˜åŒ–å‚æ•°ç»“æ„
#[derive(Debug, Clone)]
pub struct OptimizationParameters {
    pub aggression_level: f64,        // 0.0 - 1.0
    pub accuracy_level: f64,          // 0.0 - 1.0
    pub batch_size: usize,
    pub prefetch_distance: usize,
    pub parallel_threads: usize,
    pub cache_size: usize,
    pub enable_simd: bool,
    pub enable_avx512: bool,
}

impl Default for OptimizationParameters {
    fn default() -> Self {
        Self {
            aggression_level: 0.5,
            accuracy_level: 0.8,
            batch_size: 128,
            prefetch_distance: 4,
            parallel_threads: 4,
            cache_size: 1024,
            enable_simd: true,
            enable_avx512: false,
        }
    }
}

/// è°ƒä¼˜åŠ¨ä½œè®°å½•
#[derive(Debug, Clone)]
pub struct TuningAction {
    pub timestamp: Instant,
    pub parameter_name: String,
    pub old_value: f64,
    pub new_value: f64,
    pub reason: String,
    pub performance_before: PerformanceMetrics,
    pub performance_after: Option<PerformanceMetrics>,
}

impl RealTimeAutoTuner {
    /// åˆ›å»ºæ–°çš„è‡ªè°ƒä¼˜å™¨
    pub fn new(monitor: Arc<UltraPerformanceMonitor>) -> Self {
        Self {
            monitor,
            optimization_parameters: Arc::new(RwLock::new(OptimizationParameters::default())),
            tuning_history: Arc::new(Mutex::new(VecDeque::with_capacity(1000))),
            tuning_interval: Duration::from_secs(30), // æ¯ 30 ç§’è°ƒä¼˜ä¸€æ¬¡
            last_tuning: Arc::new(Mutex::new(Instant::now())),
        }
    }

    /// æ‰§è¡Œè‡ªåŠ¨è°ƒä¼˜
    pub fn auto_tune(&self) -> Result<Vec<TuningAction>, Box<dyn std::error::Error + Send + Sync>> {
        let mut last_tuning = self.last_tuning.lock().map_err(|_| "Lock poisoned")?;
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒä¼˜
        if last_tuning.elapsed() < self.tuning_interval {
            return Ok(Vec::new());
        }
        
        *last_tuning = Instant::now();
        
        let recent_perf = self.monitor.get_recent_average(100);
        let trend = self.monitor.analyze_performance_trend(200);
        let anomalies = self.monitor.detect_anomalies(500);
        
        let mut actions = Vec::new();
        
        // åŸºäºæ€§èƒ½è¶‹åŠ¿è¿›è¡Œè°ƒä¼˜
        match trend {
            PerformanceTrend::Degrading => {
                actions.extend(self.handle_performance_degradation(&recent_perf)?);
            },
            PerformanceTrend::Improving => {
                actions.extend(self.handle_performance_improvement(&recent_perf)?);
            },
            PerformanceTrend::Stable => {
                // æ€§èƒ½ç¨³å®šæ—¶è¿›è¡Œå°å¹…ä¼˜åŒ–å®éªŒ
                actions.extend(self.handle_stable_performance(&recent_perf)?);
            }
        }
        
        // å¤„ç†å¼‚å¸¸æƒ…å†µ
        for anomaly in anomalies {
            actions.extend(self.handle_anomaly(&anomaly, &recent_perf)?);
        }
        
        // è®°å½•è°ƒä¼˜åŠ¨ä½œ
        let mut history = self.tuning_history.lock().map_err(|_| "Lock poisoned")?;
        for action in &actions {
            history.push_back(action.clone());
            if history.len() > 1000 {
                history.pop_front();
            }
        }
        
        if !actions.is_empty() {
            log::info!("Auto-tuning completed with {} actions", actions.len());
        }
        
        Ok(actions)
    }

    /// å¤„ç†æ€§èƒ½é™çº§
    fn handle_performance_degradation(&self, current_perf: &PerformanceMetrics) -> Result<Vec<TuningAction>, Box<dyn std::error::Error + Send + Sync>> {
        let mut actions = Vec::new();
        let mut params = self.optimization_parameters.write().map_err(|_| "Lock poisoned")?;
        
        // æé«˜æ¿€è¿›ç¨‹åº¦ï¼Œé™ä½ç²¾åº¦è¦æ±‚
        if current_perf.latency_us > 200.0 && params.aggression_level < 0.9 {
            let old_value = params.aggression_level;
            params.aggression_level = (params.aggression_level + 0.1).min(1.0);
            
            actions.push(TuningAction {
                timestamp: Instant::now(),
                parameter_name: "aggression_level".to_string(),
                old_value,
                new_value: params.aggression_level,
                reason: format!("High latency detected: {:.2}Âµs", current_perf.latency_us),
                performance_before: *current_perf,
                performance_after: None,
            });
        }
        
        // å‡å°‘ç²¾åº¦è¦æ±‚ä»¥æé«˜é€Ÿåº¦
        if current_perf.latency_us > 150.0 && params.accuracy_level > 0.5 {
            let old_value = params.accuracy_level;
            params.accuracy_level = (params.accuracy_level - 0.1).max(0.5);
            
            actions.push(TuningAction {
                timestamp: Instant::now(),
                parameter_name: "accuracy_level".to_string(),
                old_value,
                new_value: params.accuracy_level,
                reason: "Reducing accuracy to improve speed".to_string(),
                performance_before: *current_perf,
                performance_after: None,
            });
        }
        
        // å¯ç”¨æ›´å¤šå¹¶è¡ŒåŒ–
        if params.parallel_threads < 8 {
            let old_value = params.parallel_threads as f64;
            params.parallel_threads = (params.parallel_threads + 1).min(8);
            
            actions.push(TuningAction {
                timestamp: Instant::now(),
                parameter_name: "parallel_threads".to_string(),
                old_value,
                new_value: params.parallel_threads as f64,
                reason: "Increasing parallelism to handle degradation".to_string(),
                performance_before: *current_perf,
                performance_after: None,
            });
        }
        
        Ok(actions)
    }

    /// å¤„ç†æ€§èƒ½æ”¹å–„
    fn handle_performance_improvement(&self, current_perf: &PerformanceMetrics) -> Result<Vec<TuningAction>, Box<dyn std::error::Error + Send + Sync>> {
        let mut actions = Vec::new();
        let mut params = self.optimization_parameters.write().map_err(|_| "Lock poisoned")?;
        
        // æ€§èƒ½å……è¶³æ—¶ï¼Œå¯ä»¥æé«˜ç²¾åº¦
        if current_perf.latency_us < 50.0 && params.accuracy_level < 0.95 {
            let old_value = params.accuracy_level;
            params.accuracy_level = (params.accuracy_level + 0.05).min(0.95);
            
            actions.push(TuningAction {
                timestamp: Instant::now(),
                parameter_name: "accuracy_level".to_string(),
                old_value,
                new_value: params.accuracy_level,
                reason: format!("Low latency allows higher accuracy: {:.2}Âµs", current_perf.latency_us),
                performance_before: *current_perf,
                performance_after: None,
            });
        }
        
        // å¯ä»¥é™ä½æ¿€è¿›ç¨‹åº¦ï¼ŒèŠ‚çœèµ„æº
        if current_perf.latency_us < 30.0 && params.aggression_level > 0.3 {
            let old_value = params.aggression_level;
            params.aggression_level = (params.aggression_level - 0.05).max(0.3);
            
            actions.push(TuningAction {
                timestamp: Instant::now(),
                parameter_name: "aggression_level".to_string(),
                old_value,
                new_value: params.aggression_level,
                reason: "Excellent performance allows resource conservation".to_string(),
                performance_before: *current_perf,
                performance_after: None,
            });
        }
        
        Ok(actions)
    }

    /// å¤„ç†ç¨³å®šæ€§èƒ½
    fn handle_stable_performance(&self, current_perf: &PerformanceMetrics) -> Result<Vec<TuningAction>, Box<dyn std::error::Error + Send + Sync>> {
        let mut actions = Vec::new();
        let mut params = self.optimization_parameters.write().map_err(|_| "Lock poisoned")?;
        
        // æ€§èƒ½ç¨³å®šæ—¶ï¼Œå¯ä»¥è¿›è¡Œå°å¹…å®éªŒæ€§è°ƒæ•´
        if current_perf.latency_us > 100.0 && current_perf.latency_us < 200.0 {
            // å°è¯•å¢åŠ æ‰¹å¤„ç†å¤§å°
            if params.batch_size < 256 {
                let old_value = params.batch_size as f64;
                params.batch_size = (params.batch_size * 11 / 10).min(256); // å¢åŠ  10%
                
                actions.push(TuningAction {
                    timestamp: Instant::now(),
                    parameter_name: "batch_size".to_string(),
                    old_value,
                    new_value: params.batch_size as f64,
                    reason: "Experimental batch size increase during stable period".to_string(),
                    performance_before: *current_perf,
                    performance_after: None,
                });
            }
        }
        
        Ok(actions)
    }

    /// å¤„ç†å¼‚å¸¸æƒ…å†µ
    fn handle_anomaly(&self, anomaly: &PerformanceAnomaly, current_perf: &PerformanceMetrics) -> Result<Vec<TuningAction>, Box<dyn std::error::Error + Send + Sync>> {
        let mut actions = Vec::new();
        let mut params = self.optimization_parameters.write().map_err(|_| "Lock poisoned")?;
        
        match anomaly.anomaly_type {
            AnomalyType::HighLatency => {
                // é«˜å»¶è¿Ÿå¼‚å¸¸ï¼šç«‹å³é‡‡å–æ¿€è¿›æªæ–½
                if params.aggression_level < 1.0 {
                    let old_value = params.aggression_level;
                    params.aggression_level = 1.0;
                    
                    actions.push(TuningAction {
                        timestamp: Instant::now(),
                        parameter_name: "aggression_level".to_string(),
                        old_value,
                        new_value: params.aggression_level,
                        reason: format!("Emergency response to high latency anomaly: {}", anomaly.description),
                        performance_before: *current_perf,
                        performance_after: None,
                    });
                }
            },
            
            AnomalyType::CacheThrashing => {
                // ç¼“å­˜æŠ–åŠ¨ï¼šè°ƒæ•´é¢„å–è·ç¦»
                if params.prefetch_distance > 1 {
                    let old_value = params.prefetch_distance as f64;
                    params.prefetch_distance = params.prefetch_distance / 2;
                    
                    actions.push(TuningAction {
                        timestamp: Instant::now(),
                        parameter_name: "prefetch_distance".to_string(),
                        old_value,
                        new_value: params.prefetch_distance as f64,
                        reason: "Reducing prefetch distance due to cache thrashing".to_string(),
                        performance_before: *current_perf,
                        performance_after: None,
                    });
                }
            },
            
            _ => {
                // å…¶ä»–å¼‚å¸¸ç±»å‹çš„é€šç”¨å¤„ç†
                log::warn!("Unhandled anomaly type: {:?}", anomaly.anomaly_type);
            }
        }
        
        Ok(actions)
    }

    /// è·å–å½“å‰ä¼˜åŒ–å‚æ•°
    pub fn get_parameters(&self) -> Result<OptimizationParameters, Box<dyn std::error::Error + Send + Sync>> {
        let params = self.optimization_parameters.read().map_err(|_| "Lock poisoned")?;
        Ok(params.clone())
    }

    /// è·å–è°ƒä¼˜å†å²
    pub fn get_tuning_history(&self, count: usize) -> Result<Vec<TuningAction>, Box<dyn std::error::Error + Send + Sync>> {
        let history = self.tuning_history.lock().map_err(|_| "Lock poisoned")?;
        Ok(history.iter().rev().take(count).cloned().collect())
    }
}

/// å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹
static mut GLOBAL_PERFORMANCE_MONITOR: Option<Arc<UltraPerformanceMonitor>> = None;
static MONITOR_INIT: std::sync::Once = std::sync::Once::new();

/// è·å–å…¨å±€æ€§èƒ½ç›‘æ§å™¨
pub fn get_performance_monitor() -> Arc<UltraPerformanceMonitor> {
    unsafe {
        MONITOR_INIT.call_once(|| {
            match UltraPerformanceMonitor::new() {
                Ok(monitor) => {
                    GLOBAL_PERFORMANCE_MONITOR = Some(Arc::new(monitor));
                    log::info!("Global ultra performance monitor initialized");
                },
                Err(e) => {
                    log::error!("Failed to initialize performance monitor: {}", e);
                    panic!("Critical: Cannot initialize performance monitor");
                }
            }
        });
        
        GLOBAL_PERFORMANCE_MONITOR.as_ref().expect("Global instance not initialized").clone()
    }
}

/// å…¨å±€è‡ªè°ƒä¼˜å™¨å®ä¾‹
static mut GLOBAL_AUTO_TUNER: Option<Arc<RealTimeAutoTuner>> = None;
static TUNER_INIT: std::sync::Once = std::sync::Once::new();

/// è·å–å…¨å±€è‡ªè°ƒä¼˜å™¨
pub fn get_auto_tuner() -> Arc<RealTimeAutoTuner> {
    unsafe {
        TUNER_INIT.call_once(|| {
            let monitor = get_performance_monitor();
            let tuner = RealTimeAutoTuner::new(monitor);
            GLOBAL_AUTO_TUNER = Some(Arc::new(tuner));
            log::info!("Global real-time auto-tuner initialized");
        });
        
        GLOBAL_AUTO_TUNER.as_ref().expect("Global instance not initialized").clone()
    }
}

/// ä¼˜åŒ–å»ºè®®æšä¸¾
#[derive(Debug, Clone)]
pub enum OptimizationSuggestion {
    IncreaseParallelism,
    OptimizeMemoryUsage,
    TuneCpuAffinity,
    SwitchToFastPath,
}

/// å®æ—¶æ€§èƒ½ç›‘æ§å™¨ä¸»ç»“æ„
pub struct RealTimePerformanceMonitor {
    metrics_history: Arc<Mutex<CircularBuffer<PerformanceMetrics>>>,
    current_metrics: Arc<RwLock<PerformanceMetrics>>,
    monitoring_active: AtomicU32,
}

impl RealTimePerformanceMonitor {
    pub fn new() -> Self {
        Self {
            metrics_history: Arc::new(Mutex::new(CircularBuffer::new(1000))),
            current_metrics: Arc::new(RwLock::new(PerformanceMetrics::default())),
            monitoring_active: AtomicU32::new(0),
        }
    }

    /// å¼€å§‹æ“ä½œè·Ÿè¸ª
    pub async fn start_operation(&self, _operation_name: &str) {
        // å¼€å§‹æ€§èƒ½è·Ÿè¸ª
    }

    /// ç»“æŸæ“ä½œè·Ÿè¸ª
    pub async fn end_operation(&self, _operation_name: &str, duration: Duration) {
        let mut metrics = self.current_metrics.write().expect("Failed to acquire write lock");
        metrics.latency_us = duration.as_micros() as f64;
        metrics.timestamp = Instant::now();
    }

    /// è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡
    pub async fn get_current_metrics(&self) -> PerformanceMetrics {
        self.current_metrics.read().expect("Failed to acquire read lock").clone()
    }

    /// è·å–ä¼˜åŒ–å»ºè®®
    pub async fn get_optimization_suggestion(&self) -> Option<OptimizationSuggestion> {
        let metrics = self.current_metrics.read().expect("Failed to acquire read lock");
        
        if metrics.latency_us > 200.0 {
            Some(OptimizationSuggestion::SwitchToFastPath)
        } else if metrics.allocations > 100 {
            Some(OptimizationSuggestion::OptimizeMemoryUsage)
        } else {
            None
        }
    }

    /// å¯åŠ¨ç›‘æ§
    pub async fn start_monitoring(&self) {
        self.monitoring_active.store(1, Ordering::Relaxed);
        log::info!("ğŸš€ å¯åŠ¨å®æ—¶æ€§èƒ½ç›‘æ§");
    }

    /// åœæ­¢ç›‘æ§
    pub async fn stop_monitoring(&self) {
        self.monitoring_active.store(0, Ordering::Relaxed);
        log::info!("ğŸš€ åœæ­¢å®æ—¶æ€§èƒ½ç›‘æ§");
    }

    /// é‡ç½®æŒ‡æ ‡
    pub async fn reset_metrics(&self) {
        let mut metrics = self.current_metrics.write().expect("Failed to acquire write lock");
        *metrics = PerformanceMetrics::default();
    }
}

/// ä¼˜åŒ–å»ºè®®æšä¸¾
#[derive(Debug, Clone)]
pub enum OptimizationSuggestion {
    IncreaseParallelism,
    OptimizeMemoryUsage,
    TuneCpuAffinity,
    SwitchToFastPath,
}

/// å®æ—¶æ€§èƒ½ç›‘æ§å™¨
pub struct RealTimePerformanceMonitor {
    current_metrics: Arc<RwLock<PerformanceMetrics>>,
    history: Arc<Mutex<VecDeque<PerformanceMetrics>>>,
    monitoring_enabled: Arc<std::sync::atomic::AtomicBool>,
}

impl RealTimePerformanceMonitor {
    pub fn new() -> Self {
        Self {
            current_metrics: Arc::new(RwLock::new(PerformanceMetrics::default())),
            history: Arc::new(Mutex::new(VecDeque::new())),
            monitoring_enabled: Arc::new(std::sync::atomic::AtomicBool::new(false)),
        }
    }

    /// å¼€å§‹æ“ä½œè·Ÿè¸ª
    pub async fn start_operation(&self, _operation: &str) {
        if !self.monitoring_enabled.load(Ordering::Relaxed) {
            return;
        }
        // è®°å½•æ“ä½œå¼€å§‹æ—¶é—´
    }

    /// ç»“æŸæ“ä½œè·Ÿè¸ª
    pub async fn end_operation(&self, _operation: &str, duration: Duration) {
        if !self.monitoring_enabled.load(Ordering::Relaxed) {
            return;
        }
        
        let mut metrics = self.current_metrics.write().expect("Failed to acquire write lock");
        metrics.latency_us = duration.as_micros() as f64;
        metrics.timestamp = Instant::now();
    }

    /// è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡
    pub async fn get_current_metrics(&self) -> PerformanceMetrics {
        let metrics = self.current_metrics.read().expect("Failed to acquire read lock");
        metrics.clone()
    }

    /// è·å–ä¼˜åŒ–å»ºè®®
    pub async fn get_optimization_suggestion(&self) -> Option<OptimizationSuggestion> {
        let metrics = self.current_metrics.read().expect("Failed to acquire read lock");
        
        // ç®€å•çš„å¯å‘å¼è§„åˆ™
        if metrics.latency_us > 1000.0 {
            Some(OptimizationSuggestion::IncreaseParallelism)
        } else if metrics.allocations > 100 {
            Some(OptimizationSuggestion::OptimizeMemoryUsage)
        } else {
            None
        }
    }

    /// å¼€å§‹ç›‘æ§
    pub async fn start_monitoring(&self) {
        self.monitoring_enabled.store(true, Ordering::Relaxed);
        log::info!("ğŸš€ å®æ—¶æ€§èƒ½ç›‘æ§å·²å¯åŠ¨");
    }

    /// åœæ­¢ç›‘æ§
    pub async fn stop_monitoring(&self) {
        self.monitoring_enabled.store(false, Ordering::Relaxed);
        log::info!("ğŸš€ å®æ—¶æ€§èƒ½ç›‘æ§å·²åœæ­¢");
    }

    /// é‡ç½®æŒ‡æ ‡
    pub async fn reset_metrics(&self) {
        let mut metrics = self.current_metrics.write().expect("Failed to acquire write lock");
        *metrics = PerformanceMetrics::default();
        
        let mut history = self.history.lock().expect("Failed to acquire mutex lock");
        history.clear();
    }
}
