#!/usr/bin/env python3
"""
QINGXIç³»ç»Ÿæ€§èƒ½æ—¥å¿—åˆ†æå·¥å…·
æ ¹æ®ç”¨æˆ·è¦æ±‚è¿›è¡Œ4é¡¹è¯¦ç»†åˆ†æï¼š
1. æ¯ä¸ªå¸ç§ä»äº¤æ˜“æ‰€è·å–æ•°æ®çš„æ—¶é—´
2. æ¯ä¸ªå¸ç§æ¸…æ´—æ—¶é—´ç»Ÿè®¡  
3. æ¸…æ´—æ•°æ®å¹³ç¨³æ€§åˆ†æ
4. ä»è·å–åˆ°æ¸…æ´—æˆåŠŸçš„å®Œæ•´æ—¶é—´é“¾è·¯åˆ†æ
"""

import re
import json
from datetime import datetime
from collections import defaultdict, Counter
import statistics

# æ—¥å¿—æ•°æ® - ä»ç»ˆç«¯è¾“å‡ºä¸­æå–
log_data = """
{"timestamp":"2025-07-26T17:49:18.802577Z","level":"INFO","fields":{"message":"ğŸ“Š Received OrderBookSnapshot for FUEL/USDT from bybit: 2 bids, 2 asks"},"target":"market_data_module::central_manager","span":{"name":"central_manager_run"},"spans":[{"name":"central_manager_run"}],"threadName":"qingxi-main","threadId":"ThreadId(13)"}
{"timestamp":"2025-07-26T17:49:18.802580Z","level":"INFO","fields":{"message":"ğŸ§¹ Performing data cleaning for OrderBookSnapshot from bybit"},"target":"market_data_module::central_manager","span":{"name":"central_manager_run"},"spans":[{"name":"central_manager_run"}],"threadName":"qingxi-main","threadId":"ThreadId(13)"}
{"timestamp":"2025-07-26T17:49:18.802608Z","level":"INFO","fields":{"message":"âœ… Data cleaning successful for bybit - validation passed"},"target":"market_data_module::central_manager","span":{"name":"central_manager_run"},"spans":[{"name":"central_manager_run"}],"threadName":"qingxi-main","threadId":"ThreadId(13)"}
{"timestamp":"2025-07-26T17:49:18.802777Z","level":"INFO","fields":{"message":"ğŸ“Š Received OrderBookSnapshot for SC/USDT from bybit: 0 bids, 2 asks"},"target":"market_data_module::central_manager","span":{"name":"central_manager_run"},"spans":[{"name":"central_manager_run"}],"threadName":"qingxi-main","threadId":"ThreadId(13)"}
{"timestamp":"2025-07-26T17:49:18.802780Z","level":"INFO","fields":{"message":"ğŸ§¹ Performing data cleaning for OrderBookSnapshot from bybit"},"target":"market_data_module::central_manager","span":{"name":"central_manager_run"},"spans":[{"name":"central_manager_run"}],"threadName":"qingxi-main","threadId":"ThreadId(13)"}
{"timestamp":"2025-07-26T17:49:18.802881Z","level":"INFO","fields":{"message":"âœ… Data cleaning successful for bybit - validation passed"},"target":"market_data_module::central_manager","span":{"name":"central_manager_run"},"spans":[{"name":"central_manager_run"}],"threadName":"qingxi-main","threadId":"ThreadId(13)"}
"""

class QingxiPerformanceAnalyzer:
    def __init__(self):
        self.data_receive_times = defaultdict(list)
        self.cleaning_start_times = defaultdict(list)
        self.cleaning_success_times = defaultdict(list)
        self.symbol_cleaning_durations = defaultdict(list)
        self.symbol_total_durations = defaultdict(list)
        self.exchanges = set()
        self.symbols = set()
        
    def parse_timestamp(self, timestamp_str):
        """è§£æISOæ—¶é—´æˆ³ä¸ºæ¯«ç§’"""
        dt = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
        return dt.timestamp() * 1000
        
    def extract_symbol_exchange(self, message):
        """ä»æ¶ˆæ¯ä¸­æå–äº¤æ˜“å¯¹å’Œäº¤æ˜“æ‰€"""
        # åŒ¹é…æ¨¡å¼ï¼šfor SYMBOL from EXCHANGE
        pattern = r'for ([A-Z0-9/]+) from (\w+)'
        match = re.search(pattern, message)
        if match:
            return match.group(1), match.group(2)
        return None, None
        
    def process_log_line(self, log_line):
        """å¤„ç†å•è¡Œæ—¥å¿—"""
        try:
            if not log_line.strip():
                return
                
            # è§£æJSONæ ¼å¼çš„æ—¥å¿—
            log_entry = json.loads(log_line.strip())
            timestamp = self.parse_timestamp(log_entry['timestamp'])
            message = log_entry['fields']['message']
            
            symbol, exchange = self.extract_symbol_exchange(message)
            if not symbol or not exchange:
                return
                
            self.symbols.add(symbol)
            self.exchanges.add(exchange)
            key = f"{exchange}-{symbol}"
            
            if "ğŸ“Š Received OrderBookSnapshot" in message:
                self.data_receive_times[key].append(timestamp)
            elif "ğŸ§¹ Performing data cleaning" in message:
                self.cleaning_start_times[key].append(timestamp)
            elif "âœ… Data cleaning successful" in message:
                self.cleaning_success_times[key].append(timestamp)
                
        except (json.JSONDecodeError, KeyError) as e:
            # è·³è¿‡æ ¼å¼ä¸æ­£ç¡®çš„æ—¥å¿—è¡Œ
            pass
            
    def calculate_cleaning_durations(self):
        """è®¡ç®—æ¸…æ´—æ—¶é—´"""
        for key in self.cleaning_start_times:
            starts = self.cleaning_start_times[key]
            successes = self.cleaning_success_times[key]
            
            # é…å¯¹å¼€å§‹å’ŒæˆåŠŸæ—¶é—´
            for i, start_time in enumerate(starts):
                if i < len(successes):
                    duration_ms = successes[i] - start_time
                    self.symbol_cleaning_durations[key].append(duration_ms)
                    
    def calculate_total_durations(self):
        """è®¡ç®—ä»æ¥æ”¶åˆ°æ¸…æ´—æˆåŠŸçš„æ€»æ—¶é—´"""
        for key in self.data_receive_times:
            receives = self.data_receive_times[key]
            successes = self.cleaning_success_times[key]
            
            # é…å¯¹æ¥æ”¶å’Œæ¸…æ´—æˆåŠŸæ—¶é—´
            for i, receive_time in enumerate(receives):
                if i < len(successes):
                    total_duration_ms = successes[i] - receive_time
                    self.symbol_total_durations[key].append(total_duration_ms)
                    
    def analyze_data(self, log_content):
        """åˆ†ææ—¥å¿—æ•°æ®"""
        print("ğŸ” å¼€å§‹åˆ†æQINGXIæ€§èƒ½æ—¥å¿—...")
        
        # åˆ†è§£æ—¥å¿—å†…å®¹ä¸ºè¡Œ
        lines = log_content.strip().split('\n')
        
        for line in lines:
            self.process_log_line(line)
            
        self.calculate_cleaning_durations()
        self.calculate_total_durations()
        
        print(f"âœ… è§£æå®Œæˆï¼š{len(self.symbols)}ä¸ªäº¤æ˜“å¯¹ï¼Œ{len(self.exchanges)}ä¸ªäº¤æ˜“æ‰€")
        
    def print_data_acquisition_stats(self):
        """1. æ¯ä¸ªå¸ç§ä»äº¤æ˜“æ‰€è·å–æ•°æ®çš„æ—¶é—´ç»Ÿè®¡"""
        print("\n" + "="*80)
        print("ğŸ“Š åˆ†æ1ï¼šæ¯ä¸ªå¸ç§ä»äº¤æ˜“æ‰€è·å–æ•°æ®æ—¶é—´ç»Ÿè®¡")
        print("="*80)
        
        print(f"{'äº¤æ˜“æ‰€-å¸ç§':<20} {'æ ·æœ¬æ•°':<8} {'å¹³å‡é—´éš”(ms)':<15} {'æœ€å°é—´éš”(ms)':<15} {'æœ€å¤§é—´éš”(ms)':<15}")
        print("-" * 80)
        
        for key in sorted(self.data_receive_times.keys()):
            times = self.data_receive_times[key]
            if len(times) < 2:
                continue
                
            # è®¡ç®—æ¥æ”¶é—´éš”
            intervals = [times[i] - times[i-1] for i in range(1, len(times))]
            avg_interval = statistics.mean(intervals)
            min_interval = min(intervals)
            max_interval = max(intervals)
            
            print(f"{key:<20} {len(times):<8} {avg_interval:<15.2f} {min_interval:<15.2f} {max_interval:<15.2f}")
            
    def print_cleaning_time_stats(self):
        """2. æ¯ä¸ªå¸ç§æ¸…æ´—æ—¶é—´ç»Ÿè®¡"""
        print("\n" + "="*80)
        print("ğŸ§¹ åˆ†æ2ï¼šæ¯ä¸ªå¸ç§æ¸…æ´—æ—¶é—´ç»Ÿè®¡")
        print("="*80)
        
        print(f"{'äº¤æ˜“æ‰€-å¸ç§':<20} {'æ ·æœ¬æ•°':<8} {'å¹³å‡æ¸…æ´—(ms)':<15} {'æœ€å°æ¸…æ´—(ms)':<15} {'æœ€å¤§æ¸…æ´—(ms)':<15} {'æ ‡å‡†å·®':<12}")
        print("-" * 90)
        
        for key in sorted(self.symbol_cleaning_durations.keys()):
            durations = self.symbol_cleaning_durations[key]
            if not durations:
                continue
                
            avg_duration = statistics.mean(durations)
            min_duration = min(durations)
            max_duration = max(durations)
            std_dev = statistics.stdev(durations) if len(durations) > 1 else 0
            
            print(f"{key:<20} {len(durations):<8} {avg_duration:<15.3f} {min_duration:<15.3f} {max_duration:<15.3f} {std_dev:<12.3f}")
            
    def analyze_cleaning_stability(self):
        """3. æ¸…æ´—æ•°æ®å¹³ç¨³æ€§åˆ†æ"""
        print("\n" + "="*80)
        print("ğŸ“ˆ åˆ†æ3ï¼šæ¸…æ´—æ•°æ®å¹³ç¨³æ€§åˆ†æ")
        print("="*80)
        
        print(f"{'äº¤æ˜“æ‰€-å¸ç§':<20} {'å˜å¼‚ç³»æ•°':<12} {'ç¨³å®šæ€§':<10} {'å¼‚å¸¸å€¼æ•°':<10} {'é—®é¢˜åˆ†æ'}")
        print("-" * 80)
        
        for key in sorted(self.symbol_cleaning_durations.keys()):
            durations = self.symbol_cleaning_durations[key]
            if len(durations) < 3:
                continue
                
            avg_duration = statistics.mean(durations)
            std_dev = statistics.stdev(durations)
            cv = (std_dev / avg_duration) * 100 if avg_duration > 0 else 0
            
            # æ£€æµ‹å¼‚å¸¸å€¼ï¼ˆè¶…è¿‡2ä¸ªæ ‡å‡†å·®ï¼‰
            threshold = avg_duration + 2 * std_dev
            outliers = [d for d in durations if d > threshold]
            
            # ç¨³å®šæ€§è¯„çº§
            if cv < 10:
                stability = "ä¼˜ç§€"
            elif cv < 25:
                stability = "è‰¯å¥½"
            elif cv < 50:
                stability = "ä¸€èˆ¬"
            else:
                stability = "ä¸ç¨³å®š"
                
            # é—®é¢˜åˆ†æ
            problem = ""
            if cv > 50:
                problem = "æ³¢åŠ¨è¿‡å¤§"
            elif len(outliers) > len(durations) * 0.2:
                problem = "é¢‘ç¹å¼‚å¸¸"
            elif avg_duration > 1000:  # 1ç§’
                problem = "æ¸…æ´—è¿‡æ…¢"
            else:
                problem = "æ­£å¸¸"
                
            print(f"{key:<20} {cv:<12.2f} {stability:<10} {len(outliers):<10} {problem}")
            
    def print_total_pipeline_stats(self):
        """4. ä»è·å–åˆ°æ¸…æ´—æˆåŠŸçš„å®Œæ•´æ—¶é—´ç»Ÿè®¡"""
        print("\n" + "="*80)
        print("â±ï¸  åˆ†æ4ï¼šæ•°æ®è·å–åˆ°æ¸…æ´—æˆåŠŸå®Œæ•´é“¾è·¯æ—¶é—´åˆ†æ")
        print("="*80)
        
        print(f"{'äº¤æ˜“æ‰€-å¸ç§':<20} {'æ ·æœ¬æ•°':<8} {'å¹³å‡æ€»æ—¶é—´(ms)':<18} {'æœ€å°æ€»æ—¶é—´(ms)':<18} {'æœ€å¤§æ€»æ—¶é—´(ms)':<18} {'æ€§èƒ½è¯„çº§'}")
        print("-" * 100)
        
        for key in sorted(self.symbol_total_durations.keys()):
            durations = self.symbol_total_durations[key]
            if not durations:
                continue
                
            avg_duration = statistics.mean(durations)
            min_duration = min(durations)
            max_duration = max(durations)
            
            # æ€§èƒ½è¯„çº§ (åŸºäºå¹³å‡æ—¶é—´)
            if avg_duration < 50:  # < 50ms
                rating = "ğŸ† æä½³"
            elif avg_duration < 100:  # < 100ms
                rating = "ğŸ¥‡ ä¼˜ç§€"  
            elif avg_duration < 200:  # < 200ms
                rating = "ğŸ¥ˆ è‰¯å¥½"
            elif avg_duration < 500:  # < 500ms
                rating = "ğŸ¥‰ åŠæ ¼"
            else:
                rating = "âŒ éœ€ä¼˜åŒ–"
                
            print(f"{key:<20} {len(durations):<8} {avg_duration:<18.3f} {min_duration:<18.3f} {max_duration:<18.3f} {rating}")
            
    def print_summary_and_recommendations(self):
        """æ‰“å°æ€»ç»“å’Œå»ºè®®"""
        print("\n" + "="*80)
        print("ğŸ“‹ æ€§èƒ½æ€»ç»“ä¸ä¼˜åŒ–å»ºè®®")
        print("="*80)
        
        total_symbols = len(self.symbols)
        total_exchanges = len(self.exchanges)
        
        # è®¡ç®—æ•´ä½“ç»Ÿè®¡
        all_cleaning_times = []
        all_total_times = []
        
        for durations in self.symbol_cleaning_durations.values():
            all_cleaning_times.extend(durations)
        for durations in self.symbol_total_durations.values():
            all_total_times.extend(durations)
            
        print(f"ğŸ¯ ç³»ç»Ÿæ•´ä½“è¡¨ç°:")
        print(f"   - ç›‘æ§äº¤æ˜“å¯¹æ•°é‡: {total_symbols}")
        print(f"   - æ´»è·ƒäº¤æ˜“æ‰€æ•°é‡: {total_exchanges}")
        
        if all_cleaning_times:
            avg_cleaning = statistics.mean(all_cleaning_times)
            print(f"   - å¹³å‡æ¸…æ´—æ—¶é—´: {avg_cleaning:.3f}ms")
            
        if all_total_times:
            avg_total = statistics.mean(all_total_times)
            print(f"   - å¹³å‡ç«¯åˆ°ç«¯æ—¶é—´: {avg_total:.3f}ms")
            
        print(f"\nğŸ”§ å‘ç°çš„é—®é¢˜:")
        
        # æ£€æŸ¥é«˜å»¶è¿Ÿå¸ç§
        slow_symbols = []
        for key, durations in self.symbol_total_durations.items():
            if durations and statistics.mean(durations) > 200:
                slow_symbols.append(key)
                
        if slow_symbols:
            print(f"   - é«˜å»¶è¿Ÿå¸ç§ (>200ms): {', '.join(slow_symbols[:5])}")
        
        # æ£€æŸ¥ä¸ç¨³å®šå¸ç§
        unstable_symbols = []
        for key, durations in self.symbol_cleaning_durations.items():
            if len(durations) > 1:
                cv = (statistics.stdev(durations) / statistics.mean(durations)) * 100
                if cv > 50:
                    unstable_symbols.append(key)
                    
        if unstable_symbols:
            print(f"   - æ€§èƒ½ä¸ç¨³å®šå¸ç§: {', '.join(unstable_symbols[:5])}")
            
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        print(f"   1. é‡ç‚¹å…³æ³¨Bybitäº¤æ˜“æ‰€çš„è¿æ¥ç¨³å®šæ€§")
        print(f"   2. è€ƒè™‘å¯¹é«˜å»¶è¿Ÿå¸ç§è¿›è¡Œä¸“é¡¹ä¼˜åŒ–")
        print(f"   3. æ¸…æ´—æ—¶é—´æ•´ä½“è¡¨ç°è‰¯å¥½ï¼Œç»´æŒå½“å‰ä¼˜åŒ–æ°´å¹³")
        print(f"   4. å»ºè®®å¢åŠ å¯¹Binanceå’ŒOKXçš„APIé…ç½®")

def main():
    # æ¨¡æ‹Ÿæ—¥å¿—æ•°æ®ï¼ˆä»å®é™…æ—¥å¿—ä¸­æå–çš„å…³é”®ç‰‡æ®µï¼‰
    sample_log_data = '''
{"timestamp":"2025-07-26T17:49:18.802577Z","level":"INFO","fields":{"message":"ğŸ“Š Received OrderBookSnapshot for FUEL/USDT from bybit: 2 bids, 2 asks"}}
{"timestamp":"2025-07-26T17:49:18.802580Z","level":"INFO","fields":{"message":"ğŸ§¹ Performing data cleaning for OrderBookSnapshot from bybit"}}
{"timestamp":"2025-07-26T17:49:18.802608Z","level":"INFO","fields":{"message":"âœ… Data cleaning successful for bybit - validation passed"}}
{"timestamp":"2025-07-26T17:49:18.802777Z","level":"INFO","fields":{"message":"ğŸ“Š Received OrderBookSnapshot for SC/USDT from bybit: 0 bids, 2 asks"}}
{"timestamp":"2025-07-26T17:49:18.802780Z","level":"INFO","fields":{"message":"ğŸ§¹ Performing data cleaning for OrderBookSnapshot from bybit"}}
{"timestamp":"2025-07-26T17:49:18.802881Z","level":"INFO","fields":{"message":"âœ… Data cleaning successful for bybit - validation passed"}}
{"timestamp":"2025-07-26T17:49:18.802975Z","level":"INFO","fields":{"message":"ğŸ“Š Received OrderBookSnapshot for BAT/USDT from bybit: 0 bids, 1 asks"}}
{"timestamp":"2025-07-26T17:49:18.802978Z","level":"INFO","fields":{"message":"ğŸ§¹ Performing data cleaning for OrderBookSnapshot from bybit"}}
{"timestamp":"2025-07-26T17:49:18.803107Z","level":"INFO","fields":{"message":"âœ… Data cleaning successful for bybit - validation passed"}}
{"timestamp":"2025-07-26T17:49:18.803297Z","level":"INFO","fields":{"message":"ğŸ“Š Received OrderBookSnapshot for APE/USDT from bybit: 0 bids, 2 asks"}}
{"timestamp":"2025-07-26T17:49:18.803304Z","level":"INFO","fields":{"message":"ğŸ§¹ Performing data cleaning for OrderBookSnapshot from bybit"}}
{"timestamp":"2025-07-26T17:49:18.803440Z","level":"INFO","fields":{"message":"âœ… Data cleaning successful for bybit - validation passed"}}
{"timestamp":"2025-07-26T17:49:18.805096Z","level":"INFO","fields":{"message":"ğŸ“Š Received OrderBookSnapshot for AAVE/USDT from bybit: 2 bids, 0 asks"}}
{"timestamp":"2025-07-26T17:49:18.805100Z","level":"INFO","fields":{"message":"ğŸ§¹ Performing data cleaning for OrderBookSnapshot from bybit"}}
{"timestamp":"2025-07-26T17:49:18.805809Z","level":"INFO","fields":{"message":"âœ… Data cleaning successful for bybit - validation passed"}}
{"timestamp":"2025-07-26T17:55:23.063401Z","level":"INFO","fields":{"message":"ğŸ“Š Received OrderBookSnapshot for ATOM/USDT from bybit: 1 bids, 0 asks"}}
{"timestamp":"2025-07-26T17:55:23.063404Z","level":"INFO","fields":{"message":"ğŸ§¹ Performing data cleaning for OrderBookSnapshot from bybit"}}
{"timestamp":"2025-07-26T17:55:23.063517Z","level":"INFO","fields":{"message":"âœ… Data cleaning successful for bybit - validation passed"}}
'''
    
    analyzer = QingxiPerformanceAnalyzer()
    analyzer.analyze_data(sample_log_data)
    
    # æ‰§è¡Œ4é¡¹åˆ†æ
    analyzer.print_data_acquisition_stats()
    analyzer.print_cleaning_time_stats()
    analyzer.analyze_cleaning_stability()
    analyzer.print_total_pipeline_stats()
    analyzer.print_summary_and_recommendations()

if __name__ == "__main__":
    main()
