#!/usr/bin/env python3
"""
é«˜éš¾åº¦ç­–ç•¥æ¨¡å—å®Œæ•´æµ‹è¯• - è§£å†³é£æ§å’Œé«˜é¢‘å¤„ç†é—®é¢˜
æµ‹è¯•å†…å®¹ï¼š
1. 50000+äº¤æ˜“å¯¹ä¸‰è§’å¥—åˆ©å’Œè·¨äº¤æ˜“æ‰€å¥—åˆ©æ£€æµ‹
2. AIé«˜éš¾åº¦å¼‚å¸¸æ•°æ®å’Œè®¢å•è–„æ¯ç«­æ£€æµ‹
3. é£æ§æ¨¡å—å¼ºåŒ–å‹åŠ›æµ‹è¯•
4. é«˜é¢‘å¤„ç†æ€§èƒ½ä¼˜åŒ–éªŒè¯
"""

import asyncio
import json
import time
import random
import nats
import logging
import numpy as np
import threading
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
import heapq
from collections import defaultdict

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(funcName)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AdvancedTradingPairGenerator:
    """é«˜éš¾åº¦50000+äº¤æ˜“å¯¹ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # åŸºç¡€å¸ç§ï¼ˆ100ä¸ªä¸»æµå¸ï¼‰
        self.base_currencies = [
            "BTC", "ETH", "BNB", "XRP", "ADA", "SOL", "DOT", "AVAX", "LINK", "UNI",
            "MATIC", "LTC", "BCH", "ALGO", "ATOM", "ICP", "FIL", "TRX", "ETC", "XLM",
            "NEAR", "HBAR", "APE", "MANA", "SAND", "CRV", "COMP", "AAVE", "MKR", "YFI",
            "SUSHI", "1INCH", "BAT", "ZRX", "KNC", "ENJ", "CHZ", "HOT", "VET", "ZIL",
            "ONT", "QTUM", "ICX", "SC", "DGB", "RVN", "NANO", "XEM", "WAVES", "LSK",
            "ARDR", "STRAT", "BURST", "XCP", "GAME", "STORJ", "FCT", "MAID", "AMP", "LRC",
            "GNT", "REP", "BAL", "BAND", "REN", "SNX", "UMA", "OXT", "NMR", "MLN",
            "KEEP", "NU", "ANKR", "CVC", "DNT", "MYST", "POWR", "REQ", "RLC", "STORJ",
            "CTSI", "FARM", "INDEX", "MASK", "PERP", "RARI", "TORN", "BADGER", "DIGG", "ROOK",
            "API3", "ALPHA", "BETA", "GAMMA", "DELTA", "EPSILON", "ZETA", "ETA", "THETA", "IOTA"
        ]
        
        # æŠ¥ä»·å¸ç§ï¼ˆç¨³å®šå¸å’Œä¸»æµå¸ï¼‰
        self.quote_currencies = [
            "USDT", "USDC", "BUSD", "DAI", "TUSD", "PAXG", "USDN", "USDP", "GUSD", "HUSD",
            "BTC", "ETH", "BNB", "EUR", "GBP", "JPY", "KRW", "RUB", "TRY", "NGN"
        ]
        
        # DeFiå’Œæ–°å…´å¸ç§ï¼ˆ1000ä¸ªï¼‰
        self.defi_tokens = self._generate_defi_tokens()
        
        # NFTå’ŒGameFiå¸ç§ï¼ˆ500ä¸ªï¼‰
        self.nft_tokens = self._generate_nft_tokens()
        
        # Memeå¸å’Œå°å¸ç§ï¼ˆ3000ä¸ªï¼‰
        self.meme_tokens = self._generate_meme_tokens()
        
    def _generate_defi_tokens(self) -> List[str]:
        """ç”Ÿæˆ1000ä¸ªDeFiä»£å¸"""
        prefixes = ["DEFI", "SWAP", "FARM", "POOL", "STAKE", "YIELD", "AUTO", "VAULT", "CAKE", "PAN"]
        suffixes = ["TOKEN", "COIN", "FINANCE", "PROTOCOL", "DAO", "BRIDGE", "CROSS", "MULTI", "OMNI", "META"]
        tokens = []
        
        for i in range(1000):
            prefix = random.choice(prefixes)
            suffix = random.choice(suffixes) if random.random() > 0.5 else ""
            number = f"{i:03d}" if random.random() > 0.7 else ""
            token = f"{prefix}{number}{suffix}"[:10]  # é™åˆ¶é•¿åº¦
            tokens.append(token)
        
        return tokens
    
    def _generate_nft_tokens(self) -> List[str]:
        """ç”Ÿæˆ500ä¸ªNFT/GameFiä»£å¸"""
        prefixes = ["NFT", "GAME", "META", "VERSE", "LAND", "PIXEL", "CRYPTO", "CHAIN", "BLOCK", "DIGI"]
        suffixes = ["PUNK", "APE", "KITTY", "HERO", "WORLD", "SPACE", "QUEST", "FIGHT", "RACE", "CARD"]
        tokens = []
        
        for i in range(500):
            prefix = random.choice(prefixes)
            suffix = random.choice(suffixes)
            number = f"{i:02d}" if random.random() > 0.6 else ""
            token = f"{prefix}{suffix}{number}"[:10]
            tokens.append(token)
        
        return tokens
    
    def _generate_meme_tokens(self) -> List[str]:
        """ç”Ÿæˆ3000ä¸ªMemeå¸å’Œå°å¸ç§"""
        prefixes = ["DOGE", "SHIB", "PEPE", "FLOKI", "BABY", "SAFE", "MOON", "ELON", "TRUMP", "WOJAK"]
        suffixes = ["INU", "COIN", "TOKEN", "CASH", "GOLD", "DIAMOND", "ROCKET", "LAMBO", "MEME", "CHAD"]
        tokens = []
        
        for i in range(3000):
            if random.random() > 0.3:
                prefix = random.choice(prefixes)
                suffix = random.choice(suffixes)
                number = f"{i:04d}" if random.random() > 0.5 else ""
                token = f"{prefix}{suffix}{number}"[:12]
            else:
                # éšæœºå­—ç¬¦ç»„åˆ
                token = ''.join(random.choices('ABCDEFGHIJKLMNOPQRSTUVWXYZ', k=random.randint(3, 8)))
            
            tokens.append(token)
        
        return tokens
    
    def generate_all_trading_pairs(self) -> List[str]:
        """ç”Ÿæˆ50000+äº¤æ˜“å¯¹"""
        all_tokens = (self.base_currencies + self.defi_tokens + 
                     self.nft_tokens + self.meme_tokens)
        
        trading_pairs = []
        
        # ä¸»æµå¸ vs æ‰€æœ‰æŠ¥ä»·å¸
        for base in self.base_currencies:
            for quote in self.quote_currencies:
                if base != quote:
                    trading_pairs.append(f"{base}/{quote}")
        
        # DeFiä»£å¸ vs ä¸»è¦æŠ¥ä»·å¸
        main_quotes = ["USDT", "USDC", "BTC", "ETH", "BNB"]
        for token in self.defi_tokens:
            for quote in main_quotes:
                trading_pairs.append(f"{token}/{quote}")
        
        # NFTä»£å¸ vs ä¸»è¦æŠ¥ä»·å¸
        for token in self.nft_tokens:
            for quote in main_quotes[:3]:  # åªç”¨å‰3ä¸ª
                trading_pairs.append(f"{token}/{quote}")
        
        # Memeå¸ vs USDT/USDC
        for token in self.meme_tokens:
            for quote in ["USDT", "USDC"]:
                trading_pairs.append(f"{token}/{quote}")
        
        logger.info(f"âœ… ç”Ÿæˆäº† {len(trading_pairs):,} ä¸ªäº¤æ˜“å¯¹")
        return trading_pairs

class AdvancedAIAnomalyDetector:
    """é«˜éš¾åº¦AIå¼‚å¸¸æ£€æµ‹æ¨¡å—"""
    
    def __init__(self):
        self.anomaly_history = defaultdict(list)
        self.market_correlation_matrix = {}
        self.liquidity_threshold_dynamic = {}
        self.whale_detection_patterns = []
        
    def detect_complex_anomalies(self, market_data: Dict) -> List[Dict]:
        """é«˜éš¾åº¦å¼‚å¸¸æ£€æµ‹"""
        anomalies = []
        
        # 1. æ£€æµ‹è®¢å•è–„æ“çºµï¼ˆé«˜éš¾åº¦ï¼‰
        if self._detect_orderbook_manipulation(market_data):
            anomalies.append({
                "type": "orderbook_manipulation",
                "severity": "critical",
                "description": f"æ£€æµ‹åˆ°{market_data['symbol']}è®¢å•è–„æ“çºµè¡Œä¸º",
                "pattern": "large_wall_spoofing",
                "confidence": 0.95,
                "action": "halt_trading"
            })
        
        # 2. æ£€æµ‹æµåŠ¨æ€§æ¯ç«­ï¼ˆå¤šç»´åº¦ï¼‰
        liquidity_anomaly = self._detect_liquidity_drought(market_data)
        if liquidity_anomaly:
            anomalies.append(liquidity_anomaly)
        
        # 3. æ£€æµ‹ä»·æ ¼æ“çºµï¼ˆAIæ¨¡å¼è¯†åˆ«ï¼‰
        manipulation = self._detect_ai_price_manipulation(market_data)
        if manipulation:
            anomalies.append(manipulation)
        
        # 4. æ£€æµ‹å·¨é²¸äº¤æ˜“æ¨¡å¼
        whale_activity = self._detect_whale_activity(market_data)
        if whale_activity:
            anomalies.append(whale_activity)
        
        # 5. æ£€æµ‹å¸‚åœºç»“æ„å¼‚å¸¸
        structure_anomaly = self._detect_market_structure_anomaly(market_data)
        if structure_anomaly:
            anomalies.append(structure_anomaly)
        
        return anomalies
    
    def _detect_orderbook_manipulation(self, data: Dict) -> bool:
        """æ£€æµ‹é«˜éš¾åº¦è®¢å•è–„æ“çºµ"""
        if not data.get("bids") or not data.get("asks"):
            return False
        
        bids = data["bids"][:10]  # å‰10æ¡£
        asks = data["asks"][:10]
        
        # æ£€æµ‹è™šå‡å¢™å•
        total_bid_volume = sum(float(bid[1]) for bid in bids)
        total_ask_volume = sum(float(ask[1]) for ask in asks)
        
        # æ£€æµ‹å¼‚å¸¸å¤§å•é›†ä¸­åœ¨æŸä¸€ä»·æ ¼
        bid_volumes = [float(bid[1]) for bid in bids]
        ask_volumes = [float(ask[1]) for ask in asks]
        
        # å¦‚æœæœ€å¤§å•é‡è¶…è¿‡å¹³å‡é‡çš„50å€ï¼Œå¯èƒ½æ˜¯æ“çºµ
        if bid_volumes:
            max_bid = max(bid_volumes)
            avg_bid = sum(bid_volumes) / len(bid_volumes)
            if max_bid > avg_bid * 50:
                return True
        
        if ask_volumes:
            max_ask = max(ask_volumes)
            avg_ask = sum(ask_volumes) / len(ask_volumes)
            if max_ask > avg_ask * 50:
                return True
        
        # æ£€æµ‹ä»·å·®å¼‚å¸¸
        if bids and asks:
            spread_pct = (asks[0][0] - bids[0][0]) / bids[0][0]
            if spread_pct > 0.1:  # 10%ä»¥ä¸Šä»·å·®å¼‚å¸¸
                return True
        
        return False
    
    def _detect_liquidity_drought(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹æµåŠ¨æ€§æ¯ç«­ï¼ˆé«˜éš¾åº¦ï¼‰"""
        if not data.get("bids") or not data.get("asks"):
            return {
                "type": "complete_liquidity_drought",
                "severity": "critical", 
                "description": f"{data['symbol']}å®Œå…¨æ²¡æœ‰æµåŠ¨æ€§",
                "confidence": 1.0,
                "action": "suspend_all_trading"
            }
        
        # è®¡ç®—å¤šå±‚æ¬¡æµåŠ¨æ€§æŒ‡æ ‡
        bid_depths = [float(bid[1]) for bid in data["bids"][:5]]
        ask_depths = [float(ask[1]) for ask in data["asks"][:5]]
        
        total_depth = sum(bid_depths) + sum(ask_depths)
        
        # åŠ¨æ€é˜ˆå€¼ï¼ˆæ ¹æ®äº¤æ˜“å¯¹ç±»å‹ï¼‰
        symbol = data.get("symbol", "")
        if any(meme in symbol for meme in ["DOGE", "SHIB", "PEPE", "FLOKI"]):
            threshold = 0.1  # Memeå¸é˜ˆå€¼æ›´ä½
        elif any(defi in symbol for defi in ["DEFI", "SWAP", "FARM"]):
            threshold = 1.0  # DeFiä»£å¸ä¸­ç­‰é˜ˆå€¼
        else:
            threshold = 5.0  # ä¸»æµå¸æ›´é«˜é˜ˆå€¼
        
        if total_depth < threshold:
            return {
                "type": "liquidity_drought",
                "severity": "high",
                "description": f"{symbol}æµåŠ¨æ€§ä¸¥é‡ä¸è¶³: {total_depth:.4f} < {threshold}",
                "confidence": 0.9,
                "action": "reduce_position_size"
            }
        
        return None
    
    def _detect_ai_price_manipulation(self, data: Dict) -> Optional[Dict]:
        """AIæ¨¡å¼è¯†åˆ«ä»·æ ¼æ“çºµ"""
        symbol = data.get("symbol", "")
        timestamp = data.get("timestamp", time.time())
        
        # è®°å½•ä»·æ ¼å†å²
        if symbol not in self.anomaly_history:
            self.anomaly_history[symbol] = []
        
        if data.get("bids") and data.get("asks"):
            mid_price = (data["bids"][0][0] + data["asks"][0][0]) / 2
            self.anomaly_history[symbol].append((timestamp, mid_price))
            
            # ä¿æŒæœ€è¿‘100ä¸ªä»·æ ¼ç‚¹
            if len(self.anomaly_history[symbol]) > 100:
                self.anomaly_history[symbol] = self.anomaly_history[symbol][-100:]
            
            # AIæ£€æµ‹å¼‚å¸¸ä»·æ ¼æ¨¡å¼
            if len(self.anomaly_history[symbol]) >= 10:
                prices = [p[1] for p in self.anomaly_history[symbol][-10:]]
                
                # æ£€æµ‹äººå·¥æ‹‰ç›˜æ¨¡å¼ï¼ˆè¿ç»­å•å‘å¤§å¹…æ³¢åŠ¨ï¼‰
                price_changes = [prices[i] - prices[i-1] for i in range(1, len(prices))]
                
                # å¦‚æœè¿ç»­5æ¬¡ä»¥ä¸ŠåŒæ–¹å‘å˜åŒ–ä¸”å¹…åº¦è¶…è¿‡1%
                if len(price_changes) >= 5:
                    positive_changes = sum(1 for change in price_changes[-5:] if change > 0)
                    negative_changes = sum(1 for change in price_changes[-5:] if change < 0)
                    
                    if positive_changes >= 4 or negative_changes >= 4:
                        total_change = abs(sum(price_changes[-5:]) / prices[-6])
                        if total_change > 0.05:  # 5%ä»¥ä¸Šå˜åŒ–
                            return {
                                "type": "ai_detected_manipulation",
                                "severity": "high",
                                "description": f"AIæ£€æµ‹åˆ°{symbol}äººå·¥æ“çºµæ¨¡å¼",
                                "pattern": "directional_pumping",
                                "confidence": 0.85,
                                "action": "monitor_closely"
                            }
        
        return None
    
    def _detect_whale_activity(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹å·¨é²¸æ´»åŠ¨"""
        if not data.get("bids") or not data.get("asks"):
            return None
        
        # æ£€æµ‹å¼‚å¸¸å¤§å•
        all_volumes = []
        for bid in data["bids"]:
            all_volumes.append(float(bid[1]))
        for ask in data["asks"]:
            all_volumes.append(float(ask[1]))
        
        if len(all_volumes) < 5:
            return None
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        avg_volume = sum(all_volumes) / len(all_volumes)
        max_volume = max(all_volumes)
        
        # å¦‚æœæœ€å¤§å•é‡è¶…è¿‡å¹³å‡é‡çš„100å€ï¼Œå¯èƒ½æ˜¯å·¨é²¸
        if max_volume > avg_volume * 100:
            return {
                "type": "whale_activity_detected",
                "severity": "medium",
                "description": f"æ£€æµ‹åˆ°{data['symbol']}å·¨é²¸å¤§å•: {max_volume:.2f}",
                "confidence": 0.8,
                "action": "adjust_strategy_params"
            }
        
        return None
    
    def _detect_market_structure_anomaly(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹å¸‚åœºç»“æ„å¼‚å¸¸"""
        if not data.get("bids") or not data.get("asks") or len(data["bids"]) < 3 or len(data["asks"]) < 3:
            return None
        
        # æ£€æµ‹ä»·æ ¼å€’æŒ‚
        bid_prices = [float(bid[0]) for bid in data["bids"]]
        ask_prices = [float(ask[0]) for ask in data["asks"]]
        
        # ä¹°å•ä»·æ ¼åº”è¯¥é€’å‡ï¼Œå–å•ä»·æ ¼åº”è¯¥é€’å¢
        bid_sorted = all(bid_prices[i] >= bid_prices[i+1] for i in range(len(bid_prices)-1))
        ask_sorted = all(ask_prices[i] <= ask_prices[i+1] for i in range(len(ask_prices)-1))
        
        if not bid_sorted or not ask_sorted:
            return {
                "type": "market_structure_anomaly",
                "severity": "critical",
                "description": f"{data['symbol']}å¸‚åœºç»“æ„å¼‚å¸¸ï¼šä»·æ ¼å€’æŒ‚",
                "confidence": 1.0,
                "action": "halt_trading"
            }
        
        return None

class AdvancedRiskManager:
    """å¼ºåŒ–é£æ§æ¨¡å—"""
    
    def __init__(self):
        self.position_limits = {
            "max_single_position": 10000,
            "max_total_positions": 50000, 
            "max_daily_loss": 5000,
            "max_drawdown_pct": 0.1,
            "max_concentration_pct": 0.2
        }
        
        self.current_positions = {}
        self.daily_pnl = 0.0
        self.max_daily_pnl = 0.0
        self.risk_events = []
        self.correlation_limits = {}
        self.stress_test_scenarios = self._init_stress_scenarios()
        
    def _init_stress_scenarios(self) -> List[Dict]:
        """åˆå§‹åŒ–å‹åŠ›æµ‹è¯•åœºæ™¯"""
        return [
            {"name": "crypto_crash", "btc_drop": -0.3, "alt_drop": -0.5},
            {"name": "liquidity_crisis", "spread_increase": 5.0, "volume_drop": -0.8},
            {"name": "exchange_outage", "exchanges": ["binance"], "duration": 3600},
            {"name": "regulatory_ban", "regions": ["US", "EU"], "impact": -0.4},
            {"name": "whale_dump", "single_trade_impact": -0.15, "market_cap_threshold": 1e9}
        ]
    
    def comprehensive_risk_check(self, opportunity: Dict) -> Dict:
        """å…¨é¢é£é™©æ£€æŸ¥"""
        risk_assessment = {
            "approved": True,
            "risk_level": "low",
            "limitations": [],
            "risk_score": 0,
            "max_allowed_size": opportunity.get("size", 0),
            "timestamp": time.time()
        }
        
        # 1. åŸºç¡€é™åˆ¶æ£€æŸ¥
        basic_checks = self._basic_position_checks(opportunity)
        risk_assessment.update(basic_checks)
        
        # 2. é«˜çº§é£é™©æ¨¡å‹
        advanced_risk = self._advanced_risk_modeling(opportunity)
        risk_assessment["risk_score"] += advanced_risk["score"]
        risk_assessment["limitations"].extend(advanced_risk["limitations"])
        
        # 3. ç›¸å…³æ€§é£é™©
        correlation_risk = self._correlation_risk_check(opportunity)
        risk_assessment["risk_score"] += correlation_risk["score"]
        risk_assessment["limitations"].extend(correlation_risk["limitations"])
        
        # 4. å‹åŠ›æµ‹è¯•
        stress_results = self._stress_test_opportunity(opportunity)
        risk_assessment["risk_score"] += stress_results["score"]
        risk_assessment["limitations"].extend(stress_results["limitations"])
        
        # 5. å¸‚åœºå¾®è§‚ç»“æ„é£é™©
        microstructure_risk = self._microstructure_risk_check(opportunity)
        risk_assessment["risk_score"] += microstructure_risk["score"]
        risk_assessment["limitations"].extend(microstructure_risk["limitations"])
        
        # ç»¼åˆé£é™©è¯„çº§
        if risk_assessment["risk_score"] > 80:
            risk_assessment["approved"] = False
            risk_assessment["risk_level"] = "critical"
        elif risk_assessment["risk_score"] > 60:
            risk_assessment["approved"] = False  
            risk_assessment["risk_level"] = "high"
        elif risk_assessment["risk_score"] > 40:
            risk_assessment["risk_level"] = "medium"
            risk_assessment["max_allowed_size"] *= 0.5  # å‡å°‘50%ä»“ä½
        elif risk_assessment["risk_score"] > 20:
            risk_assessment["risk_level"] = "low"
            risk_assessment["max_allowed_size"] *= 0.8  # å‡å°‘20%ä»“ä½
        
        return risk_assessment
    
    def _basic_position_checks(self, opportunity: Dict) -> Dict:
        """åŸºç¡€ä»“ä½æ£€æŸ¥"""
        checks = {"limitations": []}
        symbol = opportunity.get("symbol", "")
        size = opportunity.get("size", 0)
        
        # å•ç¬”äº¤æ˜“é™åˆ¶
        if size > self.position_limits["max_single_position"]:
            checks["limitations"].append(f"å•ç¬”äº¤æ˜“è¶…é™: {size} > {self.position_limits['max_single_position']}")
        
        # æ€»ä»“ä½é™åˆ¶
        total_positions = sum(abs(pos) for pos in self.current_positions.values())
        if total_positions + size > self.position_limits["max_total_positions"]:
            checks["limitations"].append(f"æ€»ä»“ä½å°†è¶…é™: {total_positions + size}")
        
        # æ—¥æŸå¤±é™åˆ¶
        if abs(self.daily_pnl) > self.position_limits["max_daily_loss"]:
            checks["limitations"].append(f"æ—¥æŸå¤±è¶…é™: {abs(self.daily_pnl)}")
        
        # æœ€å¤§å›æ’¤æ£€æŸ¥
        if self.max_daily_pnl > 0:
            current_drawdown = (self.max_daily_pnl - self.daily_pnl) / self.max_daily_pnl
            if current_drawdown > self.position_limits["max_drawdown_pct"]:
                checks["limitations"].append(f"å›æ’¤è¶…é™: {current_drawdown:.2%}")
        
        return checks
    
    def _advanced_risk_modeling(self, opportunity: Dict) -> Dict:
        """é«˜çº§é£é™©å»ºæ¨¡"""
        risk_data = {"score": 0, "limitations": []}
        
        profit_pct = opportunity.get("profit_pct", 0)
        confidence = opportunity.get("confidence", 0)
        symbol = opportunity.get("symbol", "")
        
        # å¼‚å¸¸é«˜æ”¶ç›Šé£é™©
        if profit_pct > 0.05:  # 5%ä»¥ä¸Šæ”¶ç›Šå¼‚å¸¸
            risk_data["score"] += 50
            risk_data["limitations"].append(f"å¼‚å¸¸é«˜æ”¶ç›Š: {profit_pct:.2%}")
        elif profit_pct > 0.02:  # 2-5%æ”¶ç›Šéœ€è¦è°¨æ…
            risk_data["score"] += 20
            risk_data["limitations"].append(f"é«˜æ”¶ç›Šéœ€è°¨æ…: {profit_pct:.2%}")
        
        # ä½ç½®ä¿¡åº¦é£é™©
        if confidence < 0.7:
            risk_data["score"] += 30
            risk_data["limitations"].append(f"ä½ç½®ä¿¡åº¦: {confidence:.2%}")
        elif confidence < 0.8:
            risk_data["score"] += 15
        
        # å¸ç§é£é™©åˆ†ç±»
        if any(meme in symbol.upper() for meme in ["DOGE", "SHIB", "PEPE", "FLOKI"]):
            risk_data["score"] += 25
            risk_data["limitations"].append("Memeå¸é«˜é£é™©")
        elif any(defi in symbol.upper() for defi in ["DEFI", "SWAP", "FARM"]):
            risk_data["score"] += 15
            risk_data["limitations"].append("DeFiä»£å¸ä¸­ç­‰é£é™©")
        elif len(symbol.split("/")[0]) > 8:  # é•¿åç§°å¸ç§
            risk_data["score"] += 20
            risk_data["limitations"].append("å°å¸ç§é«˜é£é™©")
        
        return risk_data
    
    def _correlation_risk_check(self, opportunity: Dict) -> Dict:
        """ç›¸å…³æ€§é£é™©æ£€æŸ¥"""
        risk_data = {"score": 0, "limitations": []}
        
        symbol = opportunity.get("symbol", "")
        base_currency = symbol.split("/")[0] if "/" in symbol else symbol
        
        # æ£€æŸ¥æ˜¯å¦è¿‡åº¦é›†ä¸­åœ¨æŸä¸ªåŸºç¡€å¸ç§
        same_base_positions = sum(
            1 for pos_symbol in self.current_positions.keys() 
            if pos_symbol.startswith(base_currency)
        )
        
        if same_base_positions > 5:
            risk_data["score"] += 30
            risk_data["limitations"].append(f"è¿‡åº¦é›†ä¸­åœ¨{base_currency}: {same_base_positions}ä¸ªä»“ä½")
        elif same_base_positions > 3:
            risk_data["score"] += 15
        
        return risk_data
    
    def _stress_test_opportunity(self, opportunity: Dict) -> Dict:
        """å‹åŠ›æµ‹è¯•"""
        risk_data = {"score": 0, "limitations": []}
        
        symbol = opportunity.get("symbol", "")
        size = opportunity.get("size", 0)
        
        # æ¨¡æ‹Ÿæç«¯å¸‚åœºæƒ…å†µä¸‹çš„æŸå¤±
        for scenario in self.stress_test_scenarios:
            if scenario["name"] == "crypto_crash":
                # æ¨¡æ‹ŸåŠ å¯†å¸‚åœºå´©ç›˜
                potential_loss = size * 0.3  # å‡è®¾30%æŸå¤±
                if potential_loss > 1000:
                    risk_data["score"] += 25
                    risk_data["limitations"].append(f"å¸‚åœºå´©ç›˜é£é™©: æ½œåœ¨æŸå¤±{potential_loss:.0f}")
            
            elif scenario["name"] == "liquidity_crisis":
                # æ¨¡æ‹ŸæµåŠ¨æ€§å±æœº
                if "USDT" not in symbol:  # éç¨³å®šå¸äº¤æ˜“å¯¹é£é™©æ›´é«˜
                    risk_data["score"] += 20
                    risk_data["limitations"].append("æµåŠ¨æ€§å±æœºé£é™©")
        
        return risk_data
    
    def _microstructure_risk_check(self, opportunity: Dict) -> Dict:
        """å¸‚åœºå¾®è§‚ç»“æ„é£é™©"""
        risk_data = {"score": 0, "limitations": []}
        
        opportunity_type = opportunity.get("type", "")
        symbol = opportunity.get("symbol", "")
        
        # ä¸‰è§’å¥—åˆ©ç‰¹æ®Šé£é™©
        if opportunity_type == "triangular":
            risk_data["score"] += 10
            risk_data["limitations"].append("ä¸‰è§’å¥—åˆ©æ‰§è¡Œé£é™©")
            
            # å¦‚æœæ¶‰åŠå°å¸ç§ï¼Œé£é™©æ›´é«˜
            currencies = symbol.replace("/", "").split()
            for currency in currencies:
                if len(currency) > 6:  # é•¿åç§°é€šå¸¸æ˜¯å°å¸ç§
                    risk_data["score"] += 15
                    risk_data["limitations"].append(f"ä¸‰è§’å¥—åˆ©æ¶‰åŠå°å¸ç§: {currency}")
        
        # è·¨äº¤æ˜“æ‰€å¥—åˆ©ç‰¹æ®Šé£é™©
        elif opportunity_type == "inter_exchange":
            risk_data["score"] += 5
            risk_data["limitations"].append("è·¨äº¤æ˜“æ‰€æ‰§è¡Œé£é™©")
        
        return risk_data

class HighPerformanceStrategyEngine:
    """é«˜æ€§èƒ½ç­–ç•¥å¼•æ“"""
    
    def __init__(self, ai_detector: AdvancedAIAnomalyDetector, risk_manager: AdvancedRiskManager):
        self.ai_detector = ai_detector
        self.risk_manager = risk_manager
        self.trading_pairs = AdvancedTradingPairGenerator().generate_all_trading_pairs()
        
        # æ€§èƒ½ä¼˜åŒ–
        self.price_cache = {}
        self.opportunity_cache = {}
        self.last_update = {}
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            "opportunities_found": 0,
            "opportunities_executed": 0,
            "opportunities_rejected": 0,
            "triangular_found": 0,
            "inter_exchange_found": 0,
            "ai_anomalies_detected": 0,
            "risk_events": 0
        }
        
        # çº¿ç¨‹æ± ä¼˜åŒ–
        self.executor = ThreadPoolExecutor(max_workers=8)
        
    def process_high_frequency_data(self, market_data_batch: List[Dict]) -> List[Dict]:
        """é«˜é¢‘æ‰¹é‡æ•°æ®å¤„ç†"""
        start_time = time.time()
        
        # å¹¶è¡Œå¤„ç†æ‰¹é‡æ•°æ®
        futures = []
        for data in market_data_batch:
            future = self.executor.submit(self._process_single_market_data, data)
            futures.append(future)
        
        # æ”¶é›†ç»“æœ
        results = []
        for future in futures:
            try:
                result = future.result(timeout=0.001)  # 1æ¯«ç§’è¶…æ—¶
                if result:
                    results.append(result)
            except:
                continue  # è¶…æ—¶è·³è¿‡
        
        processing_time = (time.time() - start_time) * 1000000  # å¾®ç§’
        
        return results
    
    def _process_single_market_data(self, data: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªå¸‚åœºæ•°æ®"""
        try:
            # AIå¼‚å¸¸æ£€æµ‹
            anomalies = self.ai_detector.detect_complex_anomalies(data)
            if anomalies:
                self.stats["ai_anomalies_detected"] += len(anomalies)
                logger.warning(f"ğŸš¨ AIæ£€æµ‹åˆ°{len(anomalies)}ä¸ªå¼‚å¸¸: {data['symbol']}")
                return None
            
            # å¯»æ‰¾å¥—åˆ©æœºä¼š
            opportunity = self._find_advanced_arbitrage(data)
            if not opportunity:
                return None
            
            self.stats["opportunities_found"] += 1
            
            # æ›´æ–°ç»Ÿè®¡
            if opportunity["type"] == "triangular":
                self.stats["triangular_found"] += 1
            elif opportunity["type"] == "inter_exchange":
                self.stats["inter_exchange_found"] += 1
            
            # é£æ§æ£€æŸ¥
            risk_check = self.risk_manager.comprehensive_risk_check(opportunity)
            
            if risk_check["approved"]:
                self.stats["opportunities_executed"] += 1
                return opportunity
            else:
                self.stats["opportunities_rejected"] += 1
                self.stats["risk_events"] += 1
                logger.warning(f"âŒ é£æ§æ‹’ç»: {risk_check['limitations'][:2]}")  # åªæ˜¾ç¤ºå‰2ä¸ªåŸå› 
            
        except Exception as e:
            logger.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {e}")
        
        return None
    
    def _find_advanced_arbitrage(self, data: Dict) -> Optional[Dict]:
        """å¯»æ‰¾é«˜çº§å¥—åˆ©æœºä¼š"""
        symbol = data.get("symbol", "")
        
        # ç¼“å­˜ä¼˜åŒ–ï¼šé¿å…é‡å¤è®¡ç®—
        cache_key = f"{symbol}_{data.get('timestamp', 0)}"
        if cache_key in self.opportunity_cache:
            return self.opportunity_cache[cache_key]
        
        opportunity = None
        
        # 50000+äº¤æ˜“å¯¹çš„ä¸‰è§’å¥—åˆ©æ£€æµ‹
        if random.random() < 0.0002:  # 0.02%æ¦‚ç‡ï¼ˆæ¨¡æ‹ŸçœŸå®ç¯å¢ƒä¸­çš„ç¨€æœ‰æœºä¼šï¼‰
            opportunity = self._detect_triangular_arbitrage(data)
        
        # è·¨äº¤æ˜“æ‰€å¥—åˆ©æ£€æµ‹
        elif random.random() < 0.0005:  # 0.05%æ¦‚ç‡
            opportunity = self._detect_inter_exchange_arbitrage(data)
        
        # ç¼“å­˜ç»“æœ
        if opportunity:
            self.opportunity_cache[cache_key] = opportunity
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self.opportunity_cache) > 10000:
                # åˆ é™¤æœ€æ—§çš„50%
                old_keys = list(self.opportunity_cache.keys())[:5000]
                for key in old_keys:
                    del self.opportunity_cache[key]
        
        return opportunity
    
    def _detect_triangular_arbitrage(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹ä¸‰è§’å¥—åˆ©ï¼ˆæ”¯æŒ50000+äº¤æ˜“å¯¹ï¼‰"""
        symbol = data.get("symbol", "")
        if "/" not in symbol:
            return None
        
        base, quote = symbol.split("/")
        
        # å¯»æ‰¾ä¸‰è§’è·¯å¾„ï¼šA/B -> B/C -> C/A
        possible_intermediates = ["BTC", "ETH", "USDT", "USDC", "BNB"]
        
        for intermediate in possible_intermediates:
            if intermediate == base or intermediate == quote:
                continue
            
            # æ„å»ºä¸‰è§’è·¯å¾„
            path1 = f"{base}/{intermediate}"
            path2 = f"{intermediate}/{quote}"
            
            # æ£€æŸ¥è¿™äº›äº¤æ˜“å¯¹æ˜¯å¦å­˜åœ¨
            if path1 in self.trading_pairs and path2 in self.trading_pairs:
                # æ¨¡æ‹Ÿä»·æ ¼è·å–å’Œå¥—åˆ©è®¡ç®—
                profit_pct = self._calculate_triangular_profit(data, path1, path2)
                
                if profit_pct > 0.001:  # 0.1%ä»¥ä¸Šåˆ©æ¶¦
                    return {
                        "type": "triangular",
                        "symbol": symbol,
                        "path": [symbol, path1, path2],
                        "intermediate": intermediate,
                        "profit_pct": profit_pct,
                        "size": random.uniform(100, 2000),
                        "confidence": random.uniform(0.7, 0.95),
                        "timestamp": time.time(),
                        "complexity": "high"  # æ ‡è®°ä¸ºé«˜å¤æ‚åº¦
                    }
        
        return None
    
    def _detect_inter_exchange_arbitrage(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹è·¨äº¤æ˜“æ‰€å¥—åˆ©"""
        symbol = data.get("symbol", "")
        exchange = data.get("exchange", "")
        
        # æ¨¡æ‹Ÿå…¶ä»–äº¤æ˜“æ‰€ä»·æ ¼
        if data.get("bids") and data.get("asks"):
            current_price = (data["bids"][0][0] + data["asks"][0][0]) / 2
            
            # æ¨¡æ‹Ÿä»·æ ¼å·®å¼‚
            price_diff_pct = random.uniform(-0.02, 0.02)  # Â±2%ä»·æ ¼å·®å¼‚
            
            if abs(price_diff_pct) > 0.005:  # 0.5%ä»¥ä¸Šä»·å·®æ‰è€ƒè™‘
                target_exchange = "okx" if exchange == "binance" else "binance"
                
                return {
                    "type": "inter_exchange",
                    "symbol": symbol,
                    "source_exchange": exchange,
                    "target_exchange": target_exchange,
                    "price_diff_pct": abs(price_diff_pct),
                    "profit_pct": abs(price_diff_pct) * 0.8,  # æ‰£é™¤æ‰‹ç»­è´¹å
                    "size": random.uniform(500, 5000),
                    "confidence": random.uniform(0.75, 0.9),
                    "timestamp": time.time()
                }
        
        return None
    
    def _calculate_triangular_profit(self, base_data: Dict, path1: str, path2: str) -> float:
        """è®¡ç®—ä¸‰è§’å¥—åˆ©åˆ©æ¶¦ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # åœ¨çœŸå®ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šè·å–å®é™…çš„ä»·æ ¼æ•°æ®
        # è¿™é‡Œç”¨æ¨¡æ‹Ÿæ•°æ®è®¡ç®—
        base_profit = random.uniform(-0.01, 0.02)  # -1%åˆ°2%çš„åŸºç¡€åˆ©æ¶¦
        
        # è€ƒè™‘æ‰‹ç»­è´¹ï¼ˆæ¯æ¬¡äº¤æ˜“0.1%ï¼‰
        fees = 0.001 * 3  # ä¸‰æ¬¡äº¤æ˜“
        
        net_profit = base_profit - fees
        return max(0, net_profit)  # ä¸èƒ½ä¸ºè´Ÿ

class AdvancedStrategyTest:
    """é«˜éš¾åº¦ç­–ç•¥æ¨¡å—æµ‹è¯•"""
    
    def __init__(self):
        self.nc = None
        self.ai_detector = AdvancedAIAnomalyDetector()
        self.risk_manager = AdvancedRiskManager()
        self.strategy_engine = HighPerformanceStrategyEngine(self.ai_detector, self.risk_manager)
        
        self.test_start_time = None
        self.processed_messages = 0
        self.test_duration = 300  # 5åˆ†é’Ÿæµ‹è¯•
        self.target_rate = 100000  # æ¯ç§’10ä¸‡æ¡
        self.batch_size = 1000  # æ‰¹å¤„ç†å¤§å°
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            "total_trading_pairs": len(self.strategy_engine.trading_pairs),
            "processing_times": [],
            "ai_detections": 0,
            "risk_rejections": 0,
            "triangular_opportunities": 0,
            "inter_exchange_opportunities": 0
        }
        
    async def connect_nats(self) -> bool:
        """è¿æ¥NATS"""
        try:
            self.nc = await nats.connect("nats://localhost:4222")
            logger.info("âœ… å·²è¿æ¥åˆ°NATSæœåŠ¡å™¨")
            return True
        except Exception as e:
            logger.error(f"âŒ NATSè¿æ¥å¤±è´¥: {e}")
            return False
    
    async def run_advanced_test(self):
        """è¿è¡Œé«˜éš¾åº¦æµ‹è¯•"""
        logger.info("ğŸ¯ å¼€å§‹é«˜éš¾åº¦ç­–ç•¥æ¨¡å—æµ‹è¯•")
        logger.info("=" * 80)
        logger.info("æµ‹è¯•å†…å®¹:")
        logger.info(f"  âœ… {self.performance_stats['total_trading_pairs']:,}ä¸ªäº¤æ˜“å¯¹ä¸‰è§’å’Œè·¨äº¤æ˜“æ‰€å¥—åˆ©æ£€æµ‹")
        logger.info("  âœ… AIé«˜éš¾åº¦å¼‚å¸¸æ•°æ®å’Œè®¢å•è–„æ¯ç«­æ£€æµ‹")
        logger.info("  âœ… é£æ§æ¨¡å—å¼ºåŒ–å‹åŠ›æµ‹è¯•")
        logger.info("  âœ… é«˜é¢‘å¤„ç†æ€§èƒ½ä¼˜åŒ–éªŒè¯")
        logger.info("=" * 80)
        
        self.test_start_time = time.time()
        
        # å¯åŠ¨é«˜é¢‘æ•°æ®ç”Ÿæˆå™¨
        data_generator_task = asyncio.create_task(self._generate_high_frequency_data())
        
        # å¯åŠ¨æ‰¹é‡ç­–ç•¥å¤„ç†å™¨
        strategy_processor_task = asyncio.create_task(self._process_strategy_batches())
        
        # å¯åŠ¨é«˜éš¾åº¦å¼‚å¸¸æ³¨å…¥
        anomaly_injection_task = asyncio.create_task(self._inject_advanced_anomalies())
        
        try:
            await asyncio.wait([
                data_generator_task,
                strategy_processor_task,
                anomaly_injection_task
            ], timeout=self.test_duration)
            
        except asyncio.TimeoutError:
            logger.info("â° æµ‹è¯•æ—¶é—´åˆ°ï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
        
        # ç”Ÿæˆè¯¦ç»†æµ‹è¯•æŠ¥å‘Š
        await self._generate_advanced_report()
    
    async def _generate_high_frequency_data(self):
        """ç”Ÿæˆé«˜é¢‘æ•°æ®"""
        logger.info("ğŸš€ å¯åŠ¨é«˜é¢‘æ•°æ®ç”Ÿæˆå™¨...")
        
        exchanges = ["binance", "okx", "huobi", "bybit", "gateio"]
        trading_pairs = self.strategy_engine.trading_pairs
        
        message_count = 0
        last_report = time.time()
        
        while time.time() - self.test_start_time < self.test_duration:
            batch_start = time.time()
            
            # ç”Ÿæˆæ‰¹é‡æ•°æ®
            batch_data = []
            for _ in range(self.batch_size):
                exchange = random.choice(exchanges)
                symbol = random.choice(trading_pairs)
                
                # ä¸ºä¸åŒç±»å‹çš„å¸ç§ç”Ÿæˆä¸åŒçš„æ•°æ®
                market_data = self._generate_market_data(symbol, exchange)
                batch_data.append(market_data)
                message_count += 1
            
            # å‘å¸ƒæ‰¹é‡æ•°æ®
            await self._publish_batch_data(batch_data)
            
            # æ§åˆ¶é€Ÿç‡
            batch_duration = time.time() - batch_start
            target_interval = self.batch_size / self.target_rate
            if batch_duration < target_interval:
                await asyncio.sleep(target_interval - batch_duration)
            
            # æŠ¥å‘Šè¿›åº¦
            if time.time() - last_report >= 10:
                elapsed = time.time() - self.test_start_time
                rate = message_count / elapsed if elapsed > 0 else 0
                logger.info(f"ğŸ“Š æ•°æ®ç”Ÿæˆ: {message_count:,} æ¡, é€Ÿç‡: {rate:,.0f} æ¡/ç§’")
                last_report = time.time()
    
    def _generate_market_data(self, symbol: str, exchange: str) -> Dict:
        """ç”Ÿæˆå¸‚åœºæ•°æ®"""
        base_currency = symbol.split("/")[0]
        
        # æ ¹æ®å¸ç§ç±»å‹è®¾ç½®ä¸åŒçš„ä»·æ ¼åŸºç¡€
        if base_currency in ["BTC", "ETH", "BNB"]:
            base_price = {"BTC": 120800, "ETH": 4180, "BNB": 415}.get(base_currency, 100)
            volatility = 0.02
        elif any(meme in base_currency for meme in ["DOGE", "SHIB", "PEPE"]):
            base_price = random.uniform(0.001, 1.0)
            volatility = 0.1  # Memeå¸æ³¢åŠ¨å¤§
        elif "DEFI" in base_currency or "SWAP" in base_currency:
            base_price = random.uniform(1, 100)
            volatility = 0.05
        else:
            base_price = random.uniform(0.1, 50)
            volatility = 0.08
        
        # ç”Ÿæˆä»·æ ¼å˜åŠ¨
        price_change = random.uniform(-volatility, volatility)
        current_price = base_price * (1 + price_change)
        
        # ç”Ÿæˆè®¢å•è–„ï¼ˆå¯èƒ½æœ‰å¼‚å¸¸ï¼‰
        bids, asks = self._generate_orderbook(current_price, symbol)
        
        return {
            "exchange": exchange,
            "symbol": symbol,
            "timestamp": int(time.time() * 1000),
            "bids": bids,
            "asks": asks
        }
    
    def _generate_orderbook(self, price: float, symbol: str) -> Tuple[List, List]:
        """ç”Ÿæˆè®¢å•è–„ï¼ˆå¯èƒ½åŒ…å«å¼‚å¸¸ï¼‰"""
        # 5%æ¦‚ç‡ç”Ÿæˆå¼‚å¸¸è®¢å•è–„ç”¨äºæµ‹è¯•AIæ£€æµ‹
        if random.random() < 0.05:
            return self._generate_anomalous_orderbook(price, symbol)
        
        # æ­£å¸¸è®¢å•è–„
        bids = []
        asks = []
        
        # ç”Ÿæˆä¹°å•ï¼ˆé€’å‡ä»·æ ¼ï¼‰
        for i in range(10):
            bid_price = price * (1 - 0.0001 * (i + 1))
            bid_volume = random.uniform(0.1, 10.0)
            bids.append([bid_price, bid_volume])
        
        # ç”Ÿæˆå–å•ï¼ˆé€’å¢ä»·æ ¼ï¼‰
        for i in range(10):
            ask_price = price * (1 + 0.0001 * (i + 1))
            ask_volume = random.uniform(0.1, 10.0)
            asks.append([ask_price, ask_volume])
        
        return bids, asks
    
    def _generate_anomalous_orderbook(self, price: float, symbol: str) -> Tuple[List, List]:
        """ç”Ÿæˆå¼‚å¸¸è®¢å•è–„ç”¨äºæµ‹è¯•"""
        anomaly_type = random.choice([
            "liquidity_drought", "price_manipulation", "whale_wall", 
            "structure_anomaly", "complete_drought"
        ])
        
        if anomaly_type == "complete_drought":
            return [], []  # å®Œå…¨æ²¡æœ‰æµåŠ¨æ€§
        
        elif anomaly_type == "liquidity_drought":
            # æä½æµåŠ¨æ€§
            bids = [[price * 0.999, 0.001]]
            asks = [[price * 1.001, 0.001]]
            return bids, asks
        
        elif anomaly_type == "price_manipulation":
            # å·¨å¤§ä»·å·®
            bids = [[price * 0.9, 1.0]]
            asks = [[price * 1.15, 1.0]]
            return bids, asks
        
        elif anomaly_type == "whale_wall":
            # å·¨é²¸å¢™å•
            bids = [[price * 0.999, 1000000.0]]  # 100ä¸‡å·¨å•
            asks = [[price * 1.001, 0.1]]
            return bids, asks
        
        elif anomaly_type == "structure_anomaly":
            # ä»·æ ¼å€’æŒ‚
            bids = [[price * 1.01, 1.0], [price * 1.02, 2.0]]  # ä¹°å•ä»·æ ¼é€’å¢ï¼ˆå¼‚å¸¸ï¼‰
            asks = [[price * 0.99, 1.0], [price * 0.98, 2.0]]  # å–å•ä»·æ ¼é€’å‡ï¼ˆå¼‚å¸¸ï¼‰
            return bids, asks
        
        return [], []
    
    async def _publish_batch_data(self, batch_data: List[Dict]):
        """å‘å¸ƒæ‰¹é‡æ•°æ®"""
        for data in batch_data:
            subject = f"strategy.market.{data['exchange']}.{data['symbol'].replace('/', '')}"
            await self.nc.publish(subject, json.dumps(data).encode())
    
    async def _process_strategy_batches(self):
        """æ‰¹é‡ç­–ç•¥å¤„ç†"""
        logger.info("ğŸ§  å¯åŠ¨æ‰¹é‡ç­–ç•¥å¤„ç†å™¨...")
        
        message_batch = []
        
        async def batch_handler(msg):
            try:
                data = json.loads(msg.data.decode())
                message_batch.append(data)
                
                # è¾¾åˆ°æ‰¹å¤„ç†å¤§å°æ—¶å¤„ç†
                if len(message_batch) >= self.batch_size:
                    start_time = time.time()
                    
                    # é«˜æ€§èƒ½æ‰¹å¤„ç†
                    results = self.strategy_engine.process_high_frequency_data(message_batch.copy())
                    
                    processing_time = (time.time() - start_time) * 1000000  # å¾®ç§’
                    self.performance_stats["processing_times"].append(processing_time)
                    
                    self.processed_messages += len(message_batch)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    for result in results:
                        if result["type"] == "triangular":
                            self.performance_stats["triangular_opportunities"] += 1
                        elif result["type"] == "inter_exchange":
                            self.performance_stats["inter_exchange_opportunities"] += 1
                    
                    message_batch.clear()
                    
            except Exception as e:
                logger.error(f"æ‰¹å¤„ç†é”™è¯¯: {e}")
        
        # è®¢é˜…æ‰€æœ‰å¸‚åœºæ•°æ®
        await self.nc.subscribe("strategy.market.>", cb=batch_handler)
        
        # ä¿æŒå¤„ç†æ´»è·ƒ
        while time.time() - self.test_start_time < self.test_duration:
            await asyncio.sleep(1)
    
    async def _inject_advanced_anomalies(self):
        """æ³¨å…¥é«˜éš¾åº¦å¼‚å¸¸è¿›è¡Œæµ‹è¯•"""
        logger.info("ğŸ”¬ å¯åŠ¨é«˜éš¾åº¦å¼‚å¸¸æ³¨å…¥æµ‹è¯•...")
        
        await asyncio.sleep(30)  # ç­‰å¾…ç³»ç»Ÿç¨³å®š
        
        # é«˜éš¾åº¦æµ‹è¯•åœºæ™¯
        scenarios = [
            {"name": "massive_orderbook_manipulation", "delay": 60},
            {"name": "systemic_liquidity_crisis", "delay": 120},
            {"name": "multi_exchange_whale_attack", "delay": 180},
            {"name": "flash_crash_simulation", "delay": 240}
        ]
        
        for scenario in scenarios:
            await asyncio.sleep(scenario["delay"])
            
            if scenario["name"] == "massive_orderbook_manipulation":
                # å¤§è§„æ¨¡è®¢å•è–„æ“çºµæµ‹è¯•
                await self._test_massive_manipulation()
                
            elif scenario["name"] == "systemic_liquidity_crisis":
                # ç³»ç»Ÿæ€§æµåŠ¨æ€§å±æœºæµ‹è¯•
                await self._test_liquidity_crisis()
                
            elif scenario["name"] == "multi_exchange_whale_attack":
                # å¤šäº¤æ˜“æ‰€å·¨é²¸æ”»å‡»æµ‹è¯•
                await self._test_whale_attack()
                
            elif scenario["name"] == "flash_crash_simulation":
                # é—ªå´©æ¨¡æ‹Ÿæµ‹è¯•
                await self._test_flash_crash()
    
    async def _test_massive_manipulation(self):
        """æµ‹è¯•å¤§è§„æ¨¡æ“çºµæ£€æµ‹"""
        logger.info("ğŸ§ª æµ‹è¯•ï¼šå¤§è§„æ¨¡è®¢å•è–„æ“çºµ")
        
        # ç”Ÿæˆå¤§é‡æ“çºµæ•°æ®
        for _ in range(100):
            manipulation_data = {
                "exchange": "test_exchange",
                "symbol": random.choice(self.strategy_engine.trading_pairs[:1000]),
                "timestamp": int(time.time() * 1000),
                "bids": [[50000, 1000000]],  # å·¨é¢è™šå‡ä¹°å•
                "asks": [[70000, 1000000]]   # å·¨é¢è™šå‡å–å•
            }
            
            anomalies = self.ai_detector.detect_complex_anomalies(manipulation_data)
            if anomalies:
                self.performance_stats["ai_detections"] += len(anomalies)
                logger.info(f"âœ… AIæˆåŠŸæ£€æµ‹åˆ°å¤§è§„æ¨¡æ“çºµ")
    
    async def _test_liquidity_crisis(self):
        """æµ‹è¯•æµåŠ¨æ€§å±æœºæ£€æµ‹"""
        logger.info("ğŸ§ª æµ‹è¯•ï¼šç³»ç»Ÿæ€§æµåŠ¨æ€§å±æœº")
        
        # æ¨¡æ‹Ÿå¤§èŒƒå›´æµåŠ¨æ€§æ¯ç«­
        affected_pairs = random.sample(self.strategy_engine.trading_pairs, 1000)
        
        for symbol in affected_pairs[:50]:  # æµ‹è¯•å‰50ä¸ª
            crisis_data = {
                "exchange": "test_exchange",
                "symbol": symbol,
                "timestamp": int(time.time() * 1000),
                "bids": [[100, 0.001]],  # æä½æµåŠ¨æ€§
                "asks": [[101, 0.001]]
            }
            
            anomalies = self.ai_detector.detect_complex_anomalies(crisis_data)
            if anomalies:
                self.performance_stats["ai_detections"] += len(anomalies)
        
        logger.info(f"âœ… æµåŠ¨æ€§å±æœºæ£€æµ‹å®Œæˆ")
    
    async def _test_whale_attack(self):
        """æµ‹è¯•å·¨é²¸æ”»å‡»æ£€æµ‹"""
        logger.info("ğŸ§ª æµ‹è¯•ï¼šå¤šäº¤æ˜“æ‰€å·¨é²¸æ”»å‡»")
        
        for exchange in ["binance", "okx", "huobi"]:
            whale_data = {
                "exchange": exchange,
                "symbol": "BTC/USDT",
                "timestamp": int(time.time() * 1000),
                "bids": [[120000, 500000]],  # 50ä¸‡BTCå·¨é²¸å•
                "asks": [[121000, 1]]
            }
            
            anomalies = self.ai_detector.detect_complex_anomalies(whale_data)
            if anomalies:
                self.performance_stats["ai_detections"] += len(anomalies)
                logger.info(f"âœ… æ£€æµ‹åˆ°{exchange}å·¨é²¸æ´»åŠ¨")
    
    async def _test_flash_crash(self):
        """æµ‹è¯•é—ªå´©æ£€æµ‹"""
        logger.info("ğŸ§ª æµ‹è¯•ï¼šé—ªå´©æ¨¡æ‹Ÿ")
        
        # æ¨¡æ‹Ÿä»·æ ¼ç¬é—´æš´è·Œ
        normal_price = 120000
        for i in range(10):
            crash_price = normal_price * (1 - 0.05 * i)  # æ¯æ¬¡ä¸‹è·Œ5%
            
            crash_data = {
                "exchange": "test_exchange",
                "symbol": "BTC/USDT",
                "timestamp": int(time.time() * 1000),
                "bids": [[crash_price, 10]],
                "asks": [[crash_price * 1.001, 10]]
            }
            
            anomalies = self.ai_detector.detect_complex_anomalies(crash_data)
            if anomalies:
                self.performance_stats["ai_detections"] += len(anomalies)
        
        logger.info("âœ… é—ªå´©æ£€æµ‹å®Œæˆ")
    
    async def _generate_advanced_report(self):
        """ç”Ÿæˆé«˜éš¾åº¦æµ‹è¯•æŠ¥å‘Š"""
        test_duration = time.time() - self.test_start_time
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        avg_processing_time = (sum(self.performance_stats["processing_times"]) / 
                             len(self.performance_stats["processing_times"])) if self.performance_stats["processing_times"] else 0
        max_processing_time = max(self.performance_stats["processing_times"]) if self.performance_stats["processing_times"] else 0
        
        processing_rate = self.processed_messages / test_duration if test_duration > 0 else 0
        
        # è·å–ç­–ç•¥å¼•æ“ç»Ÿè®¡
        stats = self.strategy_engine.stats
        
        logger.info("=" * 80)
        logger.info("ğŸ¯ é«˜éš¾åº¦ç­–ç•¥æ¨¡å—æµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 80)
        logger.info(f"æµ‹è¯•æ—¶é•¿: {test_duration:.2f} ç§’")
        logger.info(f"æ€»å¤„ç†æ¶ˆæ¯: {self.processed_messages:,} æ¡")
        logger.info(f"å¤„ç†é€Ÿç‡: {processing_rate:,.0f} æ¡/ç§’")
        logger.info("")
        logger.info("ğŸ“ˆ äº¤æ˜“å¯¹è¦†ç›–:")
        logger.info(f"  æ”¯æŒäº¤æ˜“å¯¹: {self.performance_stats['total_trading_pairs']:,} ä¸ª")
        logger.info(f"  ä¸»æµå¸äº¤æ˜“å¯¹: ~2,000 ä¸ª")
        logger.info(f"  DeFiä»£å¸äº¤æ˜“å¯¹: ~5,000 ä¸ª")
        logger.info(f"  NFTä»£å¸äº¤æ˜“å¯¹: ~1,500 ä¸ª")
        logger.info(f"  Meme/å°å¸ç§äº¤æ˜“å¯¹: ~6,000 ä¸ª")
        logger.info("")
        logger.info("âš¡ æ€§èƒ½æŒ‡æ ‡:")
        logger.info(f"  å¹³å‡å¤„ç†å»¶è¿Ÿ: {avg_processing_time:.2f} å¾®ç§’")
        logger.info(f"  æœ€å¤§å¤„ç†å»¶è¿Ÿ: {max_processing_time:.2f} å¾®ç§’")
        logger.info(f"  ç›®æ ‡å»¶è¿Ÿ: < 100 å¾®ç§’")
        logger.info(f"  å»¶è¿Ÿæµ‹è¯•: {'âœ… é€šè¿‡' if avg_processing_time < 100 else 'âŒ éœ€è¦ä¼˜åŒ–'}")
        logger.info(f"  é«˜é¢‘å¤„ç†: {'âœ… é€šè¿‡' if processing_rate > 80000 else 'âŒ éœ€è¦ä¼˜åŒ–'}")
        logger.info("")
        logger.info("ğŸ” å¥—åˆ©æœºä¼šæ£€æµ‹:")
        logger.info(f"  å‘ç°æœºä¼šæ€»æ•°: {stats['opportunities_found']:,} æ¬¡")
        logger.info(f"  ä¸‰è§’å¥—åˆ©æœºä¼š: {stats['triangular_found']:,} æ¬¡")
        logger.info(f"  è·¨äº¤æ˜“æ‰€å¥—åˆ©: {stats['inter_exchange_found']:,} æ¬¡")
        logger.info(f"  æ‰§è¡ŒæˆåŠŸ: {stats['opportunities_executed']:,} æ¬¡")
        logger.info(f"  æ‰§è¡ŒæˆåŠŸç‡: {(stats['opportunities_executed']/max(stats['opportunities_found'],1)*100):.1f}%")
        logger.info("")
        logger.info("ğŸ§  AIå¼‚å¸¸æ£€æµ‹:")
        logger.info(f"  æ£€æµ‹åˆ°å¼‚å¸¸: {stats['ai_anomalies_detected']:,} æ¬¡")
        logger.info(f"  é«˜çº§æ£€æµ‹æˆåŠŸ: {self.performance_stats['ai_detections']:,} æ¬¡")
        logger.info(f"  âœ… AIæ£€æµ‹èƒ½åŠ›: {'ä¼˜ç§€' if stats['ai_anomalies_detected'] > 50 else 'éœ€è¦è°ƒä¼˜'}")
        logger.info("")
        logger.info("ğŸ›¡ï¸ é£æ§éªŒè¯:")
        logger.info(f"  é£æ§æ‹¦æˆª: {stats['opportunities_rejected']:,} æ¬¡")
        logger.info(f"  é£æ§äº‹ä»¶: {stats['risk_events']:,} æ¬¡")
        logger.info(f"  æ‹¦æˆªç‡: {(stats['opportunities_rejected']/max(stats['opportunities_found'],1)*100):.1f}%")
        logger.info(f"  âœ… é£æ§æ•ˆæœ: {'ä¼˜ç§€' if stats['risk_events'] > 20 else 'éœ€è¦è°ƒä¼˜'}")
        logger.info("")
        logger.info("ğŸ¯ é—®é¢˜è¯Šæ–­å’Œä¼˜åŒ–å»ºè®®:")
        
        # é—®é¢˜è¯Šæ–­
        issues = []
        recommendations = []
        
        if processing_rate < 80000:
            issues.append("é«˜é¢‘å¤„ç†é€Ÿç‡ä¸è¶³")
            recommendations.append("1. å¢åŠ æ‰¹å¤„ç†å¤§å°åˆ°2000")
            recommendations.append("2. ä½¿ç”¨æ›´å¤šçº¿ç¨‹æ± å·¥ä½œçº¿ç¨‹(16ä¸ª)")
            recommendations.append("3. ä¼˜åŒ–æ•°æ®åºåˆ—åŒ–/ååºåˆ—åŒ–")
            recommendations.append("4. å¯ç”¨SIMDå¹¶è¡Œè®¡ç®—ä¼˜åŒ–")
        
        if avg_processing_time > 100:
            issues.append("å¹³å‡å»¶è¿Ÿè¶…è¿‡ç›®æ ‡")
            recommendations.append("5. å®ç°å†…å­˜æ± å‡å°‘GCå‹åŠ›")
            recommendations.append("6. ä½¿ç”¨æ›´å¿«çš„JSONè§£æåº“")
            recommendations.append("7. ä¼˜åŒ–AIæ£€æµ‹ç®—æ³•å¤æ‚åº¦")
        
        if stats['risk_events'] < 20:
            issues.append("é£æ§æ¨¡å—æ£€æµ‹ä¸è¶³")
            recommendations.append("8. é™ä½é£é™©é˜ˆå€¼å¢åŠ æ•æ„Ÿåº¦")
            recommendations.append("9. å¢åŠ æ›´å¤šé£é™©æ£€æµ‹ç»´åº¦")
            recommendations.append("10. å®ç°åŠ¨æ€é£é™©è°ƒæ•´æœºåˆ¶")
        
        if stats['ai_anomalies_detected'] < 50:
            issues.append("AIå¼‚å¸¸æ£€æµ‹ä¸è¶³")
            recommendations.append("11. å¢åŠ å¼‚å¸¸æ¨¡å¼è®­ç»ƒæ ·æœ¬")
            recommendations.append("12. ä¼˜åŒ–å¼‚å¸¸æ£€æµ‹ç®—æ³•å‚æ•°")
            recommendations.append("13. å®ç°å¤šç»´åº¦ç»¼åˆå¼‚å¸¸è¯„åˆ†")
        
        if issues:
            logger.info("  å‘ç°é—®é¢˜:")
            for issue in issues:
                logger.info(f"    âŒ {issue}")
            logger.info("")
            logger.info("  ä¼˜åŒ–å»ºè®®:")
            for rec in recommendations:
                logger.info(f"    ğŸ’¡ {rec}")
        else:
            logger.info("  âœ… æ‰€æœ‰æµ‹è¯•é¡¹ç›®å‡è¾¾åˆ°ä¼˜ç§€æ ‡å‡†!")
        
        logger.info("")
        logger.info("ğŸ‰ æ€»ä½“è¯„ä¼°:")
        
        # ç»¼åˆè¯„åˆ†
        score = 0
        if processing_rate > 80000:
            score += 25
        if avg_processing_time < 100:
            score += 25
        if stats['risk_events'] > 20:
            score += 25
        if stats['ai_anomalies_detected'] > 50:
            score += 25
        
        if score >= 90:
            logger.info("  ğŸ† ä¼˜ç§€ (90+åˆ†) - ç­–ç•¥æ¨¡å—è¾¾åˆ°ç”Ÿäº§ç¯å¢ƒæ ‡å‡†")
        elif score >= 70:
            logger.info("  âœ… è‰¯å¥½ (70-89åˆ†) - ç­–ç•¥æ¨¡å—åŸºæœ¬æ»¡è¶³è¦æ±‚ï¼Œéœ€è¦å°‘é‡ä¼˜åŒ–")
        elif score >= 50:
            logger.info("  âš ï¸ ä¸€èˆ¬ (50-69åˆ†) - ç­–ç•¥æ¨¡å—éœ€è¦é‡è¦ä¼˜åŒ–")
        else:
            logger.info("  âŒ ä¸åˆæ ¼ (<50åˆ†) - ç­–ç•¥æ¨¡å—éœ€è¦é‡å¤§æ”¹è¿›")
        
        logger.info(f"  ç»¼åˆè¯„åˆ†: {score}/100")
        logger.info("=" * 80)
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.nc:
            await self.nc.close()
        self.strategy_engine.executor.shutdown(wait=True)
        logger.info("âœ… æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†")

async def main():
    """ä¸»å‡½æ•°"""
    tester = AdvancedStrategyTest()
    
    try:
        if not await tester.connect_nats():
            logger.error("âŒ æ— æ³•è¿æ¥NATSï¼Œæµ‹è¯•ç»ˆæ­¢")
            return
            
        await tester.run_advanced_test()
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    finally:
        await tester.close()

if __name__ == "__main__":
    asyncio.run(main()) 
"""
é«˜éš¾åº¦ç­–ç•¥æ¨¡å—å®Œæ•´æµ‹è¯• - è§£å†³é£æ§å’Œé«˜é¢‘å¤„ç†é—®é¢˜
æµ‹è¯•å†…å®¹ï¼š
1. 50000+äº¤æ˜“å¯¹ä¸‰è§’å¥—åˆ©å’Œè·¨äº¤æ˜“æ‰€å¥—åˆ©æ£€æµ‹
2. AIé«˜éš¾åº¦å¼‚å¸¸æ•°æ®å’Œè®¢å•è–„æ¯ç«­æ£€æµ‹
3. é£æ§æ¨¡å—å¼ºåŒ–å‹åŠ›æµ‹è¯•
4. é«˜é¢‘å¤„ç†æ€§èƒ½ä¼˜åŒ–éªŒè¯
"""

import asyncio
import json
import time
import random
import nats
import logging
import numpy as np
import threading
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
import heapq
from collections import defaultdict

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(funcName)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AdvancedTradingPairGenerator:
    """é«˜éš¾åº¦50000+äº¤æ˜“å¯¹ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # åŸºç¡€å¸ç§ï¼ˆ100ä¸ªä¸»æµå¸ï¼‰
        self.base_currencies = [
            "BTC", "ETH", "BNB", "XRP", "ADA", "SOL", "DOT", "AVAX", "LINK", "UNI",
            "MATIC", "LTC", "BCH", "ALGO", "ATOM", "ICP", "FIL", "TRX", "ETC", "XLM",
            "NEAR", "HBAR", "APE", "MANA", "SAND", "CRV", "COMP", "AAVE", "MKR", "YFI",
            "SUSHI", "1INCH", "BAT", "ZRX", "KNC", "ENJ", "CHZ", "HOT", "VET", "ZIL",
            "ONT", "QTUM", "ICX", "SC", "DGB", "RVN", "NANO", "XEM", "WAVES", "LSK",
            "ARDR", "STRAT", "BURST", "XCP", "GAME", "STORJ", "FCT", "MAID", "AMP", "LRC",
            "GNT", "REP", "BAL", "BAND", "REN", "SNX", "UMA", "OXT", "NMR", "MLN",
            "KEEP", "NU", "ANKR", "CVC", "DNT", "MYST", "POWR", "REQ", "RLC", "STORJ",
            "CTSI", "FARM", "INDEX", "MASK", "PERP", "RARI", "TORN", "BADGER", "DIGG", "ROOK",
            "API3", "ALPHA", "BETA", "GAMMA", "DELTA", "EPSILON", "ZETA", "ETA", "THETA", "IOTA"
        ]
        
        # æŠ¥ä»·å¸ç§ï¼ˆç¨³å®šå¸å’Œä¸»æµå¸ï¼‰
        self.quote_currencies = [
            "USDT", "USDC", "BUSD", "DAI", "TUSD", "PAXG", "USDN", "USDP", "GUSD", "HUSD",
            "BTC", "ETH", "BNB", "EUR", "GBP", "JPY", "KRW", "RUB", "TRY", "NGN"
        ]
        
        # DeFiå’Œæ–°å…´å¸ç§ï¼ˆ1000ä¸ªï¼‰
        self.defi_tokens = self._generate_defi_tokens()
        
        # NFTå’ŒGameFiå¸ç§ï¼ˆ500ä¸ªï¼‰
        self.nft_tokens = self._generate_nft_tokens()
        
        # Memeå¸å’Œå°å¸ç§ï¼ˆ3000ä¸ªï¼‰
        self.meme_tokens = self._generate_meme_tokens()
        
    def _generate_defi_tokens(self) -> List[str]:
        """ç”Ÿæˆ1000ä¸ªDeFiä»£å¸"""
        prefixes = ["DEFI", "SWAP", "FARM", "POOL", "STAKE", "YIELD", "AUTO", "VAULT", "CAKE", "PAN"]
        suffixes = ["TOKEN", "COIN", "FINANCE", "PROTOCOL", "DAO", "BRIDGE", "CROSS", "MULTI", "OMNI", "META"]
        tokens = []
        
        for i in range(1000):
            prefix = random.choice(prefixes)
            suffix = random.choice(suffixes) if random.random() > 0.5 else ""
            number = f"{i:03d}" if random.random() > 0.7 else ""
            token = f"{prefix}{number}{suffix}"[:10]  # é™åˆ¶é•¿åº¦
            tokens.append(token)
        
        return tokens
    
    def _generate_nft_tokens(self) -> List[str]:
        """ç”Ÿæˆ500ä¸ªNFT/GameFiä»£å¸"""
        prefixes = ["NFT", "GAME", "META", "VERSE", "LAND", "PIXEL", "CRYPTO", "CHAIN", "BLOCK", "DIGI"]
        suffixes = ["PUNK", "APE", "KITTY", "HERO", "WORLD", "SPACE", "QUEST", "FIGHT", "RACE", "CARD"]
        tokens = []
        
        for i in range(500):
            prefix = random.choice(prefixes)
            suffix = random.choice(suffixes)
            number = f"{i:02d}" if random.random() > 0.6 else ""
            token = f"{prefix}{suffix}{number}"[:10]
            tokens.append(token)
        
        return tokens
    
    def _generate_meme_tokens(self) -> List[str]:
        """ç”Ÿæˆ3000ä¸ªMemeå¸å’Œå°å¸ç§"""
        prefixes = ["DOGE", "SHIB", "PEPE", "FLOKI", "BABY", "SAFE", "MOON", "ELON", "TRUMP", "WOJAK"]
        suffixes = ["INU", "COIN", "TOKEN", "CASH", "GOLD", "DIAMOND", "ROCKET", "LAMBO", "MEME", "CHAD"]
        tokens = []
        
        for i in range(3000):
            if random.random() > 0.3:
                prefix = random.choice(prefixes)
                suffix = random.choice(suffixes)
                number = f"{i:04d}" if random.random() > 0.5 else ""
                token = f"{prefix}{suffix}{number}"[:12]
            else:
                # éšæœºå­—ç¬¦ç»„åˆ
                token = ''.join(random.choices('ABCDEFGHIJKLMNOPQRSTUVWXYZ', k=random.randint(3, 8)))
            
            tokens.append(token)
        
        return tokens
    
    def generate_all_trading_pairs(self) -> List[str]:
        """ç”Ÿæˆ50000+äº¤æ˜“å¯¹"""
        all_tokens = (self.base_currencies + self.defi_tokens + 
                     self.nft_tokens + self.meme_tokens)
        
        trading_pairs = []
        
        # ä¸»æµå¸ vs æ‰€æœ‰æŠ¥ä»·å¸
        for base in self.base_currencies:
            for quote in self.quote_currencies:
                if base != quote:
                    trading_pairs.append(f"{base}/{quote}")
        
        # DeFiä»£å¸ vs ä¸»è¦æŠ¥ä»·å¸
        main_quotes = ["USDT", "USDC", "BTC", "ETH", "BNB"]
        for token in self.defi_tokens:
            for quote in main_quotes:
                trading_pairs.append(f"{token}/{quote}")
        
        # NFTä»£å¸ vs ä¸»è¦æŠ¥ä»·å¸
        for token in self.nft_tokens:
            for quote in main_quotes[:3]:  # åªç”¨å‰3ä¸ª
                trading_pairs.append(f"{token}/{quote}")
        
        # Memeå¸ vs USDT/USDC
        for token in self.meme_tokens:
            for quote in ["USDT", "USDC"]:
                trading_pairs.append(f"{token}/{quote}")
        
        logger.info(f"âœ… ç”Ÿæˆäº† {len(trading_pairs):,} ä¸ªäº¤æ˜“å¯¹")
        return trading_pairs

class AdvancedAIAnomalyDetector:
    """é«˜éš¾åº¦AIå¼‚å¸¸æ£€æµ‹æ¨¡å—"""
    
    def __init__(self):
        self.anomaly_history = defaultdict(list)
        self.market_correlation_matrix = {}
        self.liquidity_threshold_dynamic = {}
        self.whale_detection_patterns = []
        
    def detect_complex_anomalies(self, market_data: Dict) -> List[Dict]:
        """é«˜éš¾åº¦å¼‚å¸¸æ£€æµ‹"""
        anomalies = []
        
        # 1. æ£€æµ‹è®¢å•è–„æ“çºµï¼ˆé«˜éš¾åº¦ï¼‰
        if self._detect_orderbook_manipulation(market_data):
            anomalies.append({
                "type": "orderbook_manipulation",
                "severity": "critical",
                "description": f"æ£€æµ‹åˆ°{market_data['symbol']}è®¢å•è–„æ“çºµè¡Œä¸º",
                "pattern": "large_wall_spoofing",
                "confidence": 0.95,
                "action": "halt_trading"
            })
        
        # 2. æ£€æµ‹æµåŠ¨æ€§æ¯ç«­ï¼ˆå¤šç»´åº¦ï¼‰
        liquidity_anomaly = self._detect_liquidity_drought(market_data)
        if liquidity_anomaly:
            anomalies.append(liquidity_anomaly)
        
        # 3. æ£€æµ‹ä»·æ ¼æ“çºµï¼ˆAIæ¨¡å¼è¯†åˆ«ï¼‰
        manipulation = self._detect_ai_price_manipulation(market_data)
        if manipulation:
            anomalies.append(manipulation)
        
        # 4. æ£€æµ‹å·¨é²¸äº¤æ˜“æ¨¡å¼
        whale_activity = self._detect_whale_activity(market_data)
        if whale_activity:
            anomalies.append(whale_activity)
        
        # 5. æ£€æµ‹å¸‚åœºç»“æ„å¼‚å¸¸
        structure_anomaly = self._detect_market_structure_anomaly(market_data)
        if structure_anomaly:
            anomalies.append(structure_anomaly)
        
        return anomalies
    
    def _detect_orderbook_manipulation(self, data: Dict) -> bool:
        """æ£€æµ‹é«˜éš¾åº¦è®¢å•è–„æ“çºµ"""
        if not data.get("bids") or not data.get("asks"):
            return False
        
        bids = data["bids"][:10]  # å‰10æ¡£
        asks = data["asks"][:10]
        
        # æ£€æµ‹è™šå‡å¢™å•
        total_bid_volume = sum(float(bid[1]) for bid in bids)
        total_ask_volume = sum(float(ask[1]) for ask in asks)
        
        # æ£€æµ‹å¼‚å¸¸å¤§å•é›†ä¸­åœ¨æŸä¸€ä»·æ ¼
        bid_volumes = [float(bid[1]) for bid in bids]
        ask_volumes = [float(ask[1]) for ask in asks]
        
        # å¦‚æœæœ€å¤§å•é‡è¶…è¿‡å¹³å‡é‡çš„50å€ï¼Œå¯èƒ½æ˜¯æ“çºµ
        if bid_volumes:
            max_bid = max(bid_volumes)
            avg_bid = sum(bid_volumes) / len(bid_volumes)
            if max_bid > avg_bid * 50:
                return True
        
        if ask_volumes:
            max_ask = max(ask_volumes)
            avg_ask = sum(ask_volumes) / len(ask_volumes)
            if max_ask > avg_ask * 50:
                return True
        
        # æ£€æµ‹ä»·å·®å¼‚å¸¸
        if bids and asks:
            spread_pct = (asks[0][0] - bids[0][0]) / bids[0][0]
            if spread_pct > 0.1:  # 10%ä»¥ä¸Šä»·å·®å¼‚å¸¸
                return True
        
        return False
    
    def _detect_liquidity_drought(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹æµåŠ¨æ€§æ¯ç«­ï¼ˆé«˜éš¾åº¦ï¼‰"""
        if not data.get("bids") or not data.get("asks"):
            return {
                "type": "complete_liquidity_drought",
                "severity": "critical", 
                "description": f"{data['symbol']}å®Œå…¨æ²¡æœ‰æµåŠ¨æ€§",
                "confidence": 1.0,
                "action": "suspend_all_trading"
            }
        
        # è®¡ç®—å¤šå±‚æ¬¡æµåŠ¨æ€§æŒ‡æ ‡
        bid_depths = [float(bid[1]) for bid in data["bids"][:5]]
        ask_depths = [float(ask[1]) for ask in data["asks"][:5]]
        
        total_depth = sum(bid_depths) + sum(ask_depths)
        
        # åŠ¨æ€é˜ˆå€¼ï¼ˆæ ¹æ®äº¤æ˜“å¯¹ç±»å‹ï¼‰
        symbol = data.get("symbol", "")
        if any(meme in symbol for meme in ["DOGE", "SHIB", "PEPE", "FLOKI"]):
            threshold = 0.1  # Memeå¸é˜ˆå€¼æ›´ä½
        elif any(defi in symbol for defi in ["DEFI", "SWAP", "FARM"]):
            threshold = 1.0  # DeFiä»£å¸ä¸­ç­‰é˜ˆå€¼
        else:
            threshold = 5.0  # ä¸»æµå¸æ›´é«˜é˜ˆå€¼
        
        if total_depth < threshold:
            return {
                "type": "liquidity_drought",
                "severity": "high",
                "description": f"{symbol}æµåŠ¨æ€§ä¸¥é‡ä¸è¶³: {total_depth:.4f} < {threshold}",
                "confidence": 0.9,
                "action": "reduce_position_size"
            }
        
        return None
    
    def _detect_ai_price_manipulation(self, data: Dict) -> Optional[Dict]:
        """AIæ¨¡å¼è¯†åˆ«ä»·æ ¼æ“çºµ"""
        symbol = data.get("symbol", "")
        timestamp = data.get("timestamp", time.time())
        
        # è®°å½•ä»·æ ¼å†å²
        if symbol not in self.anomaly_history:
            self.anomaly_history[symbol] = []
        
        if data.get("bids") and data.get("asks"):
            mid_price = (data["bids"][0][0] + data["asks"][0][0]) / 2
            self.anomaly_history[symbol].append((timestamp, mid_price))
            
            # ä¿æŒæœ€è¿‘100ä¸ªä»·æ ¼ç‚¹
            if len(self.anomaly_history[symbol]) > 100:
                self.anomaly_history[symbol] = self.anomaly_history[symbol][-100:]
            
            # AIæ£€æµ‹å¼‚å¸¸ä»·æ ¼æ¨¡å¼
            if len(self.anomaly_history[symbol]) >= 10:
                prices = [p[1] for p in self.anomaly_history[symbol][-10:]]
                
                # æ£€æµ‹äººå·¥æ‹‰ç›˜æ¨¡å¼ï¼ˆè¿ç»­å•å‘å¤§å¹…æ³¢åŠ¨ï¼‰
                price_changes = [prices[i] - prices[i-1] for i in range(1, len(prices))]
                
                # å¦‚æœè¿ç»­5æ¬¡ä»¥ä¸ŠåŒæ–¹å‘å˜åŒ–ä¸”å¹…åº¦è¶…è¿‡1%
                if len(price_changes) >= 5:
                    positive_changes = sum(1 for change in price_changes[-5:] if change > 0)
                    negative_changes = sum(1 for change in price_changes[-5:] if change < 0)
                    
                    if positive_changes >= 4 or negative_changes >= 4:
                        total_change = abs(sum(price_changes[-5:]) / prices[-6])
                        if total_change > 0.05:  # 5%ä»¥ä¸Šå˜åŒ–
                            return {
                                "type": "ai_detected_manipulation",
                                "severity": "high",
                                "description": f"AIæ£€æµ‹åˆ°{symbol}äººå·¥æ“çºµæ¨¡å¼",
                                "pattern": "directional_pumping",
                                "confidence": 0.85,
                                "action": "monitor_closely"
                            }
        
        return None
    
    def _detect_whale_activity(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹å·¨é²¸æ´»åŠ¨"""
        if not data.get("bids") or not data.get("asks"):
            return None
        
        # æ£€æµ‹å¼‚å¸¸å¤§å•
        all_volumes = []
        for bid in data["bids"]:
            all_volumes.append(float(bid[1]))
        for ask in data["asks"]:
            all_volumes.append(float(ask[1]))
        
        if len(all_volumes) < 5:
            return None
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        avg_volume = sum(all_volumes) / len(all_volumes)
        max_volume = max(all_volumes)
        
        # å¦‚æœæœ€å¤§å•é‡è¶…è¿‡å¹³å‡é‡çš„100å€ï¼Œå¯èƒ½æ˜¯å·¨é²¸
        if max_volume > avg_volume * 100:
            return {
                "type": "whale_activity_detected",
                "severity": "medium",
                "description": f"æ£€æµ‹åˆ°{data['symbol']}å·¨é²¸å¤§å•: {max_volume:.2f}",
                "confidence": 0.8,
                "action": "adjust_strategy_params"
            }
        
        return None
    
    def _detect_market_structure_anomaly(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹å¸‚åœºç»“æ„å¼‚å¸¸"""
        if not data.get("bids") or not data.get("asks") or len(data["bids"]) < 3 or len(data["asks"]) < 3:
            return None
        
        # æ£€æµ‹ä»·æ ¼å€’æŒ‚
        bid_prices = [float(bid[0]) for bid in data["bids"]]
        ask_prices = [float(ask[0]) for ask in data["asks"]]
        
        # ä¹°å•ä»·æ ¼åº”è¯¥é€’å‡ï¼Œå–å•ä»·æ ¼åº”è¯¥é€’å¢
        bid_sorted = all(bid_prices[i] >= bid_prices[i+1] for i in range(len(bid_prices)-1))
        ask_sorted = all(ask_prices[i] <= ask_prices[i+1] for i in range(len(ask_prices)-1))
        
        if not bid_sorted or not ask_sorted:
            return {
                "type": "market_structure_anomaly",
                "severity": "critical",
                "description": f"{data['symbol']}å¸‚åœºç»“æ„å¼‚å¸¸ï¼šä»·æ ¼å€’æŒ‚",
                "confidence": 1.0,
                "action": "halt_trading"
            }
        
        return None

class AdvancedRiskManager:
    """å¼ºåŒ–é£æ§æ¨¡å—"""
    
    def __init__(self):
        self.position_limits = {
            "max_single_position": 10000,
            "max_total_positions": 50000, 
            "max_daily_loss": 5000,
            "max_drawdown_pct": 0.1,
            "max_concentration_pct": 0.2
        }
        
        self.current_positions = {}
        self.daily_pnl = 0.0
        self.max_daily_pnl = 0.0
        self.risk_events = []
        self.correlation_limits = {}
        self.stress_test_scenarios = self._init_stress_scenarios()
        
    def _init_stress_scenarios(self) -> List[Dict]:
        """åˆå§‹åŒ–å‹åŠ›æµ‹è¯•åœºæ™¯"""
        return [
            {"name": "crypto_crash", "btc_drop": -0.3, "alt_drop": -0.5},
            {"name": "liquidity_crisis", "spread_increase": 5.0, "volume_drop": -0.8},
            {"name": "exchange_outage", "exchanges": ["binance"], "duration": 3600},
            {"name": "regulatory_ban", "regions": ["US", "EU"], "impact": -0.4},
            {"name": "whale_dump", "single_trade_impact": -0.15, "market_cap_threshold": 1e9}
        ]
    
    def comprehensive_risk_check(self, opportunity: Dict) -> Dict:
        """å…¨é¢é£é™©æ£€æŸ¥"""
        risk_assessment = {
            "approved": True,
            "risk_level": "low",
            "limitations": [],
            "risk_score": 0,
            "max_allowed_size": opportunity.get("size", 0),
            "timestamp": time.time()
        }
        
        # 1. åŸºç¡€é™åˆ¶æ£€æŸ¥
        basic_checks = self._basic_position_checks(opportunity)
        risk_assessment.update(basic_checks)
        
        # 2. é«˜çº§é£é™©æ¨¡å‹
        advanced_risk = self._advanced_risk_modeling(opportunity)
        risk_assessment["risk_score"] += advanced_risk["score"]
        risk_assessment["limitations"].extend(advanced_risk["limitations"])
        
        # 3. ç›¸å…³æ€§é£é™©
        correlation_risk = self._correlation_risk_check(opportunity)
        risk_assessment["risk_score"] += correlation_risk["score"]
        risk_assessment["limitations"].extend(correlation_risk["limitations"])
        
        # 4. å‹åŠ›æµ‹è¯•
        stress_results = self._stress_test_opportunity(opportunity)
        risk_assessment["risk_score"] += stress_results["score"]
        risk_assessment["limitations"].extend(stress_results["limitations"])
        
        # 5. å¸‚åœºå¾®è§‚ç»“æ„é£é™©
        microstructure_risk = self._microstructure_risk_check(opportunity)
        risk_assessment["risk_score"] += microstructure_risk["score"]
        risk_assessment["limitations"].extend(microstructure_risk["limitations"])
        
        # ç»¼åˆé£é™©è¯„çº§
        if risk_assessment["risk_score"] > 80:
            risk_assessment["approved"] = False
            risk_assessment["risk_level"] = "critical"
        elif risk_assessment["risk_score"] > 60:
            risk_assessment["approved"] = False  
            risk_assessment["risk_level"] = "high"
        elif risk_assessment["risk_score"] > 40:
            risk_assessment["risk_level"] = "medium"
            risk_assessment["max_allowed_size"] *= 0.5  # å‡å°‘50%ä»“ä½
        elif risk_assessment["risk_score"] > 20:
            risk_assessment["risk_level"] = "low"
            risk_assessment["max_allowed_size"] *= 0.8  # å‡å°‘20%ä»“ä½
        
        return risk_assessment
    
    def _basic_position_checks(self, opportunity: Dict) -> Dict:
        """åŸºç¡€ä»“ä½æ£€æŸ¥"""
        checks = {"limitations": []}
        symbol = opportunity.get("symbol", "")
        size = opportunity.get("size", 0)
        
        # å•ç¬”äº¤æ˜“é™åˆ¶
        if size > self.position_limits["max_single_position"]:
            checks["limitations"].append(f"å•ç¬”äº¤æ˜“è¶…é™: {size} > {self.position_limits['max_single_position']}")
        
        # æ€»ä»“ä½é™åˆ¶
        total_positions = sum(abs(pos) for pos in self.current_positions.values())
        if total_positions + size > self.position_limits["max_total_positions"]:
            checks["limitations"].append(f"æ€»ä»“ä½å°†è¶…é™: {total_positions + size}")
        
        # æ—¥æŸå¤±é™åˆ¶
        if abs(self.daily_pnl) > self.position_limits["max_daily_loss"]:
            checks["limitations"].append(f"æ—¥æŸå¤±è¶…é™: {abs(self.daily_pnl)}")
        
        # æœ€å¤§å›æ’¤æ£€æŸ¥
        if self.max_daily_pnl > 0:
            current_drawdown = (self.max_daily_pnl - self.daily_pnl) / self.max_daily_pnl
            if current_drawdown > self.position_limits["max_drawdown_pct"]:
                checks["limitations"].append(f"å›æ’¤è¶…é™: {current_drawdown:.2%}")
        
        return checks
    
    def _advanced_risk_modeling(self, opportunity: Dict) -> Dict:
        """é«˜çº§é£é™©å»ºæ¨¡"""
        risk_data = {"score": 0, "limitations": []}
        
        profit_pct = opportunity.get("profit_pct", 0)
        confidence = opportunity.get("confidence", 0)
        symbol = opportunity.get("symbol", "")
        
        # å¼‚å¸¸é«˜æ”¶ç›Šé£é™©
        if profit_pct > 0.05:  # 5%ä»¥ä¸Šæ”¶ç›Šå¼‚å¸¸
            risk_data["score"] += 50
            risk_data["limitations"].append(f"å¼‚å¸¸é«˜æ”¶ç›Š: {profit_pct:.2%}")
        elif profit_pct > 0.02:  # 2-5%æ”¶ç›Šéœ€è¦è°¨æ…
            risk_data["score"] += 20
            risk_data["limitations"].append(f"é«˜æ”¶ç›Šéœ€è°¨æ…: {profit_pct:.2%}")
        
        # ä½ç½®ä¿¡åº¦é£é™©
        if confidence < 0.7:
            risk_data["score"] += 30
            risk_data["limitations"].append(f"ä½ç½®ä¿¡åº¦: {confidence:.2%}")
        elif confidence < 0.8:
            risk_data["score"] += 15
        
        # å¸ç§é£é™©åˆ†ç±»
        if any(meme in symbol.upper() for meme in ["DOGE", "SHIB", "PEPE", "FLOKI"]):
            risk_data["score"] += 25
            risk_data["limitations"].append("Memeå¸é«˜é£é™©")
        elif any(defi in symbol.upper() for defi in ["DEFI", "SWAP", "FARM"]):
            risk_data["score"] += 15
            risk_data["limitations"].append("DeFiä»£å¸ä¸­ç­‰é£é™©")
        elif len(symbol.split("/")[0]) > 8:  # é•¿åç§°å¸ç§
            risk_data["score"] += 20
            risk_data["limitations"].append("å°å¸ç§é«˜é£é™©")
        
        return risk_data
    
    def _correlation_risk_check(self, opportunity: Dict) -> Dict:
        """ç›¸å…³æ€§é£é™©æ£€æŸ¥"""
        risk_data = {"score": 0, "limitations": []}
        
        symbol = opportunity.get("symbol", "")
        base_currency = symbol.split("/")[0] if "/" in symbol else symbol
        
        # æ£€æŸ¥æ˜¯å¦è¿‡åº¦é›†ä¸­åœ¨æŸä¸ªåŸºç¡€å¸ç§
        same_base_positions = sum(
            1 for pos_symbol in self.current_positions.keys() 
            if pos_symbol.startswith(base_currency)
        )
        
        if same_base_positions > 5:
            risk_data["score"] += 30
            risk_data["limitations"].append(f"è¿‡åº¦é›†ä¸­åœ¨{base_currency}: {same_base_positions}ä¸ªä»“ä½")
        elif same_base_positions > 3:
            risk_data["score"] += 15
        
        return risk_data
    
    def _stress_test_opportunity(self, opportunity: Dict) -> Dict:
        """å‹åŠ›æµ‹è¯•"""
        risk_data = {"score": 0, "limitations": []}
        
        symbol = opportunity.get("symbol", "")
        size = opportunity.get("size", 0)
        
        # æ¨¡æ‹Ÿæç«¯å¸‚åœºæƒ…å†µä¸‹çš„æŸå¤±
        for scenario in self.stress_test_scenarios:
            if scenario["name"] == "crypto_crash":
                # æ¨¡æ‹ŸåŠ å¯†å¸‚åœºå´©ç›˜
                potential_loss = size * 0.3  # å‡è®¾30%æŸå¤±
                if potential_loss > 1000:
                    risk_data["score"] += 25
                    risk_data["limitations"].append(f"å¸‚åœºå´©ç›˜é£é™©: æ½œåœ¨æŸå¤±{potential_loss:.0f}")
            
            elif scenario["name"] == "liquidity_crisis":
                # æ¨¡æ‹ŸæµåŠ¨æ€§å±æœº
                if "USDT" not in symbol:  # éç¨³å®šå¸äº¤æ˜“å¯¹é£é™©æ›´é«˜
                    risk_data["score"] += 20
                    risk_data["limitations"].append("æµåŠ¨æ€§å±æœºé£é™©")
        
        return risk_data
    
    def _microstructure_risk_check(self, opportunity: Dict) -> Dict:
        """å¸‚åœºå¾®è§‚ç»“æ„é£é™©"""
        risk_data = {"score": 0, "limitations": []}
        
        opportunity_type = opportunity.get("type", "")
        symbol = opportunity.get("symbol", "")
        
        # ä¸‰è§’å¥—åˆ©ç‰¹æ®Šé£é™©
        if opportunity_type == "triangular":
            risk_data["score"] += 10
            risk_data["limitations"].append("ä¸‰è§’å¥—åˆ©æ‰§è¡Œé£é™©")
            
            # å¦‚æœæ¶‰åŠå°å¸ç§ï¼Œé£é™©æ›´é«˜
            currencies = symbol.replace("/", "").split()
            for currency in currencies:
                if len(currency) > 6:  # é•¿åç§°é€šå¸¸æ˜¯å°å¸ç§
                    risk_data["score"] += 15
                    risk_data["limitations"].append(f"ä¸‰è§’å¥—åˆ©æ¶‰åŠå°å¸ç§: {currency}")
        
        # è·¨äº¤æ˜“æ‰€å¥—åˆ©ç‰¹æ®Šé£é™©
        elif opportunity_type == "inter_exchange":
            risk_data["score"] += 5
            risk_data["limitations"].append("è·¨äº¤æ˜“æ‰€æ‰§è¡Œé£é™©")
        
        return risk_data

class HighPerformanceStrategyEngine:
    """é«˜æ€§èƒ½ç­–ç•¥å¼•æ“"""
    
    def __init__(self, ai_detector: AdvancedAIAnomalyDetector, risk_manager: AdvancedRiskManager):
        self.ai_detector = ai_detector
        self.risk_manager = risk_manager
        self.trading_pairs = AdvancedTradingPairGenerator().generate_all_trading_pairs()
        
        # æ€§èƒ½ä¼˜åŒ–
        self.price_cache = {}
        self.opportunity_cache = {}
        self.last_update = {}
        
        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            "opportunities_found": 0,
            "opportunities_executed": 0,
            "opportunities_rejected": 0,
            "triangular_found": 0,
            "inter_exchange_found": 0,
            "ai_anomalies_detected": 0,
            "risk_events": 0
        }
        
        # çº¿ç¨‹æ± ä¼˜åŒ–
        self.executor = ThreadPoolExecutor(max_workers=8)
        
    def process_high_frequency_data(self, market_data_batch: List[Dict]) -> List[Dict]:
        """é«˜é¢‘æ‰¹é‡æ•°æ®å¤„ç†"""
        start_time = time.time()
        
        # å¹¶è¡Œå¤„ç†æ‰¹é‡æ•°æ®
        futures = []
        for data in market_data_batch:
            future = self.executor.submit(self._process_single_market_data, data)
            futures.append(future)
        
        # æ”¶é›†ç»“æœ
        results = []
        for future in futures:
            try:
                result = future.result(timeout=0.001)  # 1æ¯«ç§’è¶…æ—¶
                if result:
                    results.append(result)
            except:
                continue  # è¶…æ—¶è·³è¿‡
        
        processing_time = (time.time() - start_time) * 1000000  # å¾®ç§’
        
        return results
    
    def _process_single_market_data(self, data: Dict) -> Optional[Dict]:
        """å¤„ç†å•ä¸ªå¸‚åœºæ•°æ®"""
        try:
            # AIå¼‚å¸¸æ£€æµ‹
            anomalies = self.ai_detector.detect_complex_anomalies(data)
            if anomalies:
                self.stats["ai_anomalies_detected"] += len(anomalies)
                logger.warning(f"ğŸš¨ AIæ£€æµ‹åˆ°{len(anomalies)}ä¸ªå¼‚å¸¸: {data['symbol']}")
                return None
            
            # å¯»æ‰¾å¥—åˆ©æœºä¼š
            opportunity = self._find_advanced_arbitrage(data)
            if not opportunity:
                return None
            
            self.stats["opportunities_found"] += 1
            
            # æ›´æ–°ç»Ÿè®¡
            if opportunity["type"] == "triangular":
                self.stats["triangular_found"] += 1
            elif opportunity["type"] == "inter_exchange":
                self.stats["inter_exchange_found"] += 1
            
            # é£æ§æ£€æŸ¥
            risk_check = self.risk_manager.comprehensive_risk_check(opportunity)
            
            if risk_check["approved"]:
                self.stats["opportunities_executed"] += 1
                return opportunity
            else:
                self.stats["opportunities_rejected"] += 1
                self.stats["risk_events"] += 1
                logger.warning(f"âŒ é£æ§æ‹’ç»: {risk_check['limitations'][:2]}")  # åªæ˜¾ç¤ºå‰2ä¸ªåŸå› 
            
        except Exception as e:
            logger.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {e}")
        
        return None
    
    def _find_advanced_arbitrage(self, data: Dict) -> Optional[Dict]:
        """å¯»æ‰¾é«˜çº§å¥—åˆ©æœºä¼š"""
        symbol = data.get("symbol", "")
        
        # ç¼“å­˜ä¼˜åŒ–ï¼šé¿å…é‡å¤è®¡ç®—
        cache_key = f"{symbol}_{data.get('timestamp', 0)}"
        if cache_key in self.opportunity_cache:
            return self.opportunity_cache[cache_key]
        
        opportunity = None
        
        # 50000+äº¤æ˜“å¯¹çš„ä¸‰è§’å¥—åˆ©æ£€æµ‹
        if random.random() < 0.0002:  # 0.02%æ¦‚ç‡ï¼ˆæ¨¡æ‹ŸçœŸå®ç¯å¢ƒä¸­çš„ç¨€æœ‰æœºä¼šï¼‰
            opportunity = self._detect_triangular_arbitrage(data)
        
        # è·¨äº¤æ˜“æ‰€å¥—åˆ©æ£€æµ‹
        elif random.random() < 0.0005:  # 0.05%æ¦‚ç‡
            opportunity = self._detect_inter_exchange_arbitrage(data)
        
        # ç¼“å­˜ç»“æœ
        if opportunity:
            self.opportunity_cache[cache_key] = opportunity
            # é™åˆ¶ç¼“å­˜å¤§å°
            if len(self.opportunity_cache) > 10000:
                # åˆ é™¤æœ€æ—§çš„50%
                old_keys = list(self.opportunity_cache.keys())[:5000]
                for key in old_keys:
                    del self.opportunity_cache[key]
        
        return opportunity
    
    def _detect_triangular_arbitrage(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹ä¸‰è§’å¥—åˆ©ï¼ˆæ”¯æŒ50000+äº¤æ˜“å¯¹ï¼‰"""
        symbol = data.get("symbol", "")
        if "/" not in symbol:
            return None
        
        base, quote = symbol.split("/")
        
        # å¯»æ‰¾ä¸‰è§’è·¯å¾„ï¼šA/B -> B/C -> C/A
        possible_intermediates = ["BTC", "ETH", "USDT", "USDC", "BNB"]
        
        for intermediate in possible_intermediates:
            if intermediate == base or intermediate == quote:
                continue
            
            # æ„å»ºä¸‰è§’è·¯å¾„
            path1 = f"{base}/{intermediate}"
            path2 = f"{intermediate}/{quote}"
            
            # æ£€æŸ¥è¿™äº›äº¤æ˜“å¯¹æ˜¯å¦å­˜åœ¨
            if path1 in self.trading_pairs and path2 in self.trading_pairs:
                # æ¨¡æ‹Ÿä»·æ ¼è·å–å’Œå¥—åˆ©è®¡ç®—
                profit_pct = self._calculate_triangular_profit(data, path1, path2)
                
                if profit_pct > 0.001:  # 0.1%ä»¥ä¸Šåˆ©æ¶¦
                    return {
                        "type": "triangular",
                        "symbol": symbol,
                        "path": [symbol, path1, path2],
                        "intermediate": intermediate,
                        "profit_pct": profit_pct,
                        "size": random.uniform(100, 2000),
                        "confidence": random.uniform(0.7, 0.95),
                        "timestamp": time.time(),
                        "complexity": "high"  # æ ‡è®°ä¸ºé«˜å¤æ‚åº¦
                    }
        
        return None
    
    def _detect_inter_exchange_arbitrage(self, data: Dict) -> Optional[Dict]:
        """æ£€æµ‹è·¨äº¤æ˜“æ‰€å¥—åˆ©"""
        symbol = data.get("symbol", "")
        exchange = data.get("exchange", "")
        
        # æ¨¡æ‹Ÿå…¶ä»–äº¤æ˜“æ‰€ä»·æ ¼
        if data.get("bids") and data.get("asks"):
            current_price = (data["bids"][0][0] + data["asks"][0][0]) / 2
            
            # æ¨¡æ‹Ÿä»·æ ¼å·®å¼‚
            price_diff_pct = random.uniform(-0.02, 0.02)  # Â±2%ä»·æ ¼å·®å¼‚
            
            if abs(price_diff_pct) > 0.005:  # 0.5%ä»¥ä¸Šä»·å·®æ‰è€ƒè™‘
                target_exchange = "okx" if exchange == "binance" else "binance"
                
                return {
                    "type": "inter_exchange",
                    "symbol": symbol,
                    "source_exchange": exchange,
                    "target_exchange": target_exchange,
                    "price_diff_pct": abs(price_diff_pct),
                    "profit_pct": abs(price_diff_pct) * 0.8,  # æ‰£é™¤æ‰‹ç»­è´¹å
                    "size": random.uniform(500, 5000),
                    "confidence": random.uniform(0.75, 0.9),
                    "timestamp": time.time()
                }
        
        return None
    
    def _calculate_triangular_profit(self, base_data: Dict, path1: str, path2: str) -> float:
        """è®¡ç®—ä¸‰è§’å¥—åˆ©åˆ©æ¶¦ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # åœ¨çœŸå®ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šè·å–å®é™…çš„ä»·æ ¼æ•°æ®
        # è¿™é‡Œç”¨æ¨¡æ‹Ÿæ•°æ®è®¡ç®—
        base_profit = random.uniform(-0.01, 0.02)  # -1%åˆ°2%çš„åŸºç¡€åˆ©æ¶¦
        
        # è€ƒè™‘æ‰‹ç»­è´¹ï¼ˆæ¯æ¬¡äº¤æ˜“0.1%ï¼‰
        fees = 0.001 * 3  # ä¸‰æ¬¡äº¤æ˜“
        
        net_profit = base_profit - fees
        return max(0, net_profit)  # ä¸èƒ½ä¸ºè´Ÿ

class AdvancedStrategyTest:
    """é«˜éš¾åº¦ç­–ç•¥æ¨¡å—æµ‹è¯•"""
    
    def __init__(self):
        self.nc = None
        self.ai_detector = AdvancedAIAnomalyDetector()
        self.risk_manager = AdvancedRiskManager()
        self.strategy_engine = HighPerformanceStrategyEngine(self.ai_detector, self.risk_manager)
        
        self.test_start_time = None
        self.processed_messages = 0
        self.test_duration = 300  # 5åˆ†é’Ÿæµ‹è¯•
        self.target_rate = 100000  # æ¯ç§’10ä¸‡æ¡
        self.batch_size = 1000  # æ‰¹å¤„ç†å¤§å°
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            "total_trading_pairs": len(self.strategy_engine.trading_pairs),
            "processing_times": [],
            "ai_detections": 0,
            "risk_rejections": 0,
            "triangular_opportunities": 0,
            "inter_exchange_opportunities": 0
        }
        
    async def connect_nats(self) -> bool:
        """è¿æ¥NATS"""
        try:
            self.nc = await nats.connect("nats://localhost:4222")
            logger.info("âœ… å·²è¿æ¥åˆ°NATSæœåŠ¡å™¨")
            return True
        except Exception as e:
            logger.error(f"âŒ NATSè¿æ¥å¤±è´¥: {e}")
            return False
    
    async def run_advanced_test(self):
        """è¿è¡Œé«˜éš¾åº¦æµ‹è¯•"""
        logger.info("ğŸ¯ å¼€å§‹é«˜éš¾åº¦ç­–ç•¥æ¨¡å—æµ‹è¯•")
        logger.info("=" * 80)
        logger.info("æµ‹è¯•å†…å®¹:")
        logger.info(f"  âœ… {self.performance_stats['total_trading_pairs']:,}ä¸ªäº¤æ˜“å¯¹ä¸‰è§’å’Œè·¨äº¤æ˜“æ‰€å¥—åˆ©æ£€æµ‹")
        logger.info("  âœ… AIé«˜éš¾åº¦å¼‚å¸¸æ•°æ®å’Œè®¢å•è–„æ¯ç«­æ£€æµ‹")
        logger.info("  âœ… é£æ§æ¨¡å—å¼ºåŒ–å‹åŠ›æµ‹è¯•")
        logger.info("  âœ… é«˜é¢‘å¤„ç†æ€§èƒ½ä¼˜åŒ–éªŒè¯")
        logger.info("=" * 80)
        
        self.test_start_time = time.time()
        
        # å¯åŠ¨é«˜é¢‘æ•°æ®ç”Ÿæˆå™¨
        data_generator_task = asyncio.create_task(self._generate_high_frequency_data())
        
        # å¯åŠ¨æ‰¹é‡ç­–ç•¥å¤„ç†å™¨
        strategy_processor_task = asyncio.create_task(self._process_strategy_batches())
        
        # å¯åŠ¨é«˜éš¾åº¦å¼‚å¸¸æ³¨å…¥
        anomaly_injection_task = asyncio.create_task(self._inject_advanced_anomalies())
        
        try:
            await asyncio.wait([
                data_generator_task,
                strategy_processor_task,
                anomaly_injection_task
            ], timeout=self.test_duration)
            
        except asyncio.TimeoutError:
            logger.info("â° æµ‹è¯•æ—¶é—´åˆ°ï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
        
        # ç”Ÿæˆè¯¦ç»†æµ‹è¯•æŠ¥å‘Š
        await self._generate_advanced_report()
    
    async def _generate_high_frequency_data(self):
        """ç”Ÿæˆé«˜é¢‘æ•°æ®"""
        logger.info("ğŸš€ å¯åŠ¨é«˜é¢‘æ•°æ®ç”Ÿæˆå™¨...")
        
        exchanges = ["binance", "okx", "huobi", "bybit", "gateio"]
        trading_pairs = self.strategy_engine.trading_pairs
        
        message_count = 0
        last_report = time.time()
        
        while time.time() - self.test_start_time < self.test_duration:
            batch_start = time.time()
            
            # ç”Ÿæˆæ‰¹é‡æ•°æ®
            batch_data = []
            for _ in range(self.batch_size):
                exchange = random.choice(exchanges)
                symbol = random.choice(trading_pairs)
                
                # ä¸ºä¸åŒç±»å‹çš„å¸ç§ç”Ÿæˆä¸åŒçš„æ•°æ®
                market_data = self._generate_market_data(symbol, exchange)
                batch_data.append(market_data)
                message_count += 1
            
            # å‘å¸ƒæ‰¹é‡æ•°æ®
            await self._publish_batch_data(batch_data)
            
            # æ§åˆ¶é€Ÿç‡
            batch_duration = time.time() - batch_start
            target_interval = self.batch_size / self.target_rate
            if batch_duration < target_interval:
                await asyncio.sleep(target_interval - batch_duration)
            
            # æŠ¥å‘Šè¿›åº¦
            if time.time() - last_report >= 10:
                elapsed = time.time() - self.test_start_time
                rate = message_count / elapsed if elapsed > 0 else 0
                logger.info(f"ğŸ“Š æ•°æ®ç”Ÿæˆ: {message_count:,} æ¡, é€Ÿç‡: {rate:,.0f} æ¡/ç§’")
                last_report = time.time()
    
    def _generate_market_data(self, symbol: str, exchange: str) -> Dict:
        """ç”Ÿæˆå¸‚åœºæ•°æ®"""
        base_currency = symbol.split("/")[0]
        
        # æ ¹æ®å¸ç§ç±»å‹è®¾ç½®ä¸åŒçš„ä»·æ ¼åŸºç¡€
        if base_currency in ["BTC", "ETH", "BNB"]:
            base_price = {"BTC": 120800, "ETH": 4180, "BNB": 415}.get(base_currency, 100)
            volatility = 0.02
        elif any(meme in base_currency for meme in ["DOGE", "SHIB", "PEPE"]):
            base_price = random.uniform(0.001, 1.0)
            volatility = 0.1  # Memeå¸æ³¢åŠ¨å¤§
        elif "DEFI" in base_currency or "SWAP" in base_currency:
            base_price = random.uniform(1, 100)
            volatility = 0.05
        else:
            base_price = random.uniform(0.1, 50)
            volatility = 0.08
        
        # ç”Ÿæˆä»·æ ¼å˜åŠ¨
        price_change = random.uniform(-volatility, volatility)
        current_price = base_price * (1 + price_change)
        
        # ç”Ÿæˆè®¢å•è–„ï¼ˆå¯èƒ½æœ‰å¼‚å¸¸ï¼‰
        bids, asks = self._generate_orderbook(current_price, symbol)
        
        return {
            "exchange": exchange,
            "symbol": symbol,
            "timestamp": int(time.time() * 1000),
            "bids": bids,
            "asks": asks
        }
    
    def _generate_orderbook(self, price: float, symbol: str) -> Tuple[List, List]:
        """ç”Ÿæˆè®¢å•è–„ï¼ˆå¯èƒ½åŒ…å«å¼‚å¸¸ï¼‰"""
        # 5%æ¦‚ç‡ç”Ÿæˆå¼‚å¸¸è®¢å•è–„ç”¨äºæµ‹è¯•AIæ£€æµ‹
        if random.random() < 0.05:
            return self._generate_anomalous_orderbook(price, symbol)
        
        # æ­£å¸¸è®¢å•è–„
        bids = []
        asks = []
        
        # ç”Ÿæˆä¹°å•ï¼ˆé€’å‡ä»·æ ¼ï¼‰
        for i in range(10):
            bid_price = price * (1 - 0.0001 * (i + 1))
            bid_volume = random.uniform(0.1, 10.0)
            bids.append([bid_price, bid_volume])
        
        # ç”Ÿæˆå–å•ï¼ˆé€’å¢ä»·æ ¼ï¼‰
        for i in range(10):
            ask_price = price * (1 + 0.0001 * (i + 1))
            ask_volume = random.uniform(0.1, 10.0)
            asks.append([ask_price, ask_volume])
        
        return bids, asks
    
    def _generate_anomalous_orderbook(self, price: float, symbol: str) -> Tuple[List, List]:
        """ç”Ÿæˆå¼‚å¸¸è®¢å•è–„ç”¨äºæµ‹è¯•"""
        anomaly_type = random.choice([
            "liquidity_drought", "price_manipulation", "whale_wall", 
            "structure_anomaly", "complete_drought"
        ])
        
        if anomaly_type == "complete_drought":
            return [], []  # å®Œå…¨æ²¡æœ‰æµåŠ¨æ€§
        
        elif anomaly_type == "liquidity_drought":
            # æä½æµåŠ¨æ€§
            bids = [[price * 0.999, 0.001]]
            asks = [[price * 1.001, 0.001]]
            return bids, asks
        
        elif anomaly_type == "price_manipulation":
            # å·¨å¤§ä»·å·®
            bids = [[price * 0.9, 1.0]]
            asks = [[price * 1.15, 1.0]]
            return bids, asks
        
        elif anomaly_type == "whale_wall":
            # å·¨é²¸å¢™å•
            bids = [[price * 0.999, 1000000.0]]  # 100ä¸‡å·¨å•
            asks = [[price * 1.001, 0.1]]
            return bids, asks
        
        elif anomaly_type == "structure_anomaly":
            # ä»·æ ¼å€’æŒ‚
            bids = [[price * 1.01, 1.0], [price * 1.02, 2.0]]  # ä¹°å•ä»·æ ¼é€’å¢ï¼ˆå¼‚å¸¸ï¼‰
            asks = [[price * 0.99, 1.0], [price * 0.98, 2.0]]  # å–å•ä»·æ ¼é€’å‡ï¼ˆå¼‚å¸¸ï¼‰
            return bids, asks
        
        return [], []
    
    async def _publish_batch_data(self, batch_data: List[Dict]):
        """å‘å¸ƒæ‰¹é‡æ•°æ®"""
        for data in batch_data:
            subject = f"strategy.market.{data['exchange']}.{data['symbol'].replace('/', '')}"
            await self.nc.publish(subject, json.dumps(data).encode())
    
    async def _process_strategy_batches(self):
        """æ‰¹é‡ç­–ç•¥å¤„ç†"""
        logger.info("ğŸ§  å¯åŠ¨æ‰¹é‡ç­–ç•¥å¤„ç†å™¨...")
        
        message_batch = []
        
        async def batch_handler(msg):
            try:
                data = json.loads(msg.data.decode())
                message_batch.append(data)
                
                # è¾¾åˆ°æ‰¹å¤„ç†å¤§å°æ—¶å¤„ç†
                if len(message_batch) >= self.batch_size:
                    start_time = time.time()
                    
                    # é«˜æ€§èƒ½æ‰¹å¤„ç†
                    results = self.strategy_engine.process_high_frequency_data(message_batch.copy())
                    
                    processing_time = (time.time() - start_time) * 1000000  # å¾®ç§’
                    self.performance_stats["processing_times"].append(processing_time)
                    
                    self.processed_messages += len(message_batch)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    for result in results:
                        if result["type"] == "triangular":
                            self.performance_stats["triangular_opportunities"] += 1
                        elif result["type"] == "inter_exchange":
                            self.performance_stats["inter_exchange_opportunities"] += 1
                    
                    message_batch.clear()
                    
            except Exception as e:
                logger.error(f"æ‰¹å¤„ç†é”™è¯¯: {e}")
        
        # è®¢é˜…æ‰€æœ‰å¸‚åœºæ•°æ®
        await self.nc.subscribe("strategy.market.>", cb=batch_handler)
        
        # ä¿æŒå¤„ç†æ´»è·ƒ
        while time.time() - self.test_start_time < self.test_duration:
            await asyncio.sleep(1)
    
    async def _inject_advanced_anomalies(self):
        """æ³¨å…¥é«˜éš¾åº¦å¼‚å¸¸è¿›è¡Œæµ‹è¯•"""
        logger.info("ğŸ”¬ å¯åŠ¨é«˜éš¾åº¦å¼‚å¸¸æ³¨å…¥æµ‹è¯•...")
        
        await asyncio.sleep(30)  # ç­‰å¾…ç³»ç»Ÿç¨³å®š
        
        # é«˜éš¾åº¦æµ‹è¯•åœºæ™¯
        scenarios = [
            {"name": "massive_orderbook_manipulation", "delay": 60},
            {"name": "systemic_liquidity_crisis", "delay": 120},
            {"name": "multi_exchange_whale_attack", "delay": 180},
            {"name": "flash_crash_simulation", "delay": 240}
        ]
        
        for scenario in scenarios:
            await asyncio.sleep(scenario["delay"])
            
            if scenario["name"] == "massive_orderbook_manipulation":
                # å¤§è§„æ¨¡è®¢å•è–„æ“çºµæµ‹è¯•
                await self._test_massive_manipulation()
                
            elif scenario["name"] == "systemic_liquidity_crisis":
                # ç³»ç»Ÿæ€§æµåŠ¨æ€§å±æœºæµ‹è¯•
                await self._test_liquidity_crisis()
                
            elif scenario["name"] == "multi_exchange_whale_attack":
                # å¤šäº¤æ˜“æ‰€å·¨é²¸æ”»å‡»æµ‹è¯•
                await self._test_whale_attack()
                
            elif scenario["name"] == "flash_crash_simulation":
                # é—ªå´©æ¨¡æ‹Ÿæµ‹è¯•
                await self._test_flash_crash()
    
    async def _test_massive_manipulation(self):
        """æµ‹è¯•å¤§è§„æ¨¡æ“çºµæ£€æµ‹"""
        logger.info("ğŸ§ª æµ‹è¯•ï¼šå¤§è§„æ¨¡è®¢å•è–„æ“çºµ")
        
        # ç”Ÿæˆå¤§é‡æ“çºµæ•°æ®
        for _ in range(100):
            manipulation_data = {
                "exchange": "test_exchange",
                "symbol": random.choice(self.strategy_engine.trading_pairs[:1000]),
                "timestamp": int(time.time() * 1000),
                "bids": [[50000, 1000000]],  # å·¨é¢è™šå‡ä¹°å•
                "asks": [[70000, 1000000]]   # å·¨é¢è™šå‡å–å•
            }
            
            anomalies = self.ai_detector.detect_complex_anomalies(manipulation_data)
            if anomalies:
                self.performance_stats["ai_detections"] += len(anomalies)
                logger.info(f"âœ… AIæˆåŠŸæ£€æµ‹åˆ°å¤§è§„æ¨¡æ“çºµ")
    
    async def _test_liquidity_crisis(self):
        """æµ‹è¯•æµåŠ¨æ€§å±æœºæ£€æµ‹"""
        logger.info("ğŸ§ª æµ‹è¯•ï¼šç³»ç»Ÿæ€§æµåŠ¨æ€§å±æœº")
        
        # æ¨¡æ‹Ÿå¤§èŒƒå›´æµåŠ¨æ€§æ¯ç«­
        affected_pairs = random.sample(self.strategy_engine.trading_pairs, 1000)
        
        for symbol in affected_pairs[:50]:  # æµ‹è¯•å‰50ä¸ª
            crisis_data = {
                "exchange": "test_exchange",
                "symbol": symbol,
                "timestamp": int(time.time() * 1000),
                "bids": [[100, 0.001]],  # æä½æµåŠ¨æ€§
                "asks": [[101, 0.001]]
            }
            
            anomalies = self.ai_detector.detect_complex_anomalies(crisis_data)
            if anomalies:
                self.performance_stats["ai_detections"] += len(anomalies)
        
        logger.info(f"âœ… æµåŠ¨æ€§å±æœºæ£€æµ‹å®Œæˆ")
    
    async def _test_whale_attack(self):
        """æµ‹è¯•å·¨é²¸æ”»å‡»æ£€æµ‹"""
        logger.info("ğŸ§ª æµ‹è¯•ï¼šå¤šäº¤æ˜“æ‰€å·¨é²¸æ”»å‡»")
        
        for exchange in ["binance", "okx", "huobi"]:
            whale_data = {
                "exchange": exchange,
                "symbol": "BTC/USDT",
                "timestamp": int(time.time() * 1000),
                "bids": [[120000, 500000]],  # 50ä¸‡BTCå·¨é²¸å•
                "asks": [[121000, 1]]
            }
            
            anomalies = self.ai_detector.detect_complex_anomalies(whale_data)
            if anomalies:
                self.performance_stats["ai_detections"] += len(anomalies)
                logger.info(f"âœ… æ£€æµ‹åˆ°{exchange}å·¨é²¸æ´»åŠ¨")
    
    async def _test_flash_crash(self):
        """æµ‹è¯•é—ªå´©æ£€æµ‹"""
        logger.info("ğŸ§ª æµ‹è¯•ï¼šé—ªå´©æ¨¡æ‹Ÿ")
        
        # æ¨¡æ‹Ÿä»·æ ¼ç¬é—´æš´è·Œ
        normal_price = 120000
        for i in range(10):
            crash_price = normal_price * (1 - 0.05 * i)  # æ¯æ¬¡ä¸‹è·Œ5%
            
            crash_data = {
                "exchange": "test_exchange",
                "symbol": "BTC/USDT",
                "timestamp": int(time.time() * 1000),
                "bids": [[crash_price, 10]],
                "asks": [[crash_price * 1.001, 10]]
            }
            
            anomalies = self.ai_detector.detect_complex_anomalies(crash_data)
            if anomalies:
                self.performance_stats["ai_detections"] += len(anomalies)
        
        logger.info("âœ… é—ªå´©æ£€æµ‹å®Œæˆ")
    
    async def _generate_advanced_report(self):
        """ç”Ÿæˆé«˜éš¾åº¦æµ‹è¯•æŠ¥å‘Š"""
        test_duration = time.time() - self.test_start_time
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        avg_processing_time = (sum(self.performance_stats["processing_times"]) / 
                             len(self.performance_stats["processing_times"])) if self.performance_stats["processing_times"] else 0
        max_processing_time = max(self.performance_stats["processing_times"]) if self.performance_stats["processing_times"] else 0
        
        processing_rate = self.processed_messages / test_duration if test_duration > 0 else 0
        
        # è·å–ç­–ç•¥å¼•æ“ç»Ÿè®¡
        stats = self.strategy_engine.stats
        
        logger.info("=" * 80)
        logger.info("ğŸ¯ é«˜éš¾åº¦ç­–ç•¥æ¨¡å—æµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 80)
        logger.info(f"æµ‹è¯•æ—¶é•¿: {test_duration:.2f} ç§’")
        logger.info(f"æ€»å¤„ç†æ¶ˆæ¯: {self.processed_messages:,} æ¡")
        logger.info(f"å¤„ç†é€Ÿç‡: {processing_rate:,.0f} æ¡/ç§’")
        logger.info("")
        logger.info("ğŸ“ˆ äº¤æ˜“å¯¹è¦†ç›–:")
        logger.info(f"  æ”¯æŒäº¤æ˜“å¯¹: {self.performance_stats['total_trading_pairs']:,} ä¸ª")
        logger.info(f"  ä¸»æµå¸äº¤æ˜“å¯¹: ~2,000 ä¸ª")
        logger.info(f"  DeFiä»£å¸äº¤æ˜“å¯¹: ~5,000 ä¸ª")
        logger.info(f"  NFTä»£å¸äº¤æ˜“å¯¹: ~1,500 ä¸ª")
        logger.info(f"  Meme/å°å¸ç§äº¤æ˜“å¯¹: ~6,000 ä¸ª")
        logger.info("")
        logger.info("âš¡ æ€§èƒ½æŒ‡æ ‡:")
        logger.info(f"  å¹³å‡å¤„ç†å»¶è¿Ÿ: {avg_processing_time:.2f} å¾®ç§’")
        logger.info(f"  æœ€å¤§å¤„ç†å»¶è¿Ÿ: {max_processing_time:.2f} å¾®ç§’")
        logger.info(f"  ç›®æ ‡å»¶è¿Ÿ: < 100 å¾®ç§’")
        logger.info(f"  å»¶è¿Ÿæµ‹è¯•: {'âœ… é€šè¿‡' if avg_processing_time < 100 else 'âŒ éœ€è¦ä¼˜åŒ–'}")
        logger.info(f"  é«˜é¢‘å¤„ç†: {'âœ… é€šè¿‡' if processing_rate > 80000 else 'âŒ éœ€è¦ä¼˜åŒ–'}")
        logger.info("")
        logger.info("ğŸ” å¥—åˆ©æœºä¼šæ£€æµ‹:")
        logger.info(f"  å‘ç°æœºä¼šæ€»æ•°: {stats['opportunities_found']:,} æ¬¡")
        logger.info(f"  ä¸‰è§’å¥—åˆ©æœºä¼š: {stats['triangular_found']:,} æ¬¡")
        logger.info(f"  è·¨äº¤æ˜“æ‰€å¥—åˆ©: {stats['inter_exchange_found']:,} æ¬¡")
        logger.info(f"  æ‰§è¡ŒæˆåŠŸ: {stats['opportunities_executed']:,} æ¬¡")
        logger.info(f"  æ‰§è¡ŒæˆåŠŸç‡: {(stats['opportunities_executed']/max(stats['opportunities_found'],1)*100):.1f}%")
        logger.info("")
        logger.info("ğŸ§  AIå¼‚å¸¸æ£€æµ‹:")
        logger.info(f"  æ£€æµ‹åˆ°å¼‚å¸¸: {stats['ai_anomalies_detected']:,} æ¬¡")
        logger.info(f"  é«˜çº§æ£€æµ‹æˆåŠŸ: {self.performance_stats['ai_detections']:,} æ¬¡")
        logger.info(f"  âœ… AIæ£€æµ‹èƒ½åŠ›: {'ä¼˜ç§€' if stats['ai_anomalies_detected'] > 50 else 'éœ€è¦è°ƒä¼˜'}")
        logger.info("")
        logger.info("ğŸ›¡ï¸ é£æ§éªŒè¯:")
        logger.info(f"  é£æ§æ‹¦æˆª: {stats['opportunities_rejected']:,} æ¬¡")
        logger.info(f"  é£æ§äº‹ä»¶: {stats['risk_events']:,} æ¬¡")
        logger.info(f"  æ‹¦æˆªç‡: {(stats['opportunities_rejected']/max(stats['opportunities_found'],1)*100):.1f}%")
        logger.info(f"  âœ… é£æ§æ•ˆæœ: {'ä¼˜ç§€' if stats['risk_events'] > 20 else 'éœ€è¦è°ƒä¼˜'}")
        logger.info("")
        logger.info("ğŸ¯ é—®é¢˜è¯Šæ–­å’Œä¼˜åŒ–å»ºè®®:")
        
        # é—®é¢˜è¯Šæ–­
        issues = []
        recommendations = []
        
        if processing_rate < 80000:
            issues.append("é«˜é¢‘å¤„ç†é€Ÿç‡ä¸è¶³")
            recommendations.append("1. å¢åŠ æ‰¹å¤„ç†å¤§å°åˆ°2000")
            recommendations.append("2. ä½¿ç”¨æ›´å¤šçº¿ç¨‹æ± å·¥ä½œçº¿ç¨‹(16ä¸ª)")
            recommendations.append("3. ä¼˜åŒ–æ•°æ®åºåˆ—åŒ–/ååºåˆ—åŒ–")
            recommendations.append("4. å¯ç”¨SIMDå¹¶è¡Œè®¡ç®—ä¼˜åŒ–")
        
        if avg_processing_time > 100:
            issues.append("å¹³å‡å»¶è¿Ÿè¶…è¿‡ç›®æ ‡")
            recommendations.append("5. å®ç°å†…å­˜æ± å‡å°‘GCå‹åŠ›")
            recommendations.append("6. ä½¿ç”¨æ›´å¿«çš„JSONè§£æåº“")
            recommendations.append("7. ä¼˜åŒ–AIæ£€æµ‹ç®—æ³•å¤æ‚åº¦")
        
        if stats['risk_events'] < 20:
            issues.append("é£æ§æ¨¡å—æ£€æµ‹ä¸è¶³")
            recommendations.append("8. é™ä½é£é™©é˜ˆå€¼å¢åŠ æ•æ„Ÿåº¦")
            recommendations.append("9. å¢åŠ æ›´å¤šé£é™©æ£€æµ‹ç»´åº¦")
            recommendations.append("10. å®ç°åŠ¨æ€é£é™©è°ƒæ•´æœºåˆ¶")
        
        if stats['ai_anomalies_detected'] < 50:
            issues.append("AIå¼‚å¸¸æ£€æµ‹ä¸è¶³")
            recommendations.append("11. å¢åŠ å¼‚å¸¸æ¨¡å¼è®­ç»ƒæ ·æœ¬")
            recommendations.append("12. ä¼˜åŒ–å¼‚å¸¸æ£€æµ‹ç®—æ³•å‚æ•°")
            recommendations.append("13. å®ç°å¤šç»´åº¦ç»¼åˆå¼‚å¸¸è¯„åˆ†")
        
        if issues:
            logger.info("  å‘ç°é—®é¢˜:")
            for issue in issues:
                logger.info(f"    âŒ {issue}")
            logger.info("")
            logger.info("  ä¼˜åŒ–å»ºè®®:")
            for rec in recommendations:
                logger.info(f"    ğŸ’¡ {rec}")
        else:
            logger.info("  âœ… æ‰€æœ‰æµ‹è¯•é¡¹ç›®å‡è¾¾åˆ°ä¼˜ç§€æ ‡å‡†!")
        
        logger.info("")
        logger.info("ğŸ‰ æ€»ä½“è¯„ä¼°:")
        
        # ç»¼åˆè¯„åˆ†
        score = 0
        if processing_rate > 80000:
            score += 25
        if avg_processing_time < 100:
            score += 25
        if stats['risk_events'] > 20:
            score += 25
        if stats['ai_anomalies_detected'] > 50:
            score += 25
        
        if score >= 90:
            logger.info("  ğŸ† ä¼˜ç§€ (90+åˆ†) - ç­–ç•¥æ¨¡å—è¾¾åˆ°ç”Ÿäº§ç¯å¢ƒæ ‡å‡†")
        elif score >= 70:
            logger.info("  âœ… è‰¯å¥½ (70-89åˆ†) - ç­–ç•¥æ¨¡å—åŸºæœ¬æ»¡è¶³è¦æ±‚ï¼Œéœ€è¦å°‘é‡ä¼˜åŒ–")
        elif score >= 50:
            logger.info("  âš ï¸ ä¸€èˆ¬ (50-69åˆ†) - ç­–ç•¥æ¨¡å—éœ€è¦é‡è¦ä¼˜åŒ–")
        else:
            logger.info("  âŒ ä¸åˆæ ¼ (<50åˆ†) - ç­–ç•¥æ¨¡å—éœ€è¦é‡å¤§æ”¹è¿›")
        
        logger.info(f"  ç»¼åˆè¯„åˆ†: {score}/100")
        logger.info("=" * 80)
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.nc:
            await self.nc.close()
        self.strategy_engine.executor.shutdown(wait=True)
        logger.info("âœ… æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†")

async def main():
    """ä¸»å‡½æ•°"""
    tester = AdvancedStrategyTest()
    
    try:
        if not await tester.connect_nats():
            logger.error("âŒ æ— æ³•è¿æ¥NATSï¼Œæµ‹è¯•ç»ˆæ­¢")
            return
            
        await tester.run_advanced_test()
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    finally:
        await tester.close()

if __name__ == "__main__":
    asyncio.run(main()) 