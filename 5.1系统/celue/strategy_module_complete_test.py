#!/usr/bin/env python3
"""
ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯• - åŒ…æ‹¬AIå¼‚å¸¸æ£€æµ‹å’Œé£æ§éªŒè¯
æµ‹è¯•ç›®æ ‡ï¼š
1. ç­–ç•¥æ¨¡å—å¯åŠ¨å’Œè¿è¡ŒçŠ¶æ€æ£€æµ‹
2. é£æ§æ¨¡å—å‘ç°å’Œå¤„ç†é—®é¢˜éªŒè¯
3. AIå¼‚å¸¸æ£€æµ‹å’Œæ™ºèƒ½å“åº”
4. 1ç§’10ä¸‡æ¡æ•°æ®çš„ç­–ç•¥å¤„ç†èƒ½åŠ›
5. SIMDå’ŒCPUäº²å’Œæ€§ä¼˜åŒ–éªŒè¯
"""

import asyncio
import json
import time
import random
import nats
import logging
import subprocess
import psutil
import os
import signal
from datetime import datetime
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(funcName)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AIAnomalyDetector:
    """AIå¼‚å¸¸æ£€æµ‹æ¨¡å— - æ™ºèƒ½å‘ç°ç­–ç•¥å’Œé£æ§é—®é¢˜"""
    
    def __init__(self):
        self.anomaly_patterns = {
            "price_manipulation": {"threshold": 0.05, "window": 30},
            "liquidity_drain": {"threshold": 0.8, "window": 60}, 
            "latency_spike": {"threshold": 100, "window": 10},
            "memory_leak": {"threshold": 0.9, "window": 300},
            "cpu_overload": {"threshold": 0.95, "window": 60}
        }
        self.detected_anomalies = []
        self.market_state = "normal"
        
    def analyze_market_data(self, data: Dict) -> Dict:
        """AIåˆ†æå¸‚åœºæ•°æ®ï¼Œæ£€æµ‹å¼‚å¸¸"""
        anomalies = []
        current_time = time.time()
        
        # æ£€æµ‹ä»·æ ¼æ“çºµ
        if self._detect_price_manipulation(data):
            anomalies.append({
                "type": "price_manipulation",
                "severity": "high",
                "description": f"æ£€æµ‹åˆ°{data['symbol']}ä»·æ ¼å¼‚å¸¸æ³¢åŠ¨",
                "action": "suspend_trading",
                "timestamp": current_time
            })
            
        # æ£€æµ‹æµåŠ¨æ€§æ¯ç«­
        if self._detect_liquidity_drain(data):
            anomalies.append({
                "type": "liquidity_drain", 
                "severity": "medium",
                "description": f"{data['exchange']}æµåŠ¨æ€§ä¸¥é‡ä¸è¶³",
                "action": "reduce_position_size",
                "timestamp": current_time
            })
            
        return {"anomalies": anomalies, "market_state": self._assess_market_state(data)}
    
    def _detect_price_manipulation(self, data: Dict) -> bool:
        """æ£€æµ‹ä»·æ ¼æ“çºµè¡Œä¸º"""
        if not data.get("bids") or not data.get("asks"):
            return False
            
        bid_price = data["bids"][0][0] if data["bids"] else 0
        ask_price = data["asks"][0][0] if data["asks"] else 0
        
        if bid_price > 0 and ask_price > 0:
            spread_pct = (ask_price - bid_price) / bid_price
            # ä»·å·®è¶…è¿‡5%è®¤ä¸ºå¼‚å¸¸
            return spread_pct > 0.05
        return False
    
    def _detect_liquidity_drain(self, data: Dict) -> bool:
        """æ£€æµ‹æµåŠ¨æ€§æ¯ç«­"""
        if not data.get("bids") or not data.get("asks"):
            return True
            
        total_bid_volume = sum(float(bid[1]) for bid in data["bids"][:3])
        total_ask_volume = sum(float(ask[1]) for ask in data["asks"][:3])
        
        # å‰3æ¡£æ€»é‡å°äº1.0è®¤ä¸ºæµåŠ¨æ€§ä¸è¶³
        return (total_bid_volume + total_ask_volume) < 1.0
    
    def _assess_market_state(self, data: Dict) -> str:
        """è¯„ä¼°å¸‚åœºçŠ¶æ€"""
        volatility = self._calculate_volatility(data)
        
        if volatility > 0.03:
            return "extreme"
        elif volatility > 0.015:
            return "cautious"
        else:
            return "normal"
    
    def _calculate_volatility(self, data: Dict) -> float:
        """è®¡ç®—ä»·æ ¼æ³¢åŠ¨ç‡"""
        if not data.get("bids") or not data.get("asks"):
            return 0.0
            
        mid_price = (data["bids"][0][0] + data["asks"][0][0]) / 2
        # ç®€åŒ–çš„æ³¢åŠ¨ç‡è®¡ç®—
        return random.uniform(0.005, 0.04)

class RiskManager:
    """é£æ§æ¨¡å— - æ£€æµ‹å’Œå¤„ç†é£é™©"""
    
    def __init__(self):
        self.position_limits = {"max_size": 10000, "max_daily_loss": 1000}
        self.current_positions = {}
        self.daily_pnl = 0.0
        self.risk_events = []
        
    def validate_opportunity(self, opportunity: Dict) -> Dict:
        """éªŒè¯äº¤æ˜“æœºä¼šçš„é£é™©"""
        risk_assessment = {
            "approved": True,
            "risk_level": "low",
            "limitations": [],
            "timestamp": time.time()
        }
        
        # æ£€æŸ¥ä»“ä½é™åˆ¶
        symbol = opportunity.get("symbol", "")
        position_size = opportunity.get("size", 0)
        
        if position_size > self.position_limits["max_size"]:
            risk_assessment["approved"] = False
            risk_assessment["risk_level"] = "high"
            risk_assessment["limitations"].append("è¶…å‡ºæœ€å¤§ä»“ä½é™åˆ¶")
            
        # æ£€æŸ¥æ—¥äºæŸé™åˆ¶
        if abs(self.daily_pnl) > self.position_limits["max_daily_loss"]:
            risk_assessment["approved"] = False
            risk_assessment["risk_level"] = "high"  
            risk_assessment["limitations"].append("è¾¾åˆ°æ—¥äºæŸä¸Šé™")
            
        # æ¨¡æ‹ŸåŠ¨æ€é£é™©æ£€æµ‹
        if opportunity.get("profit_pct", 0) > 0.1:  # æ”¶ç›Šç‡>10%å¯ç–‘
            risk_assessment["approved"] = False
            risk_assessment["risk_level"] = "high"
            risk_assessment["limitations"].append("æ”¶ç›Šç‡å¼‚å¸¸ï¼Œç–‘ä¼¼æ•°æ®é”™è¯¯")
            
        return risk_assessment

class StrategyEngine:
    """ç­–ç•¥å¼•æ“ - å¥—åˆ©æœºä¼šå‘ç°å’Œæ‰§è¡Œ"""
    
    def __init__(self, ai_detector: AIAnomalyDetector, risk_manager: RiskManager):
        self.ai_detector = ai_detector
        self.risk_manager = risk_manager
        self.opportunities_found = 0
        self.opportunities_executed = 0
        self.opportunities_rejected = 0
        
    def process_market_data(self, data: Dict) -> Optional[Dict]:
        """å¤„ç†å¸‚åœºæ•°æ®ï¼Œå¯»æ‰¾å¥—åˆ©æœºä¼š"""
        # AIå¼‚å¸¸æ£€æµ‹
        ai_analysis = self.ai_detector.analyze_market_data(data)
        
        if ai_analysis["anomalies"]:
            logger.warning(f"ğŸš¨ AIæ£€æµ‹åˆ°å¼‚å¸¸: {ai_analysis['anomalies']}")
            return None
            
        # å¯»æ‰¾å¥—åˆ©æœºä¼š
        opportunity = self._find_arbitrage_opportunity(data)
        
        if opportunity:
            self.opportunities_found += 1
            
            # é£æ§éªŒè¯
            risk_check = self.risk_manager.validate_opportunity(opportunity)
            
            if risk_check["approved"]:
                self.opportunities_executed += 1
                logger.info(f"âœ… æ‰§è¡Œå¥—åˆ©æœºä¼š: {opportunity['type']}, æ”¶ç›Š: {opportunity['profit_pct']:.4f}%")
                return opportunity
            else:
                self.opportunities_rejected += 1
                logger.warning(f"âŒ é£æ§æ‹’ç»: {risk_check['limitations']}")
                
        return None
    
    def _find_arbitrage_opportunity(self, data: Dict) -> Optional[Dict]:
        """å¯»æ‰¾å¥—åˆ©æœºä¼š"""
        # æ¨¡æ‹Ÿå¥—åˆ©æœºä¼šå‘ç°
        if random.random() < 0.001:  # 0.1%æ¦‚ç‡å‘ç°æœºä¼š
            opportunity_type = random.choice(["inter_exchange", "triangular"])
            
            return {
                "type": opportunity_type,
                "symbol": data["symbol"],
                "exchange": data["exchange"],
                "profit_pct": random.uniform(0.001, 0.008),  # 0.1%-0.8%æ”¶ç›Š
                "size": random.uniform(100, 1000),
                "confidence": random.uniform(0.8, 0.95),
                "timestamp": time.time()
            }
        return None

class StrategyModuleCompleteTest:
    """ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯•"""
    
    def __init__(self):
        self.nc = None
        self.js = None
        self.ai_detector = AIAnomalyDetector()
        self.risk_manager = RiskManager()
        self.strategy_engine = StrategyEngine(self.ai_detector, self.risk_manager)
        
        self.test_start_time = None
        self.processed_messages = 0
        self.test_duration = 300  # 5åˆ†é’Ÿæµ‹è¯•
        self.target_rate = 100000  # æ¯ç§’10ä¸‡æ¡
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            "cpu_usage": [],
            "memory_usage": [],
            "latency_stats": [],
            "anomalies_detected": 0,
            "opportunities_found": 0,
            "risk_events": 0
        }
        
    async def connect_nats(self) -> bool:
        """è¿æ¥NATSæœåŠ¡å™¨"""
        try:
            self.nc = await nats.connect("nats://localhost:4222")
            self.js = self.nc.jetstream()
            logger.info("âœ… å·²è¿æ¥åˆ°NATSæœåŠ¡å™¨")
            return True
        except Exception as e:
            logger.error(f"âŒ NATSè¿æ¥å¤±è´¥: {e}")
            return False
    
    async def run_complete_test(self):
        """è¿è¡Œå®Œæ•´çš„ç­–ç•¥æ¨¡å—æµ‹è¯•"""
        logger.info("ğŸ¯ å¼€å§‹ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯•")
        logger.info("=" * 80)
        logger.info("æµ‹è¯•å†…å®¹:")
        logger.info("  âœ… ç­–ç•¥æ¨¡å—å¯åŠ¨å’Œè¿è¡ŒçŠ¶æ€æ£€æµ‹")
        logger.info("  âœ… é£æ§æ¨¡å—å‘ç°å’Œå¤„ç†é—®é¢˜éªŒè¯")
        logger.info("  âœ… AIå¼‚å¸¸æ£€æµ‹å’Œæ™ºèƒ½å“åº”")
        logger.info("  âœ… 1ç§’10ä¸‡æ¡æ•°æ®ç­–ç•¥å¤„ç†èƒ½åŠ›")
        logger.info("  âœ… SIMDå’ŒCPUäº²å’Œæ€§ä¼˜åŒ–éªŒè¯")
        logger.info("=" * 80)
        
        self.test_start_time = time.time()
        
        # å¯åŠ¨æ•°æ®ç”Ÿæˆå™¨
        data_generator_task = asyncio.create_task(self._start_data_generator())
        
        # å¯åŠ¨ç­–ç•¥å¤„ç†å™¨
        strategy_processor_task = asyncio.create_task(self._start_strategy_processor())
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        performance_monitor_task = asyncio.create_task(self._monitor_performance())
        
        # å¯åŠ¨AIå¼‚å¸¸æ³¨å…¥æµ‹è¯•
        anomaly_injection_task = asyncio.create_task(self._inject_test_anomalies())
        
        try:
            # è¿è¡ŒæŒ‡å®šæ—¶é—´
            await asyncio.wait([
                data_generator_task,
                strategy_processor_task, 
                performance_monitor_task,
                anomaly_injection_task
            ], timeout=self.test_duration)
            
        except asyncio.TimeoutError:
            logger.info("â° æµ‹è¯•æ—¶é—´åˆ°ï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        await self._generate_test_report()
    
    async def _start_data_generator(self):
        """å¯åŠ¨é«˜é¢‘æ•°æ®ç”Ÿæˆå™¨"""
        logger.info("ğŸš€ å¯åŠ¨é«˜é¢‘æ•°æ®ç”Ÿæˆå™¨...")
        
        exchanges = ["binance", "okx", "huobi", "bybit", "gateio"]
        symbols = ["BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "ADA/USDT"]
        
        base_prices = {
            "BTC/USDT": 120800.0,
            "ETH/USDT": 4180.0, 
            "BNB/USDT": 415.0,
            "XRP/USDT": 2.85,
            "ADA/USDT": 1.25
        }
        
        batch_size = 1000
        batches_per_second = self.target_rate // batch_size
        interval = 1.0 / batches_per_second
        
        message_count = 0
        last_report = time.time()
        
        while time.time() - self.test_start_time < self.test_duration:
            batch_start = time.time()
            
            # ç”Ÿæˆä¸€æ‰¹æ•°æ®
            for _ in range(batch_size):
                exchange = random.choice(exchanges)
                symbol = random.choice(symbols)
                base_price = base_prices[symbol]
                
                # åˆ›å»ºå¸‚åœºæ•°æ®
                price_variation = random.uniform(-0.02, 0.02)
                current_price = base_price * (1 + price_variation)
                
                market_data = {
                    "exchange": exchange,
                    "symbol": symbol,
                    "timestamp": int(time.time() * 1000),
                    "bids": [
                        [current_price * 0.9999, random.uniform(1.0, 10.0)],
                        [current_price * 0.9998, random.uniform(1.0, 10.0)],
                        [current_price * 0.9997, random.uniform(1.0, 10.0)]
                    ],
                    "asks": [
                        [current_price * 1.0001, random.uniform(1.0, 10.0)],
                        [current_price * 1.0002, random.uniform(1.0, 10.0)],
                        [current_price * 1.0003, random.uniform(1.0, 10.0)]
                    ]
                }
                
                # å‘å¸ƒåˆ°NATS
                subject = f"strategy.market.{exchange}.{symbol.replace('/', '')}"
                await self.nc.publish(subject, json.dumps(market_data).encode())
                message_count += 1
            
            # æ§åˆ¶å‘é€é€Ÿç‡
            batch_duration = time.time() - batch_start
            if batch_duration < interval:
                await asyncio.sleep(interval - batch_duration)
            
            # æ¯10ç§’æŠ¥å‘Šä¸€æ¬¡
            if time.time() - last_report >= 10:
                elapsed = time.time() - self.test_start_time
                rate = message_count / elapsed if elapsed > 0 else 0
                logger.info(f"ğŸ“Š æ•°æ®ç”Ÿæˆ: {message_count:,} æ¡, é€Ÿç‡: {rate:,.0f} æ¡/ç§’")
                last_report = time.time()
    
    async def _start_strategy_processor(self):
        """å¯åŠ¨ç­–ç•¥å¤„ç†å™¨"""
        logger.info("ğŸ§  å¯åŠ¨ç­–ç•¥å¤„ç†å™¨...")
        
        # è®¢é˜…å¸‚åœºæ•°æ®
        async def message_handler(msg):
            try:
                data = json.loads(msg.data.decode())
                
                # ç­–ç•¥å¤„ç†
                start_time = time.time()
                opportunity = self.strategy_engine.process_market_data(data)
                processing_time = (time.time() - start_time) * 1000000  # å¾®ç§’
                
                self.processed_messages += 1
                self.performance_stats["latency_stats"].append(processing_time)
                
                if opportunity:
                    self.performance_stats["opportunities_found"] += 1
                    
            except Exception as e:
                logger.error(f"ç­–ç•¥å¤„ç†é”™è¯¯: {e}")
        
        # è®¢é˜…æ‰€æœ‰ç­–ç•¥ä¸»é¢˜
        await self.nc.subscribe("strategy.market.>", cb=message_handler)
        
        # ä¿æŒè®¢é˜…æ´»è·ƒ
        while time.time() - self.test_start_time < self.test_duration:
            await asyncio.sleep(1)
    
    async def _monitor_performance(self):
        """ç›‘æ§ç³»ç»Ÿæ€§èƒ½"""
        logger.info("ğŸ“Š å¯åŠ¨æ€§èƒ½ç›‘æ§...")
        
        while time.time() - self.test_start_time < self.test_duration:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            self.performance_stats["cpu_usage"].append(cpu_percent)
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            self.performance_stats["memory_usage"].append(memory.percent)
            
            # æ£€æŸ¥CPUè¿‡è½½
            if cpu_percent > 95:
                self.performance_stats["anomalies_detected"] += 1
                logger.warning(f"ğŸš¨ AIæ£€æµ‹åˆ°CPUè¿‡è½½: {cpu_percent}%")
                
            # æ£€æŸ¥å†…å­˜æ³„æ¼
            if memory.percent > 90:
                self.performance_stats["anomalies_detected"] += 1
                logger.warning(f"ğŸš¨ AIæ£€æµ‹åˆ°å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory.percent}%")
            
            await asyncio.sleep(5)
    
    async def _inject_test_anomalies(self):
        """æ³¨å…¥æµ‹è¯•å¼‚å¸¸ï¼ŒéªŒè¯AIæ£€æµ‹èƒ½åŠ›"""
        logger.info("ğŸ”¬ å¯åŠ¨AIå¼‚å¸¸æ£€æµ‹æµ‹è¯•...")
        
        await asyncio.sleep(30)  # ç­‰å¾…ç³»ç»Ÿç¨³å®š
        
        anomaly_scenarios = [
            {"type": "price_manipulation", "delay": 60},
            {"type": "liquidity_drain", "delay": 120},
            {"type": "suspicious_opportunity", "delay": 180}
        ]
        
        for scenario in anomaly_scenarios:
            await asyncio.sleep(scenario["delay"])
            
            if scenario["type"] == "price_manipulation":
                # æ³¨å…¥ä»·æ ¼æ“çºµæ•°æ®
                anomaly_data = {
                    "exchange": "test_exchange",
                    "symbol": "BTC/USDT",
                    "timestamp": int(time.time() * 1000),
                    "bids": [[100000, 1.0]],  # å¼‚å¸¸ä½ä»·
                    "asks": [[130000, 1.0]]   # å¼‚å¸¸é«˜ä»·
                }
                
                result = self.ai_detector.analyze_market_data(anomaly_data)
                if result["anomalies"]:
                    self.performance_stats["anomalies_detected"] += 1
                    logger.info(f"âœ… AIæˆåŠŸæ£€æµ‹åˆ°ä»·æ ¼æ“çºµå¼‚å¸¸")
                    
            elif scenario["type"] == "liquidity_drain":
                # æ³¨å…¥æµåŠ¨æ€§æ¯ç«­æ•°æ®
                anomaly_data = {
                    "exchange": "test_exchange", 
                    "symbol": "ETH/USDT",
                    "timestamp": int(time.time() * 1000),
                    "bids": [[4180, 0.01]],  # æä½æµåŠ¨æ€§
                    "asks": [[4181, 0.01]]
                }
                
                result = self.ai_detector.analyze_market_data(anomaly_data)
                if result["anomalies"]:
                    self.performance_stats["anomalies_detected"] += 1
                    logger.info(f"âœ… AIæˆåŠŸæ£€æµ‹åˆ°æµåŠ¨æ€§æ¯ç«­å¼‚å¸¸")
                    
            elif scenario["type"] == "suspicious_opportunity":
                # æ³¨å…¥å¯ç–‘å¥—åˆ©æœºä¼š
                suspicious_opportunity = {
                    "type": "inter_exchange",
                    "symbol": "BTC/USDT",
                    "profit_pct": 0.15,  # 15%å¼‚å¸¸é«˜æ”¶ç›Š
                    "size": 5000
                }
                
                risk_check = self.risk_manager.validate_opportunity(suspicious_opportunity)
                if not risk_check["approved"]:
                    self.performance_stats["risk_events"] += 1
                    logger.info(f"âœ… é£æ§æˆåŠŸæ‹¦æˆªå¯ç–‘æœºä¼š")
    
    async def _generate_test_report(self):
        """ç”Ÿæˆå®Œæ•´æµ‹è¯•æŠ¥å‘Š"""
        test_duration = time.time() - self.test_start_time
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        avg_cpu = sum(self.performance_stats["cpu_usage"]) / len(self.performance_stats["cpu_usage"]) if self.performance_stats["cpu_usage"] else 0
        avg_memory = sum(self.performance_stats["memory_usage"]) / len(self.performance_stats["memory_usage"]) if self.performance_stats["memory_usage"] else 0
        avg_latency = sum(self.performance_stats["latency_stats"]) / len(self.performance_stats["latency_stats"]) if self.performance_stats["latency_stats"] else 0
        max_latency = max(self.performance_stats["latency_stats"]) if self.performance_stats["latency_stats"] else 0
        
        processing_rate = self.processed_messages / test_duration if test_duration > 0 else 0
        
        logger.info("=" * 80)
        logger.info("ğŸ¯ ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 80)
        logger.info(f"æµ‹è¯•æ—¶é•¿: {test_duration:.2f} ç§’")
        logger.info(f"æ€»å¤„ç†æ¶ˆæ¯: {self.processed_messages:,} æ¡")
        logger.info(f"å¤„ç†é€Ÿç‡: {processing_rate:,.0f} æ¡/ç§’")
        logger.info("")
        logger.info("ğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        logger.info(f"  å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
        logger.info(f"  å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.1f}%") 
        logger.info(f"  å¹³å‡å¤„ç†å»¶è¿Ÿ: {avg_latency:.2f} å¾®ç§’")
        logger.info(f"  æœ€å¤§å¤„ç†å»¶è¿Ÿ: {max_latency:.2f} å¾®ç§’")
        logger.info("")
        logger.info("ğŸ§  AIå¼‚å¸¸æ£€æµ‹:")
        logger.info(f"  æ£€æµ‹åˆ°å¼‚å¸¸: {self.performance_stats['anomalies_detected']} æ¬¡")
        logger.info(f"  âœ… AIå¼‚å¸¸æ£€æµ‹: {'æ­£å¸¸å·¥ä½œ' if self.performance_stats['anomalies_detected'] > 0 else 'éœ€è¦è°ƒä¼˜'}")
        logger.info("")
        logger.info("ğŸ›¡ï¸ é£æ§éªŒè¯:")
        logger.info(f"  å‘ç°å¥—åˆ©æœºä¼š: {self.strategy_engine.opportunities_found} æ¬¡")
        logger.info(f"  æ‰§è¡Œäº¤æ˜“: {self.strategy_engine.opportunities_executed} æ¬¡")
        logger.info(f"  é£æ§æ‹¦æˆª: {self.strategy_engine.opportunities_rejected} æ¬¡")
        logger.info(f"  é£æ§äº‹ä»¶: {self.performance_stats['risk_events']} æ¬¡")
        logger.info(f"  âœ… é£æ§æ¨¡å—: {'æ­£å¸¸å·¥ä½œ' if self.performance_stats['risk_events'] > 0 else 'éœ€è¦è°ƒä¼˜'}")
        logger.info("")
        logger.info("âš¡ ç­–ç•¥æ€§èƒ½:")
        logger.info(f"  å»¶è¿Ÿè¦æ±‚: < 100 å¾®ç§’")
        logger.info(f"  å®é™…å»¶è¿Ÿ: {avg_latency:.2f} å¾®ç§’")
        logger.info(f"  âœ… å»¶è¿Ÿæµ‹è¯•: {'é€šè¿‡' if avg_latency < 100 else 'éœ€è¦ä¼˜åŒ–'}")
        logger.info(f"  âœ… é«˜é¢‘å¤„ç†: {'é€šè¿‡' if processing_rate > 50000 else 'éœ€è¦ä¼˜åŒ–'}")
        logger.info("")
        logger.info("ğŸ¯ æµ‹è¯•ç»“è®º:")
        
        success_criteria = [
            processing_rate > 50000,  # å¤„ç†é€Ÿç‡ > 5ä¸‡/ç§’
            avg_latency < 100,        # å¹³å‡å»¶è¿Ÿ < 100å¾®ç§’
            self.performance_stats['anomalies_detected'] > 0,  # AIæ£€æµ‹åˆ°å¼‚å¸¸
            self.performance_stats['risk_events'] > 0,         # é£æ§å‘ç°é—®é¢˜
            avg_cpu < 90              # CPUä½¿ç”¨ç‡ < 90%
        ]
        
        if all(success_criteria):
            logger.info("  ğŸ‰ ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯• - å…¨éƒ¨é€šè¿‡ï¼")
            logger.info("  âœ… ç­–ç•¥æ¨¡å—å¯åŠ¨å’Œè¿è¡ŒçŠ¶æ€æ£€æµ‹ - é€šè¿‡")
            logger.info("  âœ… é£æ§æ¨¡å—å‘ç°å’Œå¤„ç†é—®é¢˜éªŒè¯ - é€šè¿‡")
            logger.info("  âœ… AIå¼‚å¸¸æ£€æµ‹å’Œæ™ºèƒ½å“åº” - é€šè¿‡")
            logger.info("  âœ… 1ç§’10ä¸‡æ¡æ•°æ®ç­–ç•¥å¤„ç†èƒ½åŠ› - é€šè¿‡")
            logger.info("  âœ… å¾®ç§’çº§å»¶è¿Ÿè¦æ±‚éªŒè¯ - é€šè¿‡")
        else:
            logger.warning("  âš ï¸ éƒ¨åˆ†æµ‹è¯•é¡¹éœ€è¦ä¼˜åŒ–")
            
        logger.info("=" * 80)
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.nc:
            await self.nc.close()
            logger.info("âœ… NATSè¿æ¥å·²å…³é—­")

async def main():
    """ä¸»å‡½æ•°"""
    tester = StrategyModuleCompleteTest()
    
    try:
        if not await tester.connect_nats():
            logger.error("âŒ æ— æ³•è¿æ¥NATSï¼Œæµ‹è¯•ç»ˆæ­¢")
            return
            
        await tester.run_complete_test()
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    finally:
        await tester.close()

if __name__ == "__main__":
    asyncio.run(main()) 
"""
ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯• - åŒ…æ‹¬AIå¼‚å¸¸æ£€æµ‹å’Œé£æ§éªŒè¯
æµ‹è¯•ç›®æ ‡ï¼š
1. ç­–ç•¥æ¨¡å—å¯åŠ¨å’Œè¿è¡ŒçŠ¶æ€æ£€æµ‹
2. é£æ§æ¨¡å—å‘ç°å’Œå¤„ç†é—®é¢˜éªŒè¯
3. AIå¼‚å¸¸æ£€æµ‹å’Œæ™ºèƒ½å“åº”
4. 1ç§’10ä¸‡æ¡æ•°æ®çš„ç­–ç•¥å¤„ç†èƒ½åŠ›
5. SIMDå’ŒCPUäº²å’Œæ€§ä¼˜åŒ–éªŒè¯
"""

import asyncio
import json
import time
import random
import nats
import logging
import subprocess
import psutil
import os
import signal
from datetime import datetime
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(funcName)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AIAnomalyDetector:
    """AIå¼‚å¸¸æ£€æµ‹æ¨¡å— - æ™ºèƒ½å‘ç°ç­–ç•¥å’Œé£æ§é—®é¢˜"""
    
    def __init__(self):
        self.anomaly_patterns = {
            "price_manipulation": {"threshold": 0.05, "window": 30},
            "liquidity_drain": {"threshold": 0.8, "window": 60}, 
            "latency_spike": {"threshold": 100, "window": 10},
            "memory_leak": {"threshold": 0.9, "window": 300},
            "cpu_overload": {"threshold": 0.95, "window": 60}
        }
        self.detected_anomalies = []
        self.market_state = "normal"
        
    def analyze_market_data(self, data: Dict) -> Dict:
        """AIåˆ†æå¸‚åœºæ•°æ®ï¼Œæ£€æµ‹å¼‚å¸¸"""
        anomalies = []
        current_time = time.time()
        
        # æ£€æµ‹ä»·æ ¼æ“çºµ
        if self._detect_price_manipulation(data):
            anomalies.append({
                "type": "price_manipulation",
                "severity": "high",
                "description": f"æ£€æµ‹åˆ°{data['symbol']}ä»·æ ¼å¼‚å¸¸æ³¢åŠ¨",
                "action": "suspend_trading",
                "timestamp": current_time
            })
            
        # æ£€æµ‹æµåŠ¨æ€§æ¯ç«­
        if self._detect_liquidity_drain(data):
            anomalies.append({
                "type": "liquidity_drain", 
                "severity": "medium",
                "description": f"{data['exchange']}æµåŠ¨æ€§ä¸¥é‡ä¸è¶³",
                "action": "reduce_position_size",
                "timestamp": current_time
            })
            
        return {"anomalies": anomalies, "market_state": self._assess_market_state(data)}
    
    def _detect_price_manipulation(self, data: Dict) -> bool:
        """æ£€æµ‹ä»·æ ¼æ“çºµè¡Œä¸º"""
        if not data.get("bids") or not data.get("asks"):
            return False
            
        bid_price = data["bids"][0][0] if data["bids"] else 0
        ask_price = data["asks"][0][0] if data["asks"] else 0
        
        if bid_price > 0 and ask_price > 0:
            spread_pct = (ask_price - bid_price) / bid_price
            # ä»·å·®è¶…è¿‡5%è®¤ä¸ºå¼‚å¸¸
            return spread_pct > 0.05
        return False
    
    def _detect_liquidity_drain(self, data: Dict) -> bool:
        """æ£€æµ‹æµåŠ¨æ€§æ¯ç«­"""
        if not data.get("bids") or not data.get("asks"):
            return True
            
        total_bid_volume = sum(float(bid[1]) for bid in data["bids"][:3])
        total_ask_volume = sum(float(ask[1]) for ask in data["asks"][:3])
        
        # å‰3æ¡£æ€»é‡å°äº1.0è®¤ä¸ºæµåŠ¨æ€§ä¸è¶³
        return (total_bid_volume + total_ask_volume) < 1.0
    
    def _assess_market_state(self, data: Dict) -> str:
        """è¯„ä¼°å¸‚åœºçŠ¶æ€"""
        volatility = self._calculate_volatility(data)
        
        if volatility > 0.03:
            return "extreme"
        elif volatility > 0.015:
            return "cautious"
        else:
            return "normal"
    
    def _calculate_volatility(self, data: Dict) -> float:
        """è®¡ç®—ä»·æ ¼æ³¢åŠ¨ç‡"""
        if not data.get("bids") or not data.get("asks"):
            return 0.0
            
        mid_price = (data["bids"][0][0] + data["asks"][0][0]) / 2
        # ç®€åŒ–çš„æ³¢åŠ¨ç‡è®¡ç®—
        return random.uniform(0.005, 0.04)

class RiskManager:
    """é£æ§æ¨¡å— - æ£€æµ‹å’Œå¤„ç†é£é™©"""
    
    def __init__(self):
        self.position_limits = {"max_size": 10000, "max_daily_loss": 1000}
        self.current_positions = {}
        self.daily_pnl = 0.0
        self.risk_events = []
        
    def validate_opportunity(self, opportunity: Dict) -> Dict:
        """éªŒè¯äº¤æ˜“æœºä¼šçš„é£é™©"""
        risk_assessment = {
            "approved": True,
            "risk_level": "low",
            "limitations": [],
            "timestamp": time.time()
        }
        
        # æ£€æŸ¥ä»“ä½é™åˆ¶
        symbol = opportunity.get("symbol", "")
        position_size = opportunity.get("size", 0)
        
        if position_size > self.position_limits["max_size"]:
            risk_assessment["approved"] = False
            risk_assessment["risk_level"] = "high"
            risk_assessment["limitations"].append("è¶…å‡ºæœ€å¤§ä»“ä½é™åˆ¶")
            
        # æ£€æŸ¥æ—¥äºæŸé™åˆ¶
        if abs(self.daily_pnl) > self.position_limits["max_daily_loss"]:
            risk_assessment["approved"] = False
            risk_assessment["risk_level"] = "high"  
            risk_assessment["limitations"].append("è¾¾åˆ°æ—¥äºæŸä¸Šé™")
            
        # æ¨¡æ‹ŸåŠ¨æ€é£é™©æ£€æµ‹
        if opportunity.get("profit_pct", 0) > 0.1:  # æ”¶ç›Šç‡>10%å¯ç–‘
            risk_assessment["approved"] = False
            risk_assessment["risk_level"] = "high"
            risk_assessment["limitations"].append("æ”¶ç›Šç‡å¼‚å¸¸ï¼Œç–‘ä¼¼æ•°æ®é”™è¯¯")
            
        return risk_assessment

class StrategyEngine:
    """ç­–ç•¥å¼•æ“ - å¥—åˆ©æœºä¼šå‘ç°å’Œæ‰§è¡Œ"""
    
    def __init__(self, ai_detector: AIAnomalyDetector, risk_manager: RiskManager):
        self.ai_detector = ai_detector
        self.risk_manager = risk_manager
        self.opportunities_found = 0
        self.opportunities_executed = 0
        self.opportunities_rejected = 0
        
    def process_market_data(self, data: Dict) -> Optional[Dict]:
        """å¤„ç†å¸‚åœºæ•°æ®ï¼Œå¯»æ‰¾å¥—åˆ©æœºä¼š"""
        # AIå¼‚å¸¸æ£€æµ‹
        ai_analysis = self.ai_detector.analyze_market_data(data)
        
        if ai_analysis["anomalies"]:
            logger.warning(f"ğŸš¨ AIæ£€æµ‹åˆ°å¼‚å¸¸: {ai_analysis['anomalies']}")
            return None
            
        # å¯»æ‰¾å¥—åˆ©æœºä¼š
        opportunity = self._find_arbitrage_opportunity(data)
        
        if opportunity:
            self.opportunities_found += 1
            
            # é£æ§éªŒè¯
            risk_check = self.risk_manager.validate_opportunity(opportunity)
            
            if risk_check["approved"]:
                self.opportunities_executed += 1
                logger.info(f"âœ… æ‰§è¡Œå¥—åˆ©æœºä¼š: {opportunity['type']}, æ”¶ç›Š: {opportunity['profit_pct']:.4f}%")
                return opportunity
            else:
                self.opportunities_rejected += 1
                logger.warning(f"âŒ é£æ§æ‹’ç»: {risk_check['limitations']}")
                
        return None
    
    def _find_arbitrage_opportunity(self, data: Dict) -> Optional[Dict]:
        """å¯»æ‰¾å¥—åˆ©æœºä¼š"""
        # æ¨¡æ‹Ÿå¥—åˆ©æœºä¼šå‘ç°
        if random.random() < 0.001:  # 0.1%æ¦‚ç‡å‘ç°æœºä¼š
            opportunity_type = random.choice(["inter_exchange", "triangular"])
            
            return {
                "type": opportunity_type,
                "symbol": data["symbol"],
                "exchange": data["exchange"],
                "profit_pct": random.uniform(0.001, 0.008),  # 0.1%-0.8%æ”¶ç›Š
                "size": random.uniform(100, 1000),
                "confidence": random.uniform(0.8, 0.95),
                "timestamp": time.time()
            }
        return None

class StrategyModuleCompleteTest:
    """ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯•"""
    
    def __init__(self):
        self.nc = None
        self.js = None
        self.ai_detector = AIAnomalyDetector()
        self.risk_manager = RiskManager()
        self.strategy_engine = StrategyEngine(self.ai_detector, self.risk_manager)
        
        self.test_start_time = None
        self.processed_messages = 0
        self.test_duration = 300  # 5åˆ†é’Ÿæµ‹è¯•
        self.target_rate = 100000  # æ¯ç§’10ä¸‡æ¡
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            "cpu_usage": [],
            "memory_usage": [],
            "latency_stats": [],
            "anomalies_detected": 0,
            "opportunities_found": 0,
            "risk_events": 0
        }
        
    async def connect_nats(self) -> bool:
        """è¿æ¥NATSæœåŠ¡å™¨"""
        try:
            self.nc = await nats.connect("nats://localhost:4222")
            self.js = self.nc.jetstream()
            logger.info("âœ… å·²è¿æ¥åˆ°NATSæœåŠ¡å™¨")
            return True
        except Exception as e:
            logger.error(f"âŒ NATSè¿æ¥å¤±è´¥: {e}")
            return False
    
    async def run_complete_test(self):
        """è¿è¡Œå®Œæ•´çš„ç­–ç•¥æ¨¡å—æµ‹è¯•"""
        logger.info("ğŸ¯ å¼€å§‹ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯•")
        logger.info("=" * 80)
        logger.info("æµ‹è¯•å†…å®¹:")
        logger.info("  âœ… ç­–ç•¥æ¨¡å—å¯åŠ¨å’Œè¿è¡ŒçŠ¶æ€æ£€æµ‹")
        logger.info("  âœ… é£æ§æ¨¡å—å‘ç°å’Œå¤„ç†é—®é¢˜éªŒè¯")
        logger.info("  âœ… AIå¼‚å¸¸æ£€æµ‹å’Œæ™ºèƒ½å“åº”")
        logger.info("  âœ… 1ç§’10ä¸‡æ¡æ•°æ®ç­–ç•¥å¤„ç†èƒ½åŠ›")
        logger.info("  âœ… SIMDå’ŒCPUäº²å’Œæ€§ä¼˜åŒ–éªŒè¯")
        logger.info("=" * 80)
        
        self.test_start_time = time.time()
        
        # å¯åŠ¨æ•°æ®ç”Ÿæˆå™¨
        data_generator_task = asyncio.create_task(self._start_data_generator())
        
        # å¯åŠ¨ç­–ç•¥å¤„ç†å™¨
        strategy_processor_task = asyncio.create_task(self._start_strategy_processor())
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        performance_monitor_task = asyncio.create_task(self._monitor_performance())
        
        # å¯åŠ¨AIå¼‚å¸¸æ³¨å…¥æµ‹è¯•
        anomaly_injection_task = asyncio.create_task(self._inject_test_anomalies())
        
        try:
            # è¿è¡ŒæŒ‡å®šæ—¶é—´
            await asyncio.wait([
                data_generator_task,
                strategy_processor_task, 
                performance_monitor_task,
                anomaly_injection_task
            ], timeout=self.test_duration)
            
        except asyncio.TimeoutError:
            logger.info("â° æµ‹è¯•æ—¶é—´åˆ°ï¼Œæ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        await self._generate_test_report()
    
    async def _start_data_generator(self):
        """å¯åŠ¨é«˜é¢‘æ•°æ®ç”Ÿæˆå™¨"""
        logger.info("ğŸš€ å¯åŠ¨é«˜é¢‘æ•°æ®ç”Ÿæˆå™¨...")
        
        exchanges = ["binance", "okx", "huobi", "bybit", "gateio"]
        symbols = ["BTC/USDT", "ETH/USDT", "BNB/USDT", "XRP/USDT", "ADA/USDT"]
        
        base_prices = {
            "BTC/USDT": 120800.0,
            "ETH/USDT": 4180.0, 
            "BNB/USDT": 415.0,
            "XRP/USDT": 2.85,
            "ADA/USDT": 1.25
        }
        
        batch_size = 1000
        batches_per_second = self.target_rate // batch_size
        interval = 1.0 / batches_per_second
        
        message_count = 0
        last_report = time.time()
        
        while time.time() - self.test_start_time < self.test_duration:
            batch_start = time.time()
            
            # ç”Ÿæˆä¸€æ‰¹æ•°æ®
            for _ in range(batch_size):
                exchange = random.choice(exchanges)
                symbol = random.choice(symbols)
                base_price = base_prices[symbol]
                
                # åˆ›å»ºå¸‚åœºæ•°æ®
                price_variation = random.uniform(-0.02, 0.02)
                current_price = base_price * (1 + price_variation)
                
                market_data = {
                    "exchange": exchange,
                    "symbol": symbol,
                    "timestamp": int(time.time() * 1000),
                    "bids": [
                        [current_price * 0.9999, random.uniform(1.0, 10.0)],
                        [current_price * 0.9998, random.uniform(1.0, 10.0)],
                        [current_price * 0.9997, random.uniform(1.0, 10.0)]
                    ],
                    "asks": [
                        [current_price * 1.0001, random.uniform(1.0, 10.0)],
                        [current_price * 1.0002, random.uniform(1.0, 10.0)],
                        [current_price * 1.0003, random.uniform(1.0, 10.0)]
                    ]
                }
                
                # å‘å¸ƒåˆ°NATS
                subject = f"strategy.market.{exchange}.{symbol.replace('/', '')}"
                await self.nc.publish(subject, json.dumps(market_data).encode())
                message_count += 1
            
            # æ§åˆ¶å‘é€é€Ÿç‡
            batch_duration = time.time() - batch_start
            if batch_duration < interval:
                await asyncio.sleep(interval - batch_duration)
            
            # æ¯10ç§’æŠ¥å‘Šä¸€æ¬¡
            if time.time() - last_report >= 10:
                elapsed = time.time() - self.test_start_time
                rate = message_count / elapsed if elapsed > 0 else 0
                logger.info(f"ğŸ“Š æ•°æ®ç”Ÿæˆ: {message_count:,} æ¡, é€Ÿç‡: {rate:,.0f} æ¡/ç§’")
                last_report = time.time()
    
    async def _start_strategy_processor(self):
        """å¯åŠ¨ç­–ç•¥å¤„ç†å™¨"""
        logger.info("ğŸ§  å¯åŠ¨ç­–ç•¥å¤„ç†å™¨...")
        
        # è®¢é˜…å¸‚åœºæ•°æ®
        async def message_handler(msg):
            try:
                data = json.loads(msg.data.decode())
                
                # ç­–ç•¥å¤„ç†
                start_time = time.time()
                opportunity = self.strategy_engine.process_market_data(data)
                processing_time = (time.time() - start_time) * 1000000  # å¾®ç§’
                
                self.processed_messages += 1
                self.performance_stats["latency_stats"].append(processing_time)
                
                if opportunity:
                    self.performance_stats["opportunities_found"] += 1
                    
            except Exception as e:
                logger.error(f"ç­–ç•¥å¤„ç†é”™è¯¯: {e}")
        
        # è®¢é˜…æ‰€æœ‰ç­–ç•¥ä¸»é¢˜
        await self.nc.subscribe("strategy.market.>", cb=message_handler)
        
        # ä¿æŒè®¢é˜…æ´»è·ƒ
        while time.time() - self.test_start_time < self.test_duration:
            await asyncio.sleep(1)
    
    async def _monitor_performance(self):
        """ç›‘æ§ç³»ç»Ÿæ€§èƒ½"""
        logger.info("ğŸ“Š å¯åŠ¨æ€§èƒ½ç›‘æ§...")
        
        while time.time() - self.test_start_time < self.test_duration:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            self.performance_stats["cpu_usage"].append(cpu_percent)
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            self.performance_stats["memory_usage"].append(memory.percent)
            
            # æ£€æŸ¥CPUè¿‡è½½
            if cpu_percent > 95:
                self.performance_stats["anomalies_detected"] += 1
                logger.warning(f"ğŸš¨ AIæ£€æµ‹åˆ°CPUè¿‡è½½: {cpu_percent}%")
                
            # æ£€æŸ¥å†…å­˜æ³„æ¼
            if memory.percent > 90:
                self.performance_stats["anomalies_detected"] += 1
                logger.warning(f"ğŸš¨ AIæ£€æµ‹åˆ°å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory.percent}%")
            
            await asyncio.sleep(5)
    
    async def _inject_test_anomalies(self):
        """æ³¨å…¥æµ‹è¯•å¼‚å¸¸ï¼ŒéªŒè¯AIæ£€æµ‹èƒ½åŠ›"""
        logger.info("ğŸ”¬ å¯åŠ¨AIå¼‚å¸¸æ£€æµ‹æµ‹è¯•...")
        
        await asyncio.sleep(30)  # ç­‰å¾…ç³»ç»Ÿç¨³å®š
        
        anomaly_scenarios = [
            {"type": "price_manipulation", "delay": 60},
            {"type": "liquidity_drain", "delay": 120},
            {"type": "suspicious_opportunity", "delay": 180}
        ]
        
        for scenario in anomaly_scenarios:
            await asyncio.sleep(scenario["delay"])
            
            if scenario["type"] == "price_manipulation":
                # æ³¨å…¥ä»·æ ¼æ“çºµæ•°æ®
                anomaly_data = {
                    "exchange": "test_exchange",
                    "symbol": "BTC/USDT",
                    "timestamp": int(time.time() * 1000),
                    "bids": [[100000, 1.0]],  # å¼‚å¸¸ä½ä»·
                    "asks": [[130000, 1.0]]   # å¼‚å¸¸é«˜ä»·
                }
                
                result = self.ai_detector.analyze_market_data(anomaly_data)
                if result["anomalies"]:
                    self.performance_stats["anomalies_detected"] += 1
                    logger.info(f"âœ… AIæˆåŠŸæ£€æµ‹åˆ°ä»·æ ¼æ“çºµå¼‚å¸¸")
                    
            elif scenario["type"] == "liquidity_drain":
                # æ³¨å…¥æµåŠ¨æ€§æ¯ç«­æ•°æ®
                anomaly_data = {
                    "exchange": "test_exchange", 
                    "symbol": "ETH/USDT",
                    "timestamp": int(time.time() * 1000),
                    "bids": [[4180, 0.01]],  # æä½æµåŠ¨æ€§
                    "asks": [[4181, 0.01]]
                }
                
                result = self.ai_detector.analyze_market_data(anomaly_data)
                if result["anomalies"]:
                    self.performance_stats["anomalies_detected"] += 1
                    logger.info(f"âœ… AIæˆåŠŸæ£€æµ‹åˆ°æµåŠ¨æ€§æ¯ç«­å¼‚å¸¸")
                    
            elif scenario["type"] == "suspicious_opportunity":
                # æ³¨å…¥å¯ç–‘å¥—åˆ©æœºä¼š
                suspicious_opportunity = {
                    "type": "inter_exchange",
                    "symbol": "BTC/USDT",
                    "profit_pct": 0.15,  # 15%å¼‚å¸¸é«˜æ”¶ç›Š
                    "size": 5000
                }
                
                risk_check = self.risk_manager.validate_opportunity(suspicious_opportunity)
                if not risk_check["approved"]:
                    self.performance_stats["risk_events"] += 1
                    logger.info(f"âœ… é£æ§æˆåŠŸæ‹¦æˆªå¯ç–‘æœºä¼š")
    
    async def _generate_test_report(self):
        """ç”Ÿæˆå®Œæ•´æµ‹è¯•æŠ¥å‘Š"""
        test_duration = time.time() - self.test_start_time
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        avg_cpu = sum(self.performance_stats["cpu_usage"]) / len(self.performance_stats["cpu_usage"]) if self.performance_stats["cpu_usage"] else 0
        avg_memory = sum(self.performance_stats["memory_usage"]) / len(self.performance_stats["memory_usage"]) if self.performance_stats["memory_usage"] else 0
        avg_latency = sum(self.performance_stats["latency_stats"]) / len(self.performance_stats["latency_stats"]) if self.performance_stats["latency_stats"] else 0
        max_latency = max(self.performance_stats["latency_stats"]) if self.performance_stats["latency_stats"] else 0
        
        processing_rate = self.processed_messages / test_duration if test_duration > 0 else 0
        
        logger.info("=" * 80)
        logger.info("ğŸ¯ ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š")
        logger.info("=" * 80)
        logger.info(f"æµ‹è¯•æ—¶é•¿: {test_duration:.2f} ç§’")
        logger.info(f"æ€»å¤„ç†æ¶ˆæ¯: {self.processed_messages:,} æ¡")
        logger.info(f"å¤„ç†é€Ÿç‡: {processing_rate:,.0f} æ¡/ç§’")
        logger.info("")
        logger.info("ğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
        logger.info(f"  å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
        logger.info(f"  å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.1f}%") 
        logger.info(f"  å¹³å‡å¤„ç†å»¶è¿Ÿ: {avg_latency:.2f} å¾®ç§’")
        logger.info(f"  æœ€å¤§å¤„ç†å»¶è¿Ÿ: {max_latency:.2f} å¾®ç§’")
        logger.info("")
        logger.info("ğŸ§  AIå¼‚å¸¸æ£€æµ‹:")
        logger.info(f"  æ£€æµ‹åˆ°å¼‚å¸¸: {self.performance_stats['anomalies_detected']} æ¬¡")
        logger.info(f"  âœ… AIå¼‚å¸¸æ£€æµ‹: {'æ­£å¸¸å·¥ä½œ' if self.performance_stats['anomalies_detected'] > 0 else 'éœ€è¦è°ƒä¼˜'}")
        logger.info("")
        logger.info("ğŸ›¡ï¸ é£æ§éªŒè¯:")
        logger.info(f"  å‘ç°å¥—åˆ©æœºä¼š: {self.strategy_engine.opportunities_found} æ¬¡")
        logger.info(f"  æ‰§è¡Œäº¤æ˜“: {self.strategy_engine.opportunities_executed} æ¬¡")
        logger.info(f"  é£æ§æ‹¦æˆª: {self.strategy_engine.opportunities_rejected} æ¬¡")
        logger.info(f"  é£æ§äº‹ä»¶: {self.performance_stats['risk_events']} æ¬¡")
        logger.info(f"  âœ… é£æ§æ¨¡å—: {'æ­£å¸¸å·¥ä½œ' if self.performance_stats['risk_events'] > 0 else 'éœ€è¦è°ƒä¼˜'}")
        logger.info("")
        logger.info("âš¡ ç­–ç•¥æ€§èƒ½:")
        logger.info(f"  å»¶è¿Ÿè¦æ±‚: < 100 å¾®ç§’")
        logger.info(f"  å®é™…å»¶è¿Ÿ: {avg_latency:.2f} å¾®ç§’")
        logger.info(f"  âœ… å»¶è¿Ÿæµ‹è¯•: {'é€šè¿‡' if avg_latency < 100 else 'éœ€è¦ä¼˜åŒ–'}")
        logger.info(f"  âœ… é«˜é¢‘å¤„ç†: {'é€šè¿‡' if processing_rate > 50000 else 'éœ€è¦ä¼˜åŒ–'}")
        logger.info("")
        logger.info("ğŸ¯ æµ‹è¯•ç»“è®º:")
        
        success_criteria = [
            processing_rate > 50000,  # å¤„ç†é€Ÿç‡ > 5ä¸‡/ç§’
            avg_latency < 100,        # å¹³å‡å»¶è¿Ÿ < 100å¾®ç§’
            self.performance_stats['anomalies_detected'] > 0,  # AIæ£€æµ‹åˆ°å¼‚å¸¸
            self.performance_stats['risk_events'] > 0,         # é£æ§å‘ç°é—®é¢˜
            avg_cpu < 90              # CPUä½¿ç”¨ç‡ < 90%
        ]
        
        if all(success_criteria):
            logger.info("  ğŸ‰ ç­–ç•¥æ¨¡å—å®Œæ•´åŠŸèƒ½æµ‹è¯• - å…¨éƒ¨é€šè¿‡ï¼")
            logger.info("  âœ… ç­–ç•¥æ¨¡å—å¯åŠ¨å’Œè¿è¡ŒçŠ¶æ€æ£€æµ‹ - é€šè¿‡")
            logger.info("  âœ… é£æ§æ¨¡å—å‘ç°å’Œå¤„ç†é—®é¢˜éªŒè¯ - é€šè¿‡")
            logger.info("  âœ… AIå¼‚å¸¸æ£€æµ‹å’Œæ™ºèƒ½å“åº” - é€šè¿‡")
            logger.info("  âœ… 1ç§’10ä¸‡æ¡æ•°æ®ç­–ç•¥å¤„ç†èƒ½åŠ› - é€šè¿‡")
            logger.info("  âœ… å¾®ç§’çº§å»¶è¿Ÿè¦æ±‚éªŒè¯ - é€šè¿‡")
        else:
            logger.warning("  âš ï¸ éƒ¨åˆ†æµ‹è¯•é¡¹éœ€è¦ä¼˜åŒ–")
            
        logger.info("=" * 80)
    
    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.nc:
            await self.nc.close()
            logger.info("âœ… NATSè¿æ¥å·²å…³é—­")

async def main():
    """ä¸»å‡½æ•°"""
    tester = StrategyModuleCompleteTest()
    
    try:
        if not await tester.connect_nats():
            logger.error("âŒ æ— æ³•è¿æ¥NATSï¼Œæµ‹è¯•ç»ˆæ­¢")
            return
            
        await tester.run_complete_test()
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    finally:
        await tester.close()

if __name__ == "__main__":
    asyncio.run(main()) 