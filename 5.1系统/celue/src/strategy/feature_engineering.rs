use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc, Duration, Timelike, Datelike};
use ndarray::{Array1, Array2, ArrayView1, Axis};
use ndarray_stats::QuantileExt;
use rand::{thread_rng, Rng};

use crate::strategy::core::StrategyError;
use crate::strategy::market_state::MarketIndicators;

/// ç‰¹å¾å·¥ç¨‹é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FeatureEngineeringConfig {
    /// æŠ€æœ¯æŒ‡æ ‡é…ç½®
    pub technical_indicators: TechnicalIndicatorConfig,
    /// æ—¶é—´ç‰¹å¾é…ç½®
    pub temporal_features: TemporalFeatureConfig,
    /// ç»Ÿè®¡ç‰¹å¾é…ç½®
    pub statistical_features: StatisticalFeatureConfig,
    /// äº¤å‰ç‰¹å¾é…ç½®
    pub interaction_features: InteractionFeatureConfig,
    /// ç‰¹å¾é€‰æ‹©é…ç½®
    pub feature_selection: FeatureSelectionConfig,
    /// ç‰¹å¾å˜æ¢é…ç½®
    pub feature_transformation: FeatureTransformationConfig,
}

/// æŠ€æœ¯æŒ‡æ ‡é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TechnicalIndicatorConfig {
    /// ç§»åŠ¨å¹³å‡çª—å£
    pub ma_windows: Vec<usize>,
    /// RSIå‘¨æœŸ
    pub rsi_periods: Vec<usize>,
    /// å¸ƒæ—å¸¦é…ç½®
    pub bollinger_bands: BollingerBandConfig,
    /// MACDé…ç½®
    pub macd_config: MACDConfig,
    /// éšæœºæŒ‡æ ‡é…ç½®
    pub stochastic_config: StochasticConfig,
    /// å¨å»‰æŒ‡æ ‡é…ç½®
    pub williams_r_periods: Vec<usize>,
    /// åŠ¨é‡æŒ‡æ ‡é…ç½®
    pub momentum_periods: Vec<usize>,
}

/// å¸ƒæ—å¸¦é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BollingerBandConfig {
    pub periods: Vec<usize>,
    pub std_multipliers: Vec<f64>,
}

/// MACDé…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MACDConfig {
    pub fast_period: usize,
    pub slow_period: usize,
    pub signal_period: usize,
}

/// éšæœºæŒ‡æ ‡é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StochasticConfig {
    pub k_period: usize,
    pub d_period: usize,
    pub smooth_k: usize,
}

/// æ—¶é—´ç‰¹å¾é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TemporalFeatureConfig {
    /// æ»åç‰¹å¾æ•°é‡
    pub lag_features: Vec<usize>,
    /// æ»‘åŠ¨çª—å£ç»Ÿè®¡
    pub rolling_windows: Vec<usize>,
    /// å·®åˆ†é˜¶æ•°
    pub difference_orders: Vec<usize>,
    /// å­£èŠ‚æ€§ç‰¹å¾
    pub seasonal_features: bool,
    /// å¾ªç¯ç‰¹å¾
    pub cyclical_features: bool,
}

/// ç»Ÿè®¡ç‰¹å¾é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct StatisticalFeatureConfig {
    /// ç»Ÿè®¡çª—å£å¤§å°
    pub stat_windows: Vec<usize>,
    /// åŒ…å«çš„ç»Ÿè®¡é‡
    pub statistics: Vec<StatisticType>,
    /// åˆ†ä½æ•°
    pub quantiles: Vec<f64>,
    /// çŸ©ç»Ÿè®¡
    pub moments: Vec<usize>,
}

/// ç»Ÿè®¡ç±»å‹
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum StatisticType {
    Mean,
    Std,
    Var,
    Skew,
    Kurt,
    Min,
    Max,
    Median,
    Range,
    IQR,
}

/// äº¤å‰ç‰¹å¾é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InteractionFeatureConfig {
    /// æ˜¯å¦å¯ç”¨äº¤å‰ç‰¹å¾
    pub enabled: bool,
    /// æœ€å¤§äº¤å‰æ·±åº¦
    pub max_interaction_depth: usize,
    /// ç‰¹å¾ç»„åˆç­–ç•¥
    pub combination_strategy: CombinationStrategy,
    /// æœ€å¤§ç‰¹å¾æ•°é‡
    pub max_features: usize,
}

/// ç»„åˆç­–ç•¥
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CombinationStrategy {
    All,
    TopK(usize),
    Correlation,
    MutualInformation,
}

/// ç‰¹å¾é€‰æ‹©é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FeatureSelectionConfig {
    /// ç‰¹å¾é€‰æ‹©æ–¹æ³•
    pub methods: Vec<FeatureSelectionMethod>,
    /// é€‰æ‹©é˜ˆå€¼
    pub selection_threshold: f64,
    /// æœ€å¤§ç‰¹å¾æ•°
    pub max_features: Option<usize>,
    /// æœ€å°ç‰¹å¾æ•°
    pub min_features: usize,
    /// ç¨³å®šæ€§è¦æ±‚
    pub stability_threshold: f64,
}

/// ç‰¹å¾é€‰æ‹©æ–¹æ³•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FeatureSelectionMethod {
    /// ç›¸å…³æ€§é€‰æ‹©
    Correlation,
    /// æ–¹å·®é€‰æ‹©
    VarianceThreshold(f64),
    /// å•å˜é‡é€‰æ‹©
    UnivariateSelection,
    /// é€’å½’ç‰¹å¾æ¶ˆé™¤
    RecursiveFeatureElimination,
    /// L1æ­£åˆ™åŒ–
    L1Regularization,
    /// äº’ä¿¡æ¯
    MutualInformation,
    /// å¡æ–¹æ£€éªŒ
    ChiSquare,
}

/// ç‰¹å¾å˜æ¢é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FeatureTransformationConfig {
    /// æ ‡å‡†åŒ–æ–¹æ³•
    pub scaling_method: ScalingMethod,
    /// æ˜¯å¦åº”ç”¨PCA
    pub apply_pca: bool,
    /// PCAç»„ä»¶æ•°
    pub pca_components: Option<usize>,
    /// æ˜¯å¦åº”ç”¨å¤šé¡¹å¼ç‰¹å¾
    pub polynomial_features: bool,
    /// å¤šé¡¹å¼åº¦æ•°
    pub polynomial_degree: usize,
    /// æ˜¯å¦åº”ç”¨å¯¹æ•°å˜æ¢
    pub log_transform: bool,
}

/// ç¼©æ”¾æ–¹æ³•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ScalingMethod {
    StandardScaler,
    MinMaxScaler,
    RobustScaler,
    Normalizer,
    None,
}

impl Default for FeatureEngineeringConfig {
    fn default() -> Self {
        Self {
            technical_indicators: TechnicalIndicatorConfig {
                ma_windows: vec![5, 10, 20, 50],
                rsi_periods: vec![14, 21],
                bollinger_bands: BollingerBandConfig {
                    periods: vec![20],
                    std_multipliers: vec![2.0],
                },
                macd_config: MACDConfig {
                    fast_period: 12,
                    slow_period: 26,
                    signal_period: 9,
                },
                stochastic_config: StochasticConfig {
                    k_period: 14,
                    d_period: 3,
                    smooth_k: 3,
                },
                williams_r_periods: vec![14],
                momentum_periods: vec![10, 20],
            },
            temporal_features: TemporalFeatureConfig {
                lag_features: vec![1, 2, 3, 5, 10],
                rolling_windows: vec![5, 10, 20],
                difference_orders: vec![1, 2],
                seasonal_features: true,
                cyclical_features: true,
            },
            statistical_features: StatisticalFeatureConfig {
                stat_windows: vec![10, 20, 50],
                statistics: vec![
                    StatisticType::Mean,
                    StatisticType::Std,
                    StatisticType::Skew,
                    StatisticType::Kurt,
                ],
                quantiles: vec![0.25, 0.5, 0.75],
                moments: vec![3, 4],
            },
            interaction_features: InteractionFeatureConfig {
                enabled: true,
                max_interaction_depth: 2,
                combination_strategy: CombinationStrategy::TopK(10),
                max_features: 50,
            },
            feature_selection: FeatureSelectionConfig {
                methods: vec![
                    FeatureSelectionMethod::Correlation,
                    FeatureSelectionMethod::VarianceThreshold(0.01),
                ],
                selection_threshold: 0.01,
                max_features: Some(100),
                min_features: 10,
                stability_threshold: 0.8,
            },
            feature_transformation: FeatureTransformationConfig {
                scaling_method: ScalingMethod::StandardScaler,
                apply_pca: false,
                pca_components: None,
                polynomial_features: false,
                polynomial_degree: 2,
                log_transform: false,
            },
        }
    }
}

/// ç‰¹å¾é‡è¦æ€§è®°å½•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FeatureImportance {
    pub feature_name: String,
    pub importance_score: f64,
    pub selection_frequency: f64,
    pub stability_score: f64,
    pub correlation_with_target: f64,
}

/// ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FeatureStatistics {
    pub feature_name: String,
    pub data_type: String,
    pub missing_ratio: f64,
    pub unique_values: usize,
    pub mean: f64,
    pub std: f64,
    pub min: f64,
    pub max: f64,
    pub skewness: f64,
    pub kurtosis: f64,
    pub outlier_ratio: f64,
}

/// é«˜çº§ç‰¹å¾å·¥ç¨‹å™¨
pub struct AdvancedFeatureEngineer {
    config: Arc<RwLock<FeatureEngineeringConfig>>,
    feature_names: Arc<RwLock<Vec<String>>>,
    feature_importance: Arc<RwLock<HashMap<String, FeatureImportance>>>,
    feature_statistics: Arc<RwLock<HashMap<String, FeatureStatistics>>>,
    selected_features: Arc<RwLock<Vec<usize>>>,
    transformation_params: Arc<RwLock<TransformationParams>>,
}

/// å˜æ¢å‚æ•°
#[derive(Debug, Clone)]
pub struct TransformationParams {
    pub scaling_params: Option<ScalingParams>,
    pub pca_params: Option<PCAParams>,
    pub polynomial_params: Option<PolynomialParams>,
}

/// ç¼©æ”¾å‚æ•°
#[derive(Debug, Clone)]
pub struct ScalingParams {
    pub mean: Vec<f64>,
    pub std: Vec<f64>,
    pub min: Vec<f64>,
    pub max: Vec<f64>,
}

/// PCAå‚æ•°
#[derive(Debug, Clone)]
pub struct PCAParams {
    pub components: Array2<f64>,
    pub explained_variance: Vec<f64>,
    pub mean: Array1<f64>,
    pub n_components: usize,
}

/// å¤šé¡¹å¼å‚æ•°
#[derive(Debug, Clone)]
pub struct PolynomialParams {
    pub degree: usize,
    pub feature_combinations: Vec<Vec<usize>>,
}

impl AdvancedFeatureEngineer {
    pub fn new(config: FeatureEngineeringConfig) -> Self {
        Self {
            config: Arc::new(RwLock::new(config)),
            feature_names: Arc::new(RwLock::new(Vec::new())),
            feature_importance: Arc::new(RwLock::new(HashMap::new())),
            feature_statistics: Arc::new(RwLock::new(HashMap::new())),
            selected_features: Arc::new(RwLock::new(Vec::new())),
            transformation_params: Arc::new(RwLock::new(TransformationParams {
                scaling_params: None,
                pca_params: None,
                polynomial_params: None,
            })),
        }
    }
    
    /// æ„å»ºå®Œæ•´ç‰¹å¾é›†
    pub async fn engineer_features(
        &self,
        market_indicators: &[MarketIndicators],
        price_history: &[f64],
        volume_history: &[f64],
        returns_history: &[f64],
        timestamp_history: &[DateTime<Utc>],
    ) -> Result<Array2<f64>, StrategyError> {
        let config = self.config.read().await;
        let mut all_features = Vec::new();
        let mut feature_names = Vec::new();
        
        // 1. åŸºç¡€å¸‚åœºæŒ‡æ ‡ç‰¹å¾
        if let Some(latest) = market_indicators.last() {
            let basic_features = self.extract_basic_features(latest);
            all_features.extend(basic_features.0);
            feature_names.extend(basic_features.1);
        }
        
        // 2. æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        let tech_features = self.create_technical_indicators(
            price_history,
            volume_history,
            &config.technical_indicators,
        )?;
        all_features.extend(tech_features.0);
        feature_names.extend(tech_features.1);
        
        // 3. æ—¶é—´ç‰¹å¾
        let temporal_features = self.create_temporal_features(
            price_history,
            returns_history,
            timestamp_history,
            &config.temporal_features,
        )?;
        all_features.extend(temporal_features.0);
        feature_names.extend(temporal_features.1);
        
        // 4. ç»Ÿè®¡ç‰¹å¾
        let stat_features = self.create_statistical_features(
            price_history,
            volume_history,
            returns_history,
            &config.statistical_features,
        )?;
        all_features.extend(stat_features.0);
        feature_names.extend(stat_features.1);
        
        // 5. å¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾
        let microstructure_features = self.create_microstructure_features(market_indicators)?;
        all_features.extend(microstructure_features.0);
        feature_names.extend(microstructure_features.1);
        
        // æ›´æ–°ç‰¹å¾åç§°
        *self.feature_names.write().await = feature_names;
        
        if all_features.is_empty() {
            return Err(StrategyError::FeatureEngineeringError("No features generated".to_string()));
        }
        
        // è½¬æ¢ä¸ºçŸ©é˜µ
        let feature_matrix = Array2::from_shape_vec((1, all_features.len()), all_features)
            .map_err(|e| StrategyError::FeatureEngineeringError(format!("Matrix creation failed: {:?}", e)))?;
        
        Ok(feature_matrix)
    }
    
    /// æå–åŸºç¡€ç‰¹å¾
    fn extract_basic_features(&self, indicators: &MarketIndicators) -> (Vec<f64>, Vec<String>) {
        let mut features = Vec::new();
        let mut names = Vec::new();
        
        // åŸºç¡€å¸‚åœºæŒ‡æ ‡
        features.extend_from_slice(&[
            indicators.volatility_1h,
            indicators.volatility_4h,
            indicators.volatility_24h,
            indicators.liquidity_index,
            indicators.bid_ask_spread,
            indicators.order_book_depth,
            indicators.volume_ratio_1h,
            indicators.volume_ratio_4h,
            indicators.max_price_change_1m,
            indicators.max_price_change_5m,
            indicators.average_slippage,
            indicators.api_latency_avg,
            indicators.api_error_rate,
            indicators.api_success_rate,
            indicators.external_event_risk,
            indicators.news_sentiment_score,
        ]);
        
        names.extend_from_slice(&[
            "volatility_1h", "volatility_4h", "volatility_24h",
            "liquidity_index", "bid_ask_spread", "order_book_depth",
            "volume_ratio_1h", "volume_ratio_4h",
            "max_price_change_1m", "max_price_change_5m",
            "average_slippage", "api_latency_avg", "api_error_rate",
            "api_success_rate", "external_event_risk", "news_sentiment_score"
        ].iter().map(|s| s.to_string()).collect::<Vec<_>>());
        
        (features, names)
    }
    
    /// åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
    fn create_technical_indicators(
        &self,
        prices: &[f64],
        volumes: &[f64],
        config: &TechnicalIndicatorConfig,
    ) -> Result<(Vec<f64>, Vec<String>), StrategyError> {
        let mut features = Vec::new();
        let mut names = Vec::new();
        
        // ç§»åŠ¨å¹³å‡
        for &window in &config.ma_windows {
            if prices.len() >= window {
                let ma = self.simple_moving_average(&prices, window);
                features.push(ma);
                names.push(format!("ma_{}", window));
                
                // ä»·æ ¼ç›¸å¯¹äºç§»åŠ¨å¹³å‡çš„ä½ç½®
                if let Some(&current_price) = prices.last() {
                    let relative_position = (current_price - ma) / ma;
                    features.push(relative_position);
                    names.push(format!("price_ma_ratio_{}", window));
                }
            }
        }
        
        // RSI
        for &period in &config.rsi_periods {
            if prices.len() > period {
                let rsi = self.calculate_rsi(&prices, period);
                features.push(rsi);
                names.push(format!("rsi_{}", period));
            }
        }
        
        // å¸ƒæ—å¸¦
        for &period in &config.bollinger_bands.periods {
            for &std_mult in &config.bollinger_bands.std_multipliers {
                if prices.len() >= period {
                    let (upper, lower, width) = self.calculate_bollinger_bands(&prices, period, std_mult);
                    features.extend_from_slice(&[upper, lower, width]);
                    names.extend_from_slice(&[
                        format!("bb_upper_{}_{}", period, std_mult),
                        format!("bb_lower_{}_{}", period, std_mult),
                        format!("bb_width_{}_{}", period, std_mult),
                    ]);
                    
                    // å¸ƒæ—å¸¦ä½ç½®
                    if let Some(&current_price) = prices.last() {
                        let bb_position = if width > 0.0 {
                            (current_price - lower) / width
                        } else {
                            0.5
                        };
                        features.push(bb_position);
                        names.push(format!("bb_position_{}_{}", period, std_mult));
                    }
                }
            }
        }
        
        // MACD
        if prices.len() > config.macd_config.slow_period {
            let (macd, signal, histogram) = self.calculate_macd(
                &prices,
                config.macd_config.fast_period,
                config.macd_config.slow_period,
                config.macd_config.signal_period,
            );
            features.extend_from_slice(&[macd, signal, histogram]);
            names.extend_from_slice(&[
                "macd".to_string(),
                "macd_signal".to_string(),
                "macd_histogram".to_string(),
            ]);
        }
        
        // éšæœºæŒ‡æ ‡
        if prices.len() > config.stochastic_config.k_period {
            let (k, d) = self.calculate_stochastic(
                &prices,
                config.stochastic_config.k_period,
                config.stochastic_config.d_period,
            );
            features.extend_from_slice(&[k, d]);
            names.extend_from_slice(&["stoch_k".to_string(), "stoch_d".to_string()]);
        }
        
        // å¨å»‰æŒ‡æ ‡
        for &period in &config.williams_r_periods {
            if prices.len() >= period {
                let williams_r = self.calculate_williams_r(&prices, period);
                features.push(williams_r);
                names.push(format!("williams_r_{}", period));
            }
        }
        
        // åŠ¨é‡æŒ‡æ ‡
        for &period in &config.momentum_periods {
            if prices.len() > period {
                let momentum = self.calculate_momentum(&prices, period);
                features.push(momentum);
                names.push(format!("momentum_{}", period));
                
                // åŠ¨é‡å˜åŒ–ç‡
                if prices.len() > period + 1 {
                    let prev_momentum = self.calculate_momentum(&prices[..prices.len()-1], period);
                    let momentum_roc = (momentum - prev_momentum) / prev_momentum.abs().max(1e-8);
                    features.push(momentum_roc);
                    names.push(format!("momentum_roc_{}", period));
                }
            }
        }
        
        // æˆäº¤é‡æŠ€æœ¯æŒ‡æ ‡
        if !volumes.is_empty() {
            // æˆäº¤é‡ç§»åŠ¨å¹³å‡
            for &window in &config.ma_windows {
                if volumes.len() >= window {
                    let volume_ma = self.simple_moving_average(&volumes, window);
                    features.push(volume_ma);
                    names.push(format!("volume_ma_{}", window));
                    
                    // å½“å‰æˆäº¤é‡ç›¸å¯¹äºç§»åŠ¨å¹³å‡
                    if let Some(&current_volume) = volumes.last() {
                        let volume_ratio = current_volume / volume_ma.max(1e-8);
                        features.push(volume_ratio);
                        names.push(format!("volume_ratio_{}", window));
                    }
                }
            }
            
            // OBV (On-Balance Volume)
            let obv = self.calculate_obv(&prices, &volumes);
            features.push(obv);
            names.push("obv".to_string());
        }
        
        Ok((features, names))
    }
    
    /// åˆ›å»ºæ—¶é—´ç‰¹å¾
    fn create_temporal_features(
        &self,
        prices: &[f64],
        returns: &[f64],
        timestamps: &[DateTime<Utc>],
        config: &TemporalFeatureConfig,
    ) -> Result<(Vec<f64>, Vec<String>), StrategyError> {
        let mut features = Vec::new();
        let mut names = Vec::new();
        
        // æ»åç‰¹å¾
        for &lag in &config.lag_features {
            if prices.len() > lag {
                let lagged_price = prices[prices.len() - 1 - lag];
                features.push(lagged_price);
                names.push(format!("price_lag_{}", lag));
                
                // ä»·æ ¼å˜åŒ–
                if let Some(&current_price) = prices.last() {
                    let price_change = (current_price - lagged_price) / lagged_price.abs().max(1e-8);
                    features.push(price_change);
                    names.push(format!("price_change_lag_{}", lag));
                }
            }
            
            if returns.len() > lag {
                let lagged_return = returns[returns.len() - 1 - lag];
                features.push(lagged_return);
                names.push(format!("return_lag_{}", lag));
            }
        }
        
        // æ»‘åŠ¨çª—å£ç»Ÿè®¡
        for &window in &config.rolling_windows {
            if prices.len() >= window {
                let recent_prices = &prices[prices.len() - window..];
                
                // æ»‘åŠ¨å¹³å‡
                let rolling_mean = recent_prices.iter().sum::<f64>() / window as f64;
                features.push(rolling_mean);
                names.push(format!("rolling_mean_{}", window));
                
                // æ»‘åŠ¨æ ‡å‡†å·®
                let rolling_std = self.calculate_std(recent_prices, rolling_mean);
                features.push(rolling_std);
                names.push(format!("rolling_std_{}", window));
                
                // æ»‘åŠ¨æœ€å¤§å€¼å’Œæœ€å°å€¼
                let rolling_max = recent_prices.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
                let rolling_min = recent_prices.iter().cloned().fold(f64::INFINITY, f64::min);
                features.extend_from_slice(&[rolling_max, rolling_min]);
                names.extend_from_slice(&[
                    format!("rolling_max_{}", window),
                    format!("rolling_min_{}", window),
                ]);
                
                // å½“å‰ä»·æ ¼åœ¨æ»‘åŠ¨èŒƒå›´ä¸­çš„ä½ç½®
                if rolling_max != rolling_min {
                    if let Some(&current_price) = prices.last() {
                        let position = (current_price - rolling_min) / (rolling_max - rolling_min);
                        features.push(position);
                        names.push(format!("rolling_position_{}", window));
                    }
                }
            }
        }
        
        // å·®åˆ†ç‰¹å¾
        for &order in &config.difference_orders {
            if prices.len() > order {
                let diff = prices[prices.len() - 1] - prices[prices.len() - 1 - order];
                features.push(diff);
                names.push(format!("diff_{}", order));
                
                // ç›¸å¯¹å·®åˆ†
                let relative_diff = diff / prices[prices.len() - 1 - order].abs().max(1e-8);
                features.push(relative_diff);
                names.push(format!("relative_diff_{}", order));
            }
        }
        
        // å­£èŠ‚æ€§ç‰¹å¾
        if config.seasonal_features && !timestamps.is_empty() {
            if let Some(latest_time) = timestamps.last() {
                let hour = latest_time.hour() as f64;
                let day_of_week = latest_time.weekday().number_from_monday() as f64;
                let day_of_month = latest_time.day() as f64;
                
                // å¾ªç¯ç¼–ç 
                let hour_sin = (2.0 * std::f64::consts::PI * hour / 24.0).sin();
                let hour_cos = (2.0 * std::f64::consts::PI * hour / 24.0).cos();
                let dow_sin = (2.0 * std::f64::consts::PI * day_of_week / 7.0).sin();
                let dow_cos = (2.0 * std::f64::consts::PI * day_of_week / 7.0).cos();
                
                features.extend_from_slice(&[hour_sin, hour_cos, dow_sin, dow_cos]);
                names.extend_from_slice(&[
                    "hour_sin".to_string(),
                    "hour_cos".to_string(),
                    "dow_sin".to_string(),
                    "dow_cos".to_string(),
                ]);
                
                // æœˆä»½ç‰¹å¾
                let month = latest_time.month() as f64;
                let month_sin = (2.0 * std::f64::consts::PI * month / 12.0).sin();
                let month_cos = (2.0 * std::f64::consts::PI * month / 12.0).cos();
                features.extend_from_slice(&[month_sin, month_cos]);
                names.extend_from_slice(&["month_sin".to_string(), "month_cos".to_string()]);
            }
        }
        
        Ok((features, names))
    }
    
    /// åˆ›å»ºç»Ÿè®¡ç‰¹å¾
    fn create_statistical_features(
        &self,
        prices: &[f64],
        volumes: &[f64],
        returns: &[f64],
        config: &StatisticalFeatureConfig,
    ) -> Result<(Vec<f64>, Vec<String>), StrategyError> {
        let mut features = Vec::new();
        let mut names = Vec::new();
        
        for &window in &config.stat_windows {
            // ä»·æ ¼ç»Ÿè®¡ç‰¹å¾
            if prices.len() >= window {
                let recent_prices = &prices[prices.len() - window..];
                let stats = self.calculate_comprehensive_statistics(recent_prices, &config.statistics);
                
                for (stat_type, value) in stats {
                    features.push(value);
                    names.push(format!("price_{}_{}", stat_type, window));
                }
                
                // åˆ†ä½æ•°ç‰¹å¾
                for &quantile in &config.quantiles {
                    let q_value = self.calculate_quantile(recent_prices, quantile);
                    features.push(q_value);
                    names.push(format!("price_q{}_{}", (quantile * 100.0) as usize, window));
                }
            }
            
            // æˆäº¤é‡ç»Ÿè®¡ç‰¹å¾
            if volumes.len() >= window {
                let recent_volumes = &volumes[volumes.len() - window..];
                let stats = self.calculate_comprehensive_statistics(recent_volumes, &config.statistics);
                
                for (stat_type, value) in stats {
                    features.push(value);
                    names.push(format!("volume_{}_{}", stat_type, window));
                }
            }
            
            // æ”¶ç›Šç‡ç»Ÿè®¡ç‰¹å¾
            if returns.len() >= window {
                let recent_returns = &returns[returns.len() - window..];
                let stats = self.calculate_comprehensive_statistics(recent_returns, &config.statistics);
                
                for (stat_type, value) in stats {
                    features.push(value);
                    names.push(format!("return_{}_{}", stat_type, window));
                }
                
                // å¤æ™®æ¯”ç‡
                let mean_return = recent_returns.iter().sum::<f64>() / window as f64;
                let return_std = self.calculate_std(recent_returns, mean_return);
                let sharpe_ratio = if return_std > 0.0 { mean_return / return_std } else { 0.0 };
                features.push(sharpe_ratio);
                names.push(format!("sharpe_ratio_{}", window));
                
                // æœ€å¤§å›æ’¤
                let max_drawdown = self.calculate_max_drawdown(recent_returns);
                features.push(max_drawdown);
                names.push(format!("max_drawdown_{}", window));
            }
        }
        
        Ok((features, names))
    }
    
    /// åˆ›å»ºå¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾
    fn create_microstructure_features(
        &self,
        market_indicators: &[MarketIndicators],
    ) -> Result<(Vec<f64>, Vec<String>), StrategyError> {
        let mut features = Vec::new();
        let mut names = Vec::new();
        
        if market_indicators.is_empty() {
            return Ok((features, names));
        }
        
        let latest = market_indicators.last().unwrap();
        
        // è®¢å•æµç‰¹å¾
        let order_flow_imbalance = (latest.liquidity_index - 0.5) * 2.0;
        features.push(order_flow_imbalance);
        names.push("order_flow_imbalance".to_string());
        
        // ä»·å·®ç‰¹å¾
        let spread_volatility = latest.bid_ask_spread / latest.liquidity_index.max(0.001);
        features.push(spread_volatility);
        names.push("spread_volatility".to_string());
        
        // APIè´¨é‡ç‰¹å¾
        let api_quality = latest.api_success_rate * (1.0 - latest.api_error_rate) / (latest.api_latency_avg / 1000.0).max(0.001);
        features.push(api_quality);
        names.push("api_quality_score".to_string());
        
        // æ³¢åŠ¨ç‡æ¯”ç‡
        let volatility_ratio_1h_4h = latest.volatility_1h / latest.volatility_4h.max(1e-8);
        let volatility_ratio_4h_24h = latest.volatility_4h / latest.volatility_24h.max(1e-8);
        features.extend_from_slice(&[volatility_ratio_1h_4h, volatility_ratio_4h_24h]);
        names.extend_from_slice(&[
            "volatility_ratio_1h_4h".to_string(),
            "volatility_ratio_4h_24h".to_string(),
        ]);
        
        // æˆäº¤é‡å¼‚å¸¸æ£€æµ‹
        let volume_anomaly = (latest.volume_ratio_1h - 1.0).abs();
        features.push(volume_anomaly);
        names.push("volume_anomaly".to_string());
        
        // å¦‚æœæœ‰å†å²æ•°æ®ï¼Œè®¡ç®—è¶‹åŠ¿ç‰¹å¾
        if market_indicators.len() > 1 {
            let prev = &market_indicators[market_indicators.len() - 2];
            
            // æ³¢åŠ¨ç‡è¶‹åŠ¿
            let volatility_trend = (latest.volatility_1h - prev.volatility_1h) / prev.volatility_1h.max(1e-8);
            features.push(volatility_trend);
            names.push("volatility_trend".to_string());
            
            // æµåŠ¨æ€§è¶‹åŠ¿
            let liquidity_trend = (latest.liquidity_index - prev.liquidity_index) / prev.liquidity_index.max(1e-8);
            features.push(liquidity_trend);
            names.push("liquidity_trend".to_string());
            
            // ä»·å·®è¶‹åŠ¿
            let spread_trend = (latest.bid_ask_spread - prev.bid_ask_spread) / prev.bid_ask_spread.max(1e-8);
            features.push(spread_trend);
            names.push("spread_trend".to_string());
        }
        
        Ok((features, names))
    }
    
    /// åº”ç”¨ç‰¹å¾å˜æ¢
    pub async fn transform_features(
        &self,
        features: &Array2<f64>,
        fit_transform: bool,
    ) -> Result<Array2<f64>, StrategyError> {
        let config = self.config.read().await;
        let mut transformed_features = features.clone();
        
        // åº”ç”¨ç¼©æ”¾
        transformed_features = self.apply_scaling(&transformed_features, &config.feature_transformation.scaling_method, fit_transform).await?;
        
        // åº”ç”¨PCA
        if config.feature_transformation.apply_pca {
            transformed_features = self.apply_pca(&transformed_features, config.feature_transformation.pca_components, fit_transform).await?;
        }
        
        // åº”ç”¨å¤šé¡¹å¼ç‰¹å¾
        if config.feature_transformation.polynomial_features {
            transformed_features = self.apply_polynomial_features(&transformed_features, config.feature_transformation.polynomial_degree, fit_transform).await?;
        }
        
        // åº”ç”¨å¯¹æ•°å˜æ¢
        if config.feature_transformation.log_transform {
            transformed_features = self.apply_log_transform(&transformed_features);
        }
        
        Ok(transformed_features)
    }
    
    /// æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ–¹æ³•å®ç°
    fn simple_moving_average(&self, data: &[f64], window: usize) -> f64 {
        if data.len() < window {
            return data.iter().sum::<f64>() / data.len() as f64;
        }
        
        let recent_data = &data[data.len() - window..];
        recent_data.iter().sum::<f64>() / window as f64
    }
    
    fn calculate_rsi(&self, prices: &[f64], period: usize) -> f64 {
        if prices.len() <= period {
            return 50.0;
        }
        
        let mut gains = Vec::new();
        let mut losses = Vec::new();
        
        for i in 1..prices.len() {
            let change = prices[i] - prices[i-1];
            if change > 0.0 {
                gains.push(change);
                losses.push(0.0);
            } else {
                gains.push(0.0);
                losses.push(-change);
            }
        }
        
        if gains.len() < period {
            return 50.0;
        }
        
        let avg_gain = gains[gains.len() - period..].iter().sum::<f64>() / period as f64;
        let avg_loss = losses[losses.len() - period..].iter().sum::<f64>() / period as f64;
        
        if avg_loss == 0.0 {
            return 100.0;
        }
        
        let rs = avg_gain / avg_loss;
        100.0 - (100.0 / (1.0 + rs))
    }
    
    fn calculate_bollinger_bands(&self, prices: &[f64], period: usize, std_multiplier: f64) -> (f64, f64, f64) {
        if prices.len() < period {
            let mean = prices.iter().sum::<f64>() / prices.len() as f64;
            return (mean, mean, 0.0);
        }
        
        let recent_prices = &prices[prices.len() - period..];
        let mean = recent_prices.iter().sum::<f64>() / period as f64;
        let std_dev = self.calculate_std(recent_prices, mean);
        
        let upper = mean + std_multiplier * std_dev;
        let lower = mean - std_multiplier * std_dev;
        let width = upper - lower;
        
        (upper, lower, width)
    }
    
    fn calculate_macd(&self, prices: &[f64], fast_period: usize, slow_period: usize, signal_period: usize) -> (f64, f64, f64) {
        if prices.len() < slow_period {
            return (0.0, 0.0, 0.0);
        }
        
        // ç”Ÿäº§çº§EMAè®¡ç®—
        let ema_fast = self.exponential_moving_average_production(prices, fast_period);
        let ema_slow = self.exponential_moving_average_production(prices, slow_period);
        let macd = ema_fast - ema_slow;
        
        // ç”Ÿäº§çº§ä¿¡å·çº¿ï¼šåŸºäºMACDå†å²çš„EMA
        let signal = if prices.len() >= slow_period + signal_period {
            // æ„å»ºMACDå†å²åºåˆ—è¿›è¡Œä¿¡å·çº¿è®¡ç®—
            let mut macd_history = Vec::with_capacity(prices.len() - slow_period + 1);
            
            for i in slow_period..=prices.len() {
                let window_prices = &prices[..i];
                let window_ema_fast = self.exponential_moving_average_production(window_prices, fast_period);
                let window_ema_slow = self.exponential_moving_average_production(window_prices, slow_period);
                macd_history.push(window_ema_fast - window_ema_slow);
            }
            
            // å¯¹MACDå†å²è®¡ç®—EMAä½œä¸ºä¿¡å·çº¿
            self.exponential_moving_average_production(&macd_history, signal_period)
        } else {
            macd
        };
        
        let histogram = macd - signal;
        
        (macd, signal, histogram)
    }
    
    /// ç”Ÿäº§çº§EMAè®¡ç®— - é¿å…ç®€åŒ–å®ç°
    fn exponential_moving_average_production(&self, prices: &[f64], period: usize) -> f64 {
        if prices.is_empty() {
            return 0.0;
        }
        
        if prices.len() < period {
            // ä½¿ç”¨ç®€å•ç§»åŠ¨å¹³å‡ä½œä¸ºåˆå§‹å€¼
            return prices.iter().sum::<f64>() / prices.len() as f64;
        }
        
        let smoothing_factor = 2.0 / (period as f64 + 1.0);
        
        // ä½¿ç”¨å‰Nä¸ªå€¼çš„SMAä½œä¸ºEMAçš„åˆå§‹å€¼
        let initial_sma = prices[..period].iter().sum::<f64>() / period as f64;
        let mut ema = initial_sma;
        
        // ä»ç¬¬N+1ä¸ªå€¼å¼€å§‹è®¡ç®—EMA
        for &price in prices.iter().skip(period) {
            ema = (price * smoothing_factor) + (ema * (1.0 - smoothing_factor));
        }
        
        ema
    }
    
    fn exponential_moving_average(&self, prices: &[f64], period: usize) -> f64 {
        if prices.is_empty() {
            return 0.0;
        }
        
        let alpha = 2.0 / (period as f64 + 1.0);
        let mut ema = prices[0];
        
        for &price in prices.iter().skip(1) {
            ema = alpha * price + (1.0 - alpha) * ema;
        }
        
        ema
    }
    
    fn calculate_stochastic(&self, prices: &[f64], k_period: usize, d_period: usize) -> (f64, f64) {
        if prices.len() < k_period {
            return (50.0, 50.0);
        }
        
        let recent_prices = &prices[prices.len() - k_period..];
        let highest = recent_prices.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
        let lowest = recent_prices.iter().cloned().fold(f64::INFINITY, f64::min);
        let current_price = prices[prices.len() - 1];
        
        let k = if highest != lowest {
            100.0 * (current_price - lowest) / (highest - lowest)
        } else {
            50.0
        };
        
        // ç”Ÿäº§çº§Då€¼è®¡ç®—ï¼šKå€¼çš„d_periodç§»åŠ¨å¹³å‡
        let d = if prices.len() >= k_period + d_period {
            // è®¡ç®—å†å²Kå€¼
            let mut k_values = Vec::with_capacity(d_period);
            
            for i in 0..d_period {
                let end_idx = prices.len() - i;
                let start_idx = end_idx.saturating_sub(k_period);
                
                if start_idx < end_idx {
                    let window_prices = &prices[start_idx..end_idx];
                    let window_highest = window_prices.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
                    let window_lowest = window_prices.iter().cloned().fold(f64::INFINITY, f64::min);
                    let window_current = window_prices[window_prices.len() - 1];
                    
                    let window_k = if window_highest != window_lowest {
                        100.0 * (window_current - window_lowest) / (window_highest - window_lowest)
                    } else {
                        50.0
                    };
                    
                    k_values.push(window_k);
                }
            }
            
            if !k_values.is_empty() {
                k_values.iter().sum::<f64>() / k_values.len() as f64
            } else {
                k
            }
        } else {
            k
        };
        
        (k, d)
    }
    
    fn calculate_williams_r(&self, prices: &[f64], period: usize) -> f64 {
        if prices.len() < period {
            return -50.0;
        }
        
        let recent_prices = &prices[prices.len() - period..];
        let highest = recent_prices.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
        let lowest = recent_prices.iter().cloned().fold(f64::INFINITY, f64::min);
        let current_price = prices[prices.len() - 1];
        
        if highest != lowest {
            -100.0 * (highest - current_price) / (highest - lowest)
        } else {
            -50.0
        }
    }
    
    fn calculate_momentum(&self, prices: &[f64], period: usize) -> f64 {
        if prices.len() <= period {
            return 0.0;
        }
        
        let current_price = prices[prices.len() - 1];
        let past_price = prices[prices.len() - 1 - period];
        
        (current_price - past_price) / past_price.abs().max(1e-8)
    }
    
    fn calculate_obv(&self, prices: &[f64], volumes: &[f64]) -> f64 {
        if prices.len() != volumes.len() || prices.len() < 2 {
            return 0.0;
        }
        
        let mut obv = 0.0;
        for i in 1..prices.len() {
            if prices[i] > prices[i-1] {
                obv += volumes[i];
            } else if prices[i] < prices[i-1] {
                obv -= volumes[i];
            }
        }
        
        obv
    }
    
    fn calculate_std(&self, data: &[f64], mean: f64) -> f64 {
        if data.len() <= 1 {
            return 0.0;
        }
        
        let variance = data.iter()
            .map(|&x| (x - mean).powi(2))
            .sum::<f64>() / data.len() as f64;
        
        variance.sqrt()
    }
    
    fn calculate_comprehensive_statistics(&self, data: &[f64], stat_types: &[StatisticType]) -> Vec<(String, f64)> {
        let mut results = Vec::new();
        
        if data.is_empty() {
            return results;
        }
        
        let mean = data.iter().sum::<f64>() / data.len() as f64;
        
        for stat_type in stat_types {
            let value = match stat_type {
                StatisticType::Mean => mean,
                StatisticType::Std => self.calculate_std(data, mean),
                StatisticType::Var => {
                    let std = self.calculate_std(data, mean);
                    std * std
                },
                StatisticType::Skew => self.calculate_skewness(data, mean),
                StatisticType::Kurt => self.calculate_kurtosis(data, mean),
                StatisticType::Min => data.iter().cloned().fold(f64::INFINITY, f64::min),
                StatisticType::Max => data.iter().cloned().fold(f64::NEG_INFINITY, f64::max),
                StatisticType::Median => self.calculate_quantile(data, 0.5),
                StatisticType::Range => {
                    let min = data.iter().cloned().fold(f64::INFINITY, f64::min);
                    let max = data.iter().cloned().fold(f64::NEG_INFINITY, f64::max);
                    max - min
                },
                StatisticType::IQR => {
                    let q75 = self.calculate_quantile(data, 0.75);
                    let q25 = self.calculate_quantile(data, 0.25);
                    q75 - q25
                },
            };
            
            results.push((format!("{:?}", stat_type).to_lowercase(), value));
        }
        
        results
    }
    
    fn calculate_skewness(&self, data: &[f64], mean: f64) -> f64 {
        if data.len() < 3 {
            return 0.0;
        }
        
        let std = self.calculate_std(data, mean);
        if std == 0.0 {
            return 0.0;
        }
        
        let n = data.len() as f64;
        let sum_cubed_deviations: f64 = data.iter()
            .map(|&x| ((x - mean) / std).powi(3))
            .sum();
        
        (n / ((n - 1.0) * (n - 2.0))) * sum_cubed_deviations
    }
    
    fn calculate_kurtosis(&self, data: &[f64], mean: f64) -> f64 {
        if data.len() < 4 {
            return 3.0;
        }
        
        let std = self.calculate_std(data, mean);
        if std == 0.0 {
            return 3.0;
        }
        
        let n = data.len() as f64;
        let sum_fourth_deviations: f64 = data.iter()
            .map(|&x| ((x - mean) / std).powi(4))
            .sum();
        
        let kurtosis = (n * (n + 1.0) / ((n - 1.0) * (n - 2.0) * (n - 3.0))) * sum_fourth_deviations;
        kurtosis - 3.0 * ((n - 1.0).powi(2) / ((n - 2.0) * (n - 3.0)))
    }
    
    fn calculate_quantile(&self, data: &[f64], quantile: f64) -> f64 {
        if data.is_empty() {
            return 0.0;
        }
        
        let mut sorted_data = data.to_vec();
        sorted_data.sort_by(|a, b| a.partial_cmp(b).unwrap());
        
        let index = (quantile * (sorted_data.len() - 1) as f64).round() as usize;
        sorted_data[index.min(sorted_data.len() - 1)]
    }
    
    fn calculate_max_drawdown(&self, returns: &[f64]) -> f64 {
        if returns.is_empty() {
            return 0.0;
        }
        
        let mut cumulative_return = 1.0;
        let mut peak = 1.0;
        let mut max_drawdown: f64 = 0.0;
        
        for &ret in returns {
            cumulative_return *= (1.0 + ret);
            if cumulative_return > peak {
                peak = cumulative_return;
            }
            let drawdown = (peak - cumulative_return) / peak;
            max_drawdown = max_drawdown.max(drawdown);
        }
        
        max_drawdown
    }
    
    // å˜æ¢æ–¹æ³•çš„ç®€åŒ–å®ç°
    async fn apply_scaling(&self, features: &Array2<f64>, method: &ScalingMethod, fit: bool) -> Result<Array2<f64>, StrategyError> {
        match method {
            ScalingMethod::StandardScaler => {
                if fit {
                    // è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
                    let means: Vec<f64> = (0..features.ncols()).map(|i| {
                        features.column(i).mean().unwrap_or(0.0)
                    }).collect();
                    
                    let stds: Vec<f64> = (0..features.ncols()).map(|i| {
                        let col = features.column(i);
                        let mean = means[i];
                        let variance = col.iter().map(|&x| (x - mean).powi(2)).sum::<f64>() / col.len() as f64;
                        variance.sqrt().max(1e-8)
                    }).collect();
                    
                    // å­˜å‚¨å‚æ•°
                    let mut params = self.transformation_params.write().await;
                    params.scaling_params = Some(ScalingParams {
                        mean: means.clone(),
                        std: stds.clone(),
                        min: vec![0.0; features.ncols()],
                        max: vec![1.0; features.ncols()],
                    });
                    
                    // åº”ç”¨æ ‡å‡†åŒ–
                    let mut scaled = features.clone();
                    for i in 0..features.ncols() {
                        for j in 0..features.nrows() {
                            scaled[[j, i]] = (features[[j, i]] - means[i]) / stds[i];
                        }
                    }
                    Ok(scaled)
                } else {
                    // ä½¿ç”¨å·²å­˜å‚¨çš„å‚æ•°
                    let params = self.transformation_params.read().await;
                    if let Some(ref scaling_params) = params.scaling_params {
                        let mut scaled = features.clone();
                        for i in 0..features.ncols() {
                            for j in 0..features.nrows() {
                                scaled[[j, i]] = (features[[j, i]] - scaling_params.mean[i]) / scaling_params.std[i];
                            }
                        }
                        Ok(scaled)
                    } else {
                        Err(StrategyError::FeatureEngineeringError("Scaling parameters not fitted".to_string()))
                    }
                }
            },
            ScalingMethod::None => Ok(features.clone()),
            _ => {
                // å…¶ä»–ç¼©æ”¾æ–¹æ³•çš„ç®€åŒ–å®ç°
                Ok(features.clone())
            }
        }
    }
    
    async fn apply_pca(&self, features: &Array2<f64>, n_components: Option<usize>, fit: bool) -> Result<Array2<f64>, StrategyError> {
        // ç”Ÿäº§çº§PCAå®ç° - å®Œæ•´çš„ä¸»æˆåˆ†åˆ†æ
        use ndarray_linalg::{Eig, UPLO};
        use ndarray::Axis;
        
        info!("ğŸ” å¼€å§‹ç”Ÿäº§çº§PCAåˆ†æ - æ•°æ®ç»´åº¦: {}x{}, ç›®æ ‡ç»„ä»¶æ•°: {:?}", 
              features.nrows(), features.ncols(), n_components);
        
        let n_samples = features.nrows();
        let n_features = features.ncols();
        let n_components = n_components.unwrap_or((n_features.min(n_samples)).min(50)); // é»˜è®¤æœ€å¤š50ä¸ªä¸»æˆåˆ†
        
        if fit {
            // æ•°æ®ä¸­å¿ƒåŒ–
            let means = features.mean_axis(Axis(0)).ok_or_else(|| 
                StrategyError::FeatureEngineeringError("Failed to compute feature means".to_string()))?;
            
            let centered_data = features - &means.insert_axis(Axis(0));
            
            // è®¡ç®—åæ–¹å·®çŸ©é˜µ
            let covariance = centered_data.t().dot(&centered_data) / (n_samples as f64 - 1.0);
            
            // è®¡ç®—ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
            let (eigenvalues, eigenvectors) = covariance.eig(UPLO::Upper)
                .map_err(|e| StrategyError::FeatureEngineeringError(
                    format!("Eigenvalue decomposition failed: {:?}", e)))?;
            
            // æå–å®éƒ¨å¹¶æ’åºï¼ˆæŒ‰ç‰¹å¾å€¼é™åºï¼‰
            let mut eigenvalues_real: Vec<f64> = eigenvalues.iter().map(|c| c.re).collect();
            let mut indices: Vec<usize> = (0..eigenvalues_real.len()).collect();
            indices.sort_by(|&i, &j| eigenvalues_real[j].partial_cmp(&eigenvalues_real[i]).unwrap());
            
            // é€‰æ‹©å‰n_componentsä¸ªä¸»æˆåˆ†
            let selected_indices: Vec<usize> = indices.into_iter().take(n_components).collect();
            let mut principal_components = Array2::zeros((n_features, n_components));
            
            for (i, &idx) in selected_indices.iter().enumerate() {
                for j in 0..n_features {
                    principal_components[[j, i]] = eigenvectors[[j, idx]].re;
                }
            }
            
            // å­˜å‚¨PCAå‚æ•°
            let mut params = self.transformation_params.write().await;
            params.pca_params = Some(PCAParams {
                components: principal_components.clone(),
                mean: means.to_owned(),
                explained_variance: selected_indices.iter()
                    .map(|&i| eigenvalues_real[i].max(0.0))
                    .collect(),
                n_components,
            });
            
            // å˜æ¢æ•°æ®
            let transformed = centered_data.dot(&principal_components);
            
            // è®¡ç®—è§£é‡Šæ–¹å·®æ¯”
            let total_variance: f64 = eigenvalues_real.iter().sum();
            let explained_variance_ratio: f64 = selected_indices.iter()
                .map(|&i| eigenvalues_real[i])
                .sum::<f64>() / total_variance;
            
            info!("âœ… PCAæ‹Ÿåˆå®Œæˆ - ä¿ç•™äº† {:.2}% çš„æ–¹å·®ï¼Œé€‰æ‹©äº† {} ä¸ªä¸»æˆåˆ†", 
                  explained_variance_ratio * 100.0, n_components);
            
            Ok(transformed)
        } else {
            // ä½¿ç”¨å·²æ‹Ÿåˆçš„å‚æ•°è¿›è¡Œå˜æ¢
            let params = self.transformation_params.read().await;
            if let Some(ref pca_params) = params.pca_params {
                let centered_data = features - &pca_params.mean.insert_axis(Axis(0));
                let transformed = centered_data.dot(&pca_params.components);
                Ok(transformed)
            } else {
                Err(StrategyError::FeatureEngineeringError("PCA parameters not fitted".to_string()))
            }
        }
    }
    
    async fn apply_polynomial_features(&self, features: &Array2<f64>, _degree: usize, _fit: bool) -> Result<Array2<f64>, StrategyError> {
        // å¤šé¡¹å¼ç‰¹å¾çš„ç®€åŒ–å®ç° - ç›´æ¥è¿”å›åŸå§‹ç‰¹å¾
        Ok(features.clone())
    }
    
    fn apply_log_transform(&self, features: &Array2<f64>) -> Array2<f64> {
        let mut transformed = features.clone();
        for i in 0..features.nrows() {
            for j in 0..features.ncols() {
                if features[[i, j]] > 0.0 {
                    transformed[[i, j]] = features[[i, j]].ln();
                }
            }
        }
        transformed
    }
    
    /// è·å–ç‰¹å¾åç§°
    pub async fn get_feature_names(&self) -> Vec<String> {
        self.feature_names.read().await.clone()
    }
    
    /// è·å–é€‰ä¸­çš„ç‰¹å¾ç´¢å¼•
    pub async fn get_selected_features(&self) -> Vec<usize> {
        self.selected_features.read().await.clone()
    }
    
    /// æ›´æ–°é…ç½®
    pub async fn update_config(&self, config: FeatureEngineeringConfig) {
        *self.config.write().await = config;
    }
} 
                    for i in 0..features.ncols() {
                        for j in 0..features.nrows() {
                            scaled[[j, i]] = (features[[j, i]] - means[i]) / stds[i];
                        }
                    }
                    Ok(scaled)
                } else {
                    // ä½¿ç”¨å·²å­˜å‚¨çš„å‚æ•°
                    let params = self.transformation_params.read().await;
                    if let Some(ref scaling_params) = params.scaling_params {
                        let mut scaled = features.clone();
                        for i in 0..features.ncols() {
                            for j in 0..features.nrows() {
                                scaled[[j, i]] = (features[[j, i]] - scaling_params.mean[i]) / scaling_params.std[i];
                            }
                        }
                        Ok(scaled)
                    } else {
                        Err(StrategyError::FeatureEngineeringError("Scaling parameters not fitted".to_string()))
                    }
                }
            },
            ScalingMethod::None => Ok(features.clone()),
            _ => {
                // å…¶ä»–ç¼©æ”¾æ–¹æ³•çš„ç®€åŒ–å®ç°
                Ok(features.clone())
            }
        }
    }
    
    async fn apply_pca(&self, features: &Array2<f64>, n_components: Option<usize>, fit: bool) -> Result<Array2<f64>, StrategyError> {
        // ç”Ÿäº§çº§PCAå®ç° - å®Œæ•´çš„ä¸»æˆåˆ†åˆ†æ
        use ndarray_linalg::{Eig, UPLO};
        use ndarray::Axis;
        
        info!("ğŸ” å¼€å§‹ç”Ÿäº§çº§PCAåˆ†æ - æ•°æ®ç»´åº¦: {}x{}, ç›®æ ‡ç»„ä»¶æ•°: {:?}", 
              features.nrows(), features.ncols(), n_components);
        
        let n_samples = features.nrows();
        let n_features = features.ncols();
        let n_components = n_components.unwrap_or((n_features.min(n_samples)).min(50)); // é»˜è®¤æœ€å¤š50ä¸ªä¸»æˆåˆ†
        
        if fit {
            // æ•°æ®ä¸­å¿ƒåŒ–
            let means = features.mean_axis(Axis(0)).ok_or_else(|| 
                StrategyError::FeatureEngineeringError("Failed to compute feature means".to_string()))?;
            
            let centered_data = features - &means.insert_axis(Axis(0));
            
            // è®¡ç®—åæ–¹å·®çŸ©é˜µ
            let covariance = centered_data.t().dot(&centered_data) / (n_samples as f64 - 1.0);
            
            // è®¡ç®—ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
            let (eigenvalues, eigenvectors) = covariance.eig(UPLO::Upper)
                .map_err(|e| StrategyError::FeatureEngineeringError(
                    format!("Eigenvalue decomposition failed: {:?}", e)))?;
            
            // æå–å®éƒ¨å¹¶æ’åºï¼ˆæŒ‰ç‰¹å¾å€¼é™åºï¼‰
            let mut eigenvalues_real: Vec<f64> = eigenvalues.iter().map(|c| c.re).collect();
            let mut indices: Vec<usize> = (0..eigenvalues_real.len()).collect();
            indices.sort_by(|&i, &j| eigenvalues_real[j].partial_cmp(&eigenvalues_real[i]).unwrap());
            
            // é€‰æ‹©å‰n_componentsä¸ªä¸»æˆåˆ†
            let selected_indices: Vec<usize> = indices.into_iter().take(n_components).collect();
            let mut principal_components = Array2::zeros((n_features, n_components));
            
            for (i, &idx) in selected_indices.iter().enumerate() {
                for j in 0..n_features {
                    principal_components[[j, i]] = eigenvectors[[j, idx]].re;
                }
            }
            
            // å­˜å‚¨PCAå‚æ•°
            let mut params = self.transformation_params.write().await;
            params.pca_params = Some(PCAParams {
                components: principal_components.clone(),
                mean: means.to_owned(),
                explained_variance: selected_indices.iter()
                    .map(|&i| eigenvalues_real[i].max(0.0))
                    .collect(),
                n_components,
            });
            
            // å˜æ¢æ•°æ®
            let transformed = centered_data.dot(&principal_components);
            
            // è®¡ç®—è§£é‡Šæ–¹å·®æ¯”
            let total_variance: f64 = eigenvalues_real.iter().sum();
            let explained_variance_ratio: f64 = selected_indices.iter()
                .map(|&i| eigenvalues_real[i])
                .sum::<f64>() / total_variance;
            
            info!("âœ… PCAæ‹Ÿåˆå®Œæˆ - ä¿ç•™äº† {:.2}% çš„æ–¹å·®ï¼Œé€‰æ‹©äº† {} ä¸ªä¸»æˆåˆ†", 
                  explained_variance_ratio * 100.0, n_components);
            
            Ok(transformed)
        } else {
            // ä½¿ç”¨å·²æ‹Ÿåˆçš„å‚æ•°è¿›è¡Œå˜æ¢
            let params = self.transformation_params.read().await;
            if let Some(ref pca_params) = params.pca_params {
                let centered_data = features - &pca_params.mean.insert_axis(Axis(0));
                let transformed = centered_data.dot(&pca_params.components);
                Ok(transformed)
            } else {
                Err(StrategyError::FeatureEngineeringError("PCA parameters not fitted".to_string()))
            }
        }
    }
    
    async fn apply_polynomial_features(&self, features: &Array2<f64>, _degree: usize, _fit: bool) -> Result<Array2<f64>, StrategyError> {
        // å¤šé¡¹å¼ç‰¹å¾çš„ç®€åŒ–å®ç° - ç›´æ¥è¿”å›åŸå§‹ç‰¹å¾
        Ok(features.clone())
    }
    
    fn apply_log_transform(&self, features: &Array2<f64>) -> Array2<f64> {
        let mut transformed = features.clone();
        for i in 0..features.nrows() {
            for j in 0..features.ncols() {
                if features[[i, j]] > 0.0 {
                    transformed[[i, j]] = features[[i, j]].ln();
                }
            }
        }
        transformed
    }
    
    /// è·å–ç‰¹å¾åç§°
    pub async fn get_feature_names(&self) -> Vec<String> {
        self.feature_names.read().await.clone()
    }
    
    /// è·å–é€‰ä¸­çš„ç‰¹å¾ç´¢å¼•
    pub async fn get_selected_features(&self) -> Vec<usize> {
        self.selected_features.read().await.clone()
    }
    
    /// æ›´æ–°é…ç½®
    pub async fn update_config(&self, config: FeatureEngineeringConfig) {
        *self.config.write().await = config;
    }
} 